
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>How to Train Your Neural Net: A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes. &#8212; How to Train Your Neural Net, A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes.</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ASTR330_Final_Project_Jupyter';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="How to Train Your Neural Net, A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes. - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="How to Train Your Neural Net, A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes. - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to Machine Learning for Astrophysical Purposes.
                </a>
            </li>
        </ul>
        
    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/iam37/DualFinder.git/main?urlpath=tree/dual_finder_book/ASTR330_Final_Project_Jupyter.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/iam37/DualFinder.git" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/iam37/DualFinder.git/issues/new?title=Issue%20on%20page%20%2FASTR330_Final_Project_Jupyter.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/ASTR330_Final_Project_Jupyter.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>How to Train Your Neural Net: A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes.</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#author-isaac-moskowitz">Author: Isaac Moskowitz</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#professor-earl-p-bellinger">Professor Earl P. Bellinger</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#astr-330-scientific-computing-in-astrophysics">ASTR 330: Scientific Computing in Astrophysics.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-project">Final Project.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing-and-packaging">Data Preprocessing and Packaging</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-structure">Dataset Structure</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#synthetic-images">Synthetic Images</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#real-and-composite-images">Real and “Composite” Images</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-and-design-of-dualfinder">Architecture and Design of <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conv2d-and-maxpooling2d-layers"><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> and <code class="docutils literal notranslate"><span class="pre">MaxPooling2d</span></code> Layers.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-functions">Activation Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dropout-regularization-and-batchnormalization"><code class="docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">Regularization</span></code>, and <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code>.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compiling-dualfinder">Compiling <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-learning-rate">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-batch-size">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">batch_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-dropout">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">dropout</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-dualfinder">Training <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-metrics">Model Metrics</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-proceedure">Training Proceedure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-one-discussion">Training Run One Discussion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-two-revised-hyperparameters">Training Run Two: Revised Hyperparameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-two-results-revised-hyperparameters">Training Run Two Results: Revised Hyperparameters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">Transfer Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-results-transfer-learning">Training Results: Transfer Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning-discussion">Transfer Learning Discussion</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#synthetic-phase">Synthetic Phase</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#frozen-phase">Frozen Phase</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradual-unfreezing-phase">Gradual Unfreezing Phase</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#fully-unfrozen-phase">Fully Unfrozen Phase</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-optimization">Hyperparameter Optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-discussion">Optimization Discussion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#works-cited-and-libaries-used">Works Cited and Libaries Used.</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="how-to-train-your-neural-net-a-comprehensive-guide-to-designing-and-training-convolutional-neural-networks-for-astrophysical-purposes">
<h1>How to Train Your Neural Net: A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes.<a class="headerlink" href="#how-to-train-your-neural-net-a-comprehensive-guide-to-designing-and-training-convolutional-neural-networks-for-astrophysical-purposes" title="Link to this heading">#</a></h1>
<section id="author-isaac-moskowitz">
<h2>Author: Isaac Moskowitz<a class="headerlink" href="#author-isaac-moskowitz" title="Link to this heading">#</a></h2>
</section>
<section id="professor-earl-p-bellinger">
<h2>Professor Earl P. Bellinger<a class="headerlink" href="#professor-earl-p-bellinger" title="Link to this heading">#</a></h2>
<section id="astr-330-scientific-computing-in-astrophysics">
<h3>ASTR 330: Scientific Computing in Astrophysics.<a class="headerlink" href="#astr-330-scientific-computing-in-astrophysics" title="Link to this heading">#</a></h3>
</section>
<section id="final-project">
<h3>Final Project.<a class="headerlink" href="#final-project" title="Link to this heading">#</a></h3>
</section>
</section>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>In the past few years, machine learning and artificial intelligence have become incredibly useful and popular tools for scientific analysis, serving as a type of virtual research assistant that can probe and analyze large datasets to assist and help advance human scientific discoveries. Research in astrophysics often involves analyzing huge datasets, with the newly-launched Roman and Euclid satellites expected to output terabytes of data <em>per day</em>, these datasets have grown exponetially. Machine learning frameworks are fantastic tools that astrophysicists can use to study these datasets in a comprehensive way that will lead to new discoveries and new answers to some of the biggest current questions of our field. Nevertheless, desiging and training these models to best perform a given data analysis task is a difficult and confusing endeavour (speaking from personal experience). That is why I have created this Juypter Notebook as a tutorial on how to design, train, test, and optimize a convolutional neural network for an image recognition task in astronomy. We will be using the CNN <em>DualFinder</em>, a network I and my collegues in Professor Meg Urry’s research group at Yale University designed to detect dual AGN candidates in large sky survey fields. The results of using this model on Hyper-Suprime Cam, Hubble Space Telescope, and Euclid data will be publically available through Moskowitz <em>et al.</em> (in preparation). This notebook goes through the steps of creating and loading in the training and testing datasets, desiging the model architecture to fit our image identification task, creating a training schema for our model, the effect of hyperparameters on a model’s training success, the effect of two different training procedures on the model’s ability to detect dual AGN, and the process of optimizing hyperparameters. The training data, data preparation codes, model design codes, model training codes, training visualization codes, and model optimization codes are available under the package <code class="docutils literal notranslate"><span class="pre">dual_finder</span></code> provided on my GitHub page along with this tutorial.</p>
<p><strong>Disclaimer:</strong> This tutorial has cells that train the model, which requires GPU compatibility. We have provided functionallity that displays the results of previously-executed training runs in the cells immediately succeeding training cells. Additionally, because of the size of the training dataset, the <code class="docutils literal notranslate"><span class="pre">dual_finder</span></code> package will require substantial free storage space to download.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">streamlit</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">listdir</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">isfile</span><span class="p">,</span> <span class="n">join</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">exists</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="c1">#!pwd</span>
<span class="c1">#from spectral_cube import SpectralCube</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="data-preprocessing-and-packaging">
<h2>Data Preprocessing and Packaging<a class="headerlink" href="#data-preprocessing-and-packaging" title="Link to this heading">#</a></h2>
<p>Astrophysical data can come in many different varieties. We often work with <code class="docutils literal notranslate"><span class="pre">FITS</span></code> files for image data, <code class="docutils literal notranslate"><span class="pre">FITS</span></code> tables for numerical data, and data cubes for spectra, among a myriad of other filetypes. Preprocessing your data in a way that you can use effectively to train and test your neural network is essential to tailoring the network to handle your given task as well as yield accurate predictions. In this demonstration, we will be working with image data, as is common with computer vision problems solved with neural networks. More specifically, we will be working with images of quasar (QSO) objects taken by the Hyper-Suprime Cam on the Subaru Telescope at Mauna Kea, HI. This telescope has a resolution of approximately <span class="math notranslate nohighlight">\(0.4\)</span> arcsecond, which makes it well suited for preliminary studies of dual AGN with (semi) large separations on the order of tens of kiloparsecs.</p>
<p>We accessed our data directly from the HSC Public Data Release 3 (PDR3) catalogue to be <span class="math notranslate nohighlight">\(16^&quot; \times 16^&quot;\)</span>, chosen to capture potential dual AGN candidates that may be separated by up to 3.5 arcseconds, but small enough so as to not also collect other point-source objects (such as stars) in that region of the sky. The cutouts returned by HSC’s data retrieval system are not uniform, and so our first preprocessing step is to reshape all objects to be of the same shape.</p>
<section id="dataset-structure">
<h3>Dataset Structure<a class="headerlink" href="#dataset-structure" title="Link to this heading">#</a></h3>
<p>Before we dive into how to process data for <code class="docutils literal notranslate"><span class="pre">DualFinder</span></code>, we must first discuss the structure of our example dataset. We trained <code class="docutils literal notranslate"><span class="pre">DualFinder</span></code> on two datasets of sample single and dual AGN – one made of synthetic images and the other made of real images.</p>
<section id="synthetic-images">
<h4>Synthetic Images<a class="headerlink" href="#synthetic-images" title="Link to this heading">#</a></h4>
<p>We create our synthetic images by first modeling a point-source light profile with a Moffat model [INSERT RERFERENCE] and Gaussian noise, then convolving the image with a real PSF from HSC to best model the noise and light profiles that would be captured in real images from HSC. We created approximately 55,000 of these images</p>
</section>
<section id="real-and-composite-images">
<h4>Real and “Composite” Images<a class="headerlink" href="#real-and-composite-images" title="Link to this heading">#</a></h4>
<p>While we modeled our synthetic images as closely as possible to real HSC images, there is no way to capture exactly all of the image exentricities (such as its noise and light profiles) in a simulated image. As such, in order to create a model that can effectively detect dual AGN candidates in real images, it must be trained on real images. There are many images of single AGN available in HSC PDR3. However, there are very few images of real confirmed dual AGN, which is the motivation behind why this network was developed. As such, we have a bit of a cart-and-horse problem, as we cannot effectively train our model without these real images, but we need this model to find these images in the first place. Our work-around for this problem was to create so-called <em>composite</em> images to model dual AGN. We created composite images by combining two confirmed single poit-source AGN into a single image, capturing inherent variability in orientation and relative brightness by selecting one of the point-sources as the “center” (and placing it at the center of the image) and the other as the “companion” (and rotating it about the center for arbitrary angles) and by reducing the flux of one of the sources by a given percentage value before combining into a single image. This method allowed us to make an arbitrarily large dataset of images that visually represented dual AGN without needing to find a large sample of true dual AGN candidates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># from dual_finder.preprocess_data.process_data import create_dataset</span>
<span class="kn">import</span> <span class="nn">importlib</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1">#!pwd</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;dual_finder/dual_finder/&quot;</span><span class="p">)</span>
<span class="c1">#os.chdir(&quot;dual_finder/dual_finder/preprocess_data/&quot;)</span>

<span class="kn">from</span> <span class="nn">preprocess_data.process_data</span> <span class="kn">import</span> <span class="n">create_dataset</span>

<span class="kn">from</span> <span class="nn">preprocess_data.fits_utils</span> <span class="kn">import</span> <span class="n">modified_plot_image</span> <span class="k">as</span> <span class="n">plot_image</span>

<span class="kn">from</span> <span class="nn">preprocess_data.</span> <span class="n">fits_utils</span> <span class="kn">import</span> <span class="nn">plot_dataset_sample</span>

<span class="kn">from</span> <span class="nn">cnn.create_cnn</span> <span class="kn">import</span> <span class="n">ModelCreator</span>

<span class="kn">from</span> <span class="nn">cnn.load_model</span> <span class="kn">import</span> <span class="n">loadModelClass</span>

<span class="kn">from</span> <span class="nn">cnn.train_cnn</span> <span class="kn">import</span> <span class="n">DualFinder</span>

<span class="kn">from</span> <span class="nn">cnn.extract_feature_maps</span> <span class="kn">import</span> <span class="n">FeatureExtractor</span>

<span class="kn">from</span> <span class="nn">optimize.optimize_hyperparameters</span> <span class="kn">import</span> <span class="n">OptimizeHyperparameters</span>
<span class="kn">from</span> <span class="nn">visualize.visualize_performance</span> <span class="kn">import</span> <span class="n">load_training_history</span><span class="p">,</span> <span class="n">plot_training_progress</span><span class="p">,</span> <span class="n">plot_grouped_training_progress</span><span class="p">,</span> <span class="n">VisualizeOptimization</span>

<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">reload_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
<span class="c1">#os.chdir(&quot;/vast/palmer/scratch/urry/iam37/astr330&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">line</span> <span class="mi">8</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;dual_finder/dual_finder/&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="c1">#os.chdir(&quot;dual_finder/dual_finder/preprocess_data/&quot;)</span>
<span class="ne">----&gt; </span><span class="mi">8</span> <span class="kn">from</span> <span class="nn">preprocess_data.process_data</span> <span class="kn">import</span> <span class="n">create_dataset</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="kn">from</span> <span class="nn">preprocess_data.fits_utils</span> <span class="kn">import</span> <span class="n">modified_plot_image</span> <span class="k">as</span> <span class="n">plot_image</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="kn">from</span> <span class="nn">preprocess_data.</span> <span class="n">fits_utils</span> <span class="kn">import</span> <span class="nn">plot_dataset_sample</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;preprocess_data&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The following script loads &quot;model B&quot; data, which is split between synthetic and real datasets</span>
<span class="n">X_train_1</span><span class="p">,</span> <span class="n">X_val_1</span><span class="p">,</span> <span class="n">X_train_2</span><span class="p">,</span> <span class="n">X_val_2</span><span class="p">,</span> <span class="n">train_modelA</span><span class="p">,</span> <span class="n">val_modelA</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="n">train_dataset_modelB_sim</span><span class="p">,</span> <span class="n">train_labels_modelB_sim</span> <span class="o">=</span> <span class="n">X_train_1</span>
<span class="n">val_dataset_modelB_sim</span><span class="p">,</span> <span class="n">val_labels_modelB_sim</span> <span class="o">=</span> <span class="n">X_val_1</span>
<span class="n">train_dataset_modelB_real</span><span class="p">,</span> <span class="n">train_labels_modelB_real</span> <span class="o">=</span> <span class="n">X_train_2</span>
<span class="n">val_dataset_modelB_real</span><span class="p">,</span> <span class="n">val_labels_modelB_real</span> <span class="o">=</span> <span class="n">X_val_2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This script creates &quot;model A&quot; data, which concatenates synthetic and real datasets for the model to train on simultaneously.</span>
<span class="n">train_dataset_modelA</span><span class="p">,</span> <span class="n">train_labels_modelA</span> <span class="o">=</span> <span class="n">train_modelA</span>
<span class="n">val_dataset_modelA</span><span class="p">,</span> <span class="n">val_labels_modelA</span> <span class="o">=</span> <span class="n">val_modelA</span>
</pre></div>
</div>
</div>
</div>
<p>Lets visually inspect our dataset. We will use the plotting function designed in ASTR 330 Lab 3 to display a randomly selected simulated single and double AGN, a real single AGN, and a composite AGN.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Synthetic images</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">val_dataset_modelB_sim</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">val_labels_modelB_sim</span><span class="p">))</span>
<span class="c1">#print(val_labels_modelB_sim[345])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">val_labels_modelB_sim</span> <span class="o">==</span> <span class="s1">&#39;single AGN&#39;</span><span class="p">))[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">val_labels_modelB_real</span> <span class="o">==</span> <span class="s1">&#39;single AGN&#39;</span><span class="p">))[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_dataset_sample</span><span class="p">(</span><span class="n">val_dataset_modelB_sim</span><span class="p">,</span> <span class="n">val_labels_modelB_sim</span><span class="p">,</span> 
                    <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Randomly Selected Synthetic Single AGN&quot;</span><span class="p">,</span> <span class="n">AGN_type</span> <span class="o">=</span> <span class="s2">&quot;single AGN&quot;</span><span class="p">)</span>
<span class="n">plot_dataset_sample</span><span class="p">(</span><span class="n">val_dataset_modelB_sim</span><span class="p">,</span> <span class="n">val_labels_modelB_sim</span><span class="p">,</span> 
                    <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Randomly Selected Synthetic Double AGN&quot;</span><span class="p">,</span> <span class="n">AGN_type</span> <span class="o">=</span> <span class="s2">&quot;double AGN&quot;</span><span class="p">)</span>

<span class="c1"># Real images</span>
<span class="n">plot_dataset_sample</span><span class="p">(</span><span class="n">val_dataset_modelB_real</span><span class="p">,</span> <span class="n">val_labels_modelB_real</span><span class="p">,</span> 
                    <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Randomly Selected Real Single AGN&quot;</span><span class="p">,</span> <span class="n">AGN_type</span> <span class="o">=</span> <span class="s2">&quot;single AGN&quot;</span><span class="p">)</span>
<span class="n">plot_dataset_sample</span><span class="p">(</span><span class="n">val_dataset_modelB_real</span><span class="p">,</span> <span class="n">val_labels_modelB_real</span><span class="p">,</span> 
                    <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Randomly Selected Composite AGN&quot;</span><span class="p">,</span> <span class="n">AGN_type</span> <span class="o">=</span> <span class="s2">&quot;double AGN&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="architecture-and-design-of-dualfinder">
<h3>Architecture and Design of <em>DualFinder</em><a class="headerlink" href="#architecture-and-design-of-dualfinder" title="Link to this heading">#</a></h3>
<p><em>DualFinder</em> is a deep convolutional neural network with four convolutional layers, three fully connected layers, and an output layers with two neurons representing the two possible classes for our binary classification task: <strong>single AGN</strong> and <strong>dual AGN</strong>.</p>
<section id="conv2d-and-maxpooling2d-layers">
<h4><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> and <code class="docutils literal notranslate"><span class="pre">MaxPooling2d</span></code> Layers.<a class="headerlink" href="#conv2d-and-maxpooling2d-layers" title="Link to this heading">#</a></h4>
<p>Following the structures of the AlexNET (Krizhevsky <em>et al</em> 2012), VGG6 (Simonyan &amp; Zisserman 2014), and GaMorNet (Ghosh <em>et al</em> 2020), we begin our model with an input layer of filter size <span class="math notranslate nohighlight">\(96\)</span>. The filter in a convolutional layer is a matrix of weights that are applied iteratively to elemenents in the inputted image as the network “strides” over the two-dimensional grayscale image. Our CNN multiplies the weights in this filter to the imput values of each element in the image that is contained within our filter, sums up the result, outputs it to a single pixel in the next layer, and repeats this process over the entire image in several steps, or <strong>strides</strong>. The size of the stride indicates how many pixels the filter is moved before it is applied again. Consequently, the stride size informs the amount of downsampling the model performs form layer to layer. A larger stride size will lead to more downsampling. CNNs of similar architectures to <em>DualFinder</em> are designed to reduce the dimensionality of the inputted images to capture the pixels that produce maximum values when multiplied by the weights in our filter, which is often indicates that the model has captured the most important information in the image. In practice, the model accomplishes this downsampling through the use of a <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> layer, which sums up the values in the filter and outputs them to the next layer. We repeat this process for three additional <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> layers past our input, with the filter size increasing in each layer to help the model capture finer details in the image. The larger the filter size, the larger the weight matrix and therefore more pixels “make the cut” from downsampling into the next round, and thus more small-scale structure is preserved. We intenionally set our initial filter size to be relatively small because we want the model to discover large scale repeated structure first before it learns from finer details in each image. This is done to prevent the model from recognizing background noise, contaminant sources, or fluctuations in the seeing of a given image as essential for classification, and to encourage the model to identify patterns – such as the presence of one (or two!) bright circular objects near the centers of each image. Our last convolutional layer has a filter size of <span class="math notranslate nohighlight">\(384\)</span>, which was empirically tested yield high-valued metrics in GaMorNet (Ghosh <em>et al</em>. 2020). We include a <code class="docutils literal notranslate"><span class="pre">for</span></code> loop that adds a given number <code class="docutils literal notranslate"><span class="pre">num_layers</span></code> of layers of this size. We fine-tune <code class="docutils literal notranslate"><span class="pre">num_layers</span></code> as a hyperparameter to measure its effect on the model’s success. Once the data has been downsized through these layers, we flatten the layer and allow all neurons to be fully connected to those in the previous layer through the use of a <code class="docutils literal notranslate"><span class="pre">Dense</span></code> class fully connected layer. This allows the model to retail the <em>most important</em>, or high level, information from the image and pass it to the final output layer, with two output neurons representing the “single AGN” and “double AGN” classes for prediction.</p>
</section>
</section>
<section id="activation-functions">
<h3>Activation Functions<a class="headerlink" href="#activation-functions" title="Link to this heading">#</a></h3>
<p>In a CNN, the value a neuron takes on is multiplied by a matrix of weights <span class="math notranslate nohighlight">\(w_i\)</span>, the result of which is added to a bias term <span class="math notranslate nohighlight">\(b_i\)</span> and passed through a function to give an output to the neuron, which in a fully connected layer is sent to every neuron in the next layer, and in a convolutional layer is summed with other outputs within the filter and subsequently given to the following layer. Mathematically, this process is modeled by $<span class="math notranslate nohighlight">\(y_i(x) = \sum^{N}_{i = 1}f(w_i \cdot x_i + b_i)\)</span><span class="math notranslate nohighlight">\(
where \)</span>N<span class="math notranslate nohighlight">\( is the total number of neurons in each layer. The function \)</span>f<span class="math notranslate nohighlight">\( is our *activation function* and it is essential for regulating neuron outputs to the next layer. Although the equation above is a linear transformation, these functions – along with the weight matricies – introduce non-linearity into the model essential for the model to make novel predictions and learn from the dataset. There are several activation functions available in the `Tensorflow` library which have their benefits and drawbacks for different machine learning tasks and purposes. We use the `leaky_relu` function, an adaptation of the popular ReLU (Rectified Liner Unit) function. In the ReLU function, neurons with negative values are set to zero, and neurons with positive values preserve their outputs and are passed onto the next layer. This model gained popularity over the earlier *sigmoid* function, which maps the output of a neuron to \)</span>0<span class="math notranslate nohighlight">\( for large negative outputs or \)</span>1$ for large positive outputs, because of its simplicity (as it is a piecewise linear function), its computational efficiency, and its ability to preserve useful information from the neuron by outputing its value without correction to the next layer. Nevertheless,  models using ReLU often suffer from the “dying ReLU” problem, wherby setting the output of a neuron with a negative value has rendered it dormant and therefore does not take part in the rest of the training process. This leads to loss of information and instability while training the model. There have been several activation functions developed to combat this problem, including the <code class="docutils literal notranslate"><span class="pre">leaky_relu</span></code> function, which allows for small negative outputs to be passed onto the next layer. Some of the most popular activation functions and there graphs are plotted below. <img alt="Activation Functions" src="markdown_images/activation_functions.png" /> (Image credit: Jadon Shruti (2018)., “Introduction to Different Activation Functions for Deep Learning”., <em>Medium</em>., <a class="reference external" href="https://medium.com/&#64;shrutijadon/survey-on-activation-functions-for-deep-learning-9689331ba092">https://medium.com/&#64;shrutijadon/survey-on-activation-functions-for-deep-learning-9689331ba092</a>)</p>
<p>Our final output layer uses the <code class="docutils literal notranslate"><span class="pre">softmax</span></code> activivation function, which is well-suited for categorical probability predictions because all of the component predictions that are created by the function must sum to 1 (there is a 100% probability that the model will predict <em>something</em>). We are treating our binary classification problem as a multi-class classification scheme with only two classes. We could’ve also represented our task as purely binary – in which case, we would have one output layer where the value of the neuron represents the probability that the image belongs to the positive class (<span class="math notranslate nohighlight">\(0\)</span> represents no chance, and therefore the negative class). Both methods are equally valid ways of desiging the model, however, we intend to adjust our model architecture to account for three or more classes of images in future development, so using a categorical classification scheme allows us to more easily scale up the number of classes predicted by the model.</p>
</section>
<section id="dropout-regularization-and-batchnormalization">
<h3><code class="docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">Regularization</span></code>, and <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code>.<a class="headerlink" href="#dropout-regularization-and-batchnormalization" title="Link to this heading">#</a></h3>
<p><em>DualFinder</em> also contains several non-trainable layers that are dispersed between the <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>, <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> and <code class="docutils literal notranslate"><span class="pre">Dense</span></code> layers within the model. Together, the <code class="docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">Regularization</span></code> and <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code> layers are designed to prevent the model from <em>overfitting</em> to the dataset. If a CNN is too deep of a network, it can achieve very high metrics when training on training data, but when tested on validation data, the model demonstrates poor performance. This is the “overfitting” problem, and it arises in very deep models where because of its complexity and learning capacity the model essentially “memorizes” the structure of the training data, down to its finest details, but doesnt learn the overall patterns well. So when presented with new data, it cannot recognize any patterns that are indicative of a class and therefore does not perform well. Because of the size of our model, overfitting remains an important problem with the model to monitor and fight against during training and testing, so lets go over the tools in our arsenal that help us prevent it.</p>
<p><code class="docutils literal notranslate"><span class="pre">Dropout</span></code>: The technique of dropout involves randomly selecting a certain percentage of neurons and setting them to be untrainable (therefore “dropping them out”) during training. This introduces uncertainty in the model and purposeful loss of information, which enables the model to learn the larger-scale patterns of an image more effectively and therefore apply them to new data.</p>
<p><code class="docutils literal notranslate"><span class="pre">Regularization</span></code>: L2 regularization involves applying a “penalty term” to the loss function that is the sum of the squares of the weights of the model. As such, the new loss function, with L2 regularization, is given by,
$<span class="math notranslate nohighlight">\( L = L_0 + \lambda \sum_{j = 1}^{N}(w_j)\)</span><span class="math notranslate nohighlight">\( 
where \)</span>L_0<span class="math notranslate nohighlight">\( is the original loss function (in our case, categorical crossentropy) and \)</span>\lambda<span class="math notranslate nohighlight">\( represents how much importance regularization has in the calculation of the loss function. \)</span>\lambda$ is an adjustable hyperparameter that is fine-tuned with training runs. While the loss function is minimized during training, the introduction of L2 regularization tends to decay the weights to near zero (but crucially non-zero) values. This allows the weights to be dominated by outputs from features of the image, and less affected by background noise, which leads to better applicability of the model to new data and therefore less overfitting.</p>
<p><code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code>: Batch normalization serves many purposes in regulating model training, from stabilizing gradient descent to reducing CNN training times by fascilitating faster loss function convergence, and generally is a method that improves the stability and versatility of the model. It does so by slightly adjusting the activation function of a given layer such that the mean output of the function is <span class="math notranslate nohighlight">\(0\)</span> and its standard deviation is <span class="math notranslate nohighlight">\(1\)</span> over a given image batch. This process introduces a small amount of noise via random variations caused by the normalization to the model outputs, which in turn helps prevent the model from memorizing the noise profiles of the dataset.</p>
<p>Putting it all together, we show a schematic diagram of <em>DualFinder</em> below, which highlights some of the key components (such as the convolutional layers, dropout layers, and fully connected layers) of the model’s architecture. <img alt="DualFinder Diagram" src="markdown_images/structure_of_dual_finder.png" /></p>
<p>All of these components of the model work together, often in ways unknown to us as the user due to the highly non-linear structure of the network, to extract features from the dataset and learn how they correlate to the given labels, so that once fully trained, the model can effectively discover similar images based on the presence (or lack thereof) of these features in new images.</p>
</section>
<section id="compiling-dualfinder">
<h3>Compiling <em>DualFinder</em><a class="headerlink" href="#compiling-dualfinder" title="Link to this heading">#</a></h3>
<p>Once we have preprocessed our data, we are ready to compile and train our model. Our model contained over 9 million trainable parameters, and countless connections between neurons that makes the calculations of weights and biases a highly non-linear problem. As such, we cannot rely on familiar algorithms such as <span class="math notranslate nohighlight">\(\chi^2\)</span> minimization or even Markov Chain Monte Carlo (MCMC) simulations to arrive at optimial weights and biases for our dataset.</p>
<p>Enter <em>Stochastic Gradient Descent</em> (SGD). SGD projects our optimizable parameters into a high-dimensional parameter space according to the outputs of the binary cross-entropy loss function. This space is a complicated surface with many peaks and valleys that is difficult to visualize, as for most machine-learning applications, usually has a higher dimension than the three we can easily visualize. Nevertheless, algorithms employing SGD are specially designed to handle this multidimensionality. It calculates the gradient at a particular point, corresponding to a combination of weight and bias values, and adjusts these weights so as to “travel” along the gradient (which we know from multivariable calculus represents the path of greatest ascent/descent” towards the <strong>global minimum</strong> of the loss function parameter space. For our model, we use a modern version of SGD called <code class="docutils literal notranslate"><span class="pre">Adam</span></code>, which is an adaptive SGD algorithm that continually calculates the <em>momentum</em> of the gradient descent. In this algorithm, the next step in gradient descent is calculated by taking the update to the gradient at each iteration and takes the linear combination of this update, and the previous, to create an update to the gradient descent. This method allows for more efficient convergence towards a local minimum, though there have been studies that cast doubt on the completeness of this conversion for large-parameter models. Nevertheless, it remains popular among modern machine learning models for its efficiency and relative efficacy, and is what we used to optimize our model.</p>
<section id="hyperparameters-learning-rate">
<h4>Hyperparameters: <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code><a class="headerlink" href="#hyperparameters-learning-rate" title="Link to this heading">#</a></h4>
<p>The algorithm does this in sufficiently small incremental steps, often called a “learning rate” in machine learning, so that it is efficiently progressing towards a minimum without overstepping what could be a valley in the parameter surface. This learning rate is often an adjustable <em>hyperparameter</em> of the model – an input to our model that can be adjusted manually to test its effect on the model’s efficacy – that needs to be optimized for the SGD algorithm to converge on a minimum. If the learning rate is too large, then the optimization algorithm can completely skip over minima and fail to converge. If the learning rate is too small, the time to convergence could be enormous, and we may lack the computing resources to fasciliate convergence this way. As such, finding the optimal learning rate is crucial to model success.</p>
</section>
<section id="hyperparameters-batch-size">
<h4>Hyperparameters: <code class="docutils literal notranslate"><span class="pre">batch_size</span></code><a class="headerlink" href="#hyperparameters-batch-size" title="Link to this heading">#</a></h4>
<p>It might initially seem wise to train our model on one image at a time to ensure the model has ample time to learn from its features. However, for large models with large datasets, this approach can be impractical, as the computational resources required for this may not be available. Moreover, this may lead to the optimizer getting stuck in local minima and not learning from overall patterns in the entire dataset. As good as GPUs are at parallelization, training on the entire dataset all at once is also not feasible for most (if not all) GPU resources, and will most-likely cause your program to crash. This is where <em>mini batching</em> will be useful. Mini-batching, or simply batching, creates clusters of images within the training data based on a <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> (how many images are contained within the batch). The model will be trained on the images within a batch simultaneously, allowing the model to capture overall structure present in many (or all)images without sacrificing its ability to detect individual variations. This is also an adjustable hyperparameter. Larger datasets may require a larger batch size to ensure efficient convergence, while smaller datasets most likely use smaller batch sizes to ensure variation in the dataset isn’t missed. Batch sizes are usually given in powers of 2, which empirically is seen to yield better optimizer convergence. It is important to note that adjusting the batch size hyperparameter may also necessitate a corresponding adjustment to the learning rate, as a larger batch size will need a smaller learning rate to make sure that the model does not overshoot minima.</p>
</section>
<section id="hyperparameters-dropout">
<h4>Hyperparameters: <code class="docutils literal notranslate"><span class="pre">dropout</span></code><a class="headerlink" href="#hyperparameters-dropout" title="Link to this heading">#</a></h4>
<p>Neural networks with large numbers of parameters, when trained over many training epochs, can get very good at identifying training data correctly. So much so, that the model essentially memorizes the dataset, but doesnt learn from the features and is thus unable to reproduce its success with brand-new data. This phenomena is called <em>overfitting</em> and it often manifests itself in a model achieving near perfect accuracy on training datasets, but failing to reach benchmarks on validation or testing datasets. We implement several methods to combat this, but one of the most popular and effective is to randomly set the outputs of a certain percentage of neurons to zero. This “deactivates” them, and removes them as trainable parameters during a given training cycle. This ensures that some neurons are learning from features for the first time in any given training iteration, which helps avoid overfitting. The percentage of neurons that are randomly selected for deactivation, <code class="docutils literal notranslate"><span class="pre">dropout</span></code>, is an adjustable hyperparameter that has significant impact on training efficacy. If too little neurons are dropped out, then the model is prone to overfitting. If too many are dropped out, then the model cannot effectively learn from the dataset.</p>
</section>
</section>
<section id="training-dualfinder">
<h3>Training <em>DualFinder</em><a class="headerlink" href="#training-dualfinder" title="Link to this heading">#</a></h3>
<p>Lets illustrate how to construct a training run of <em>DualFinder</em>. We first must create an instance of our <code class="docutils literal notranslate"><span class="pre">DualFinder</span></code> class, which contains several functions that train the model and monitor its progress. As of the creation of this project, our classification problem is binary, so we have two possible classes that a given image can fall under: “single AGN” or “double AGN”.</p>
<p>Our loss function is the <em>categorical crossentropy</em> function, given by, $<span class="math notranslate nohighlight">\( L = -\frac{1}{N}\sum_{i}^{N}y_i\log{p(y_i)}+(1-y_i)\log{(1-p(y_i))} \)</span>$</p>
<p>where <span class="math notranslate nohighlight">\(y_i\)</span> is the true value of the class, <span class="math notranslate nohighlight">\(\log{p(y_i)}\)</span> represents the model’s prediction, and <span class="math notranslate nohighlight">\(N\)</span> is the total number of datapoints. Both the predicted and true labels <span class="math notranslate nohighlight">\(\log{p(y_i)}\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> respectively must be numerically encoded so that the loss function can be calculated and thus prediction can be made. For binary classification tasks, it is common to define a <em>positive</em> and <em>negative</em> class and represent the output of the model as its prediction of the likelihood that a given image belongs to the positive class. In <em>DualFinder</em>, we define the positive class to be if two point sources are detected in the image. Consequently, the label of “double AGN” is given a value of <code class="docutils literal notranslate"><span class="pre">1.0</span></code> and an image labeled as a “single AGN” is given a value of <code class="docutils literal notranslate"><span class="pre">0.0</span></code> (lack of a double AGN). The final two neurons of the model output these probabilities, the loss function check’s the model’s probability prediction to the true value, and outputs a value, which motivates the continued exploration of parameter space towards the global minimum.</p>
<p>One approach to numerically encode labels is to create a “binary class matrix” from categorical class vectors. In this method, the categorical variable, in our case the label “single AGN” or “double AGN”, is first mapped to a numerical value, in our case “single AGN” to <span class="math notranslate nohighlight">\(0\)</span> and “double AGN” <span class="math notranslate nohighlight">\(1\)</span>. Then, the array (vector) containing the numerical encoding of these labels are passed into a function that creates a matrix of ones and zeros that represent the presence of a particular class in a particular label. To illustrate this, suppose that we encoded a snipet of our training labels such that $<span class="math notranslate nohighlight">\(y_i = [..., 1, 1, 0, 0, 1....]\)</span><span class="math notranslate nohighlight">\(. The binary matrix representation of this would be \)</span><span class="math notranslate nohighlight">\([...,
[0, 1], 
[0, 1], 
[1, 0],
[1, 0], 
[0, 1], ...]\)</span>$.
We create these matricies using Tensorflow’s built-in <code class="docutils literal notranslate"><span class="pre">tensorflow.keras.utils.to_categorical()</span></code> function. Once our labels are encoded, we compile our model with the binary cross-entropy loss function and all useful monitoring metrics – which in our case includes accuracy, false positives, false negatives, true positives, true negatives, recall, precision, F1 score, and the Matthews Correlation Coefficient (MCC).</p>
<section id="model-metrics">
<h4>Model Metrics<a class="headerlink" href="#model-metrics" title="Link to this heading">#</a></h4>
<p><strong>Recall</strong>: Recall measures how often the model correctly predicts the positive class out of the total number of positives in the dataset. A recall value of 1 indicates the model always predicts the positive class correcly, i.e, any time there is an instance of the positive class in the dataset, the model identifies it correctly. Because the goal of our model is to detect as many dual AGN candidates (positive classes) as available in a dataset, achieving a high recall is top priority and as such this metric is arguably the most important for evaluating the success of <em>DualFinder</em>.</p>
<p><strong>Precision</strong>: Precision is a measure of how many positive predictions made by the model were correct. It is defined as the predicted positives divided by the total number of positives <span class="math notranslate nohighlight">\(\frac{TP}{TP+FP}\)</span> where <span class="math notranslate nohighlight">\(TP\)</span> is a true positive and <span class="math notranslate nohighlight">\(FP\)</span> is a false positive.</p>
<p>The distinction between precision and recall is subtle. Essentially, recall measures the percentage of positive class detections that were identified correctly, while precision measures how often the model is correct when it predicts a positive detection. Both are vital to measuring the efficacy of <em>DualFinder</em> though a high value in one or the other individually doesn’t necessarily mean that the model is performing well. For example, suppose during a given training iteration the model achieves a high precion of <span class="math notranslate nohighlight">\(P = 98.7\%\)</span> while the recall lags behind at <span class="math notranslate nohighlight">\(R = 50.7\%\)</span>. This would mean that when the model predicts a positive class, it is highly likely to be correct. However, because the recall is so low, the model rarely predicts a positive class, and so it misses a lot of potential detections (i.e, the model has many false negatives). A <em>DualFinder</em> model with these metrics would be horrible at detecting dual AGN candidates, as it would miss-classify most of them as single AGN. Given the size of the datasets we hope to implement <em>DualFinder</em> on, it is highly unlikely that scientists would review images classified as single AGN, so the model would not be able to perform its duties and actually hampers further investigation of the images that it misses.</p>
<p>On the other hand, if the recall is high but the precision is low, then the model classifies nearly everything as a potential dual AGN candidate, which is not very useful. Consequently, a model is optimally trained when both metrics take on high values.</p>
<p><strong>F1 Score</strong>: F1 score is defined as $<span class="math notranslate nohighlight">\(\frac{precision \cdot recall}{precision + recall}\)</span>$ and is thus a combination of the two metrics above. It is an effective single metric to use to evaluate the success of a model without running into the issues of using solely precision or recall outlined above. As is the case with the metrics above, a high value of the F1 score indicates high values in precision <em>and</em> recall and thus a potentially well-trained model.</p>
<p><strong>MCC</strong>: The Matthews Correlation Coefficient (MCC) measures the difference between the actual and predicted values of the dataset’s labels and outputs a number that is equivalent to the <span class="math notranslate nohighlight">\(\chi^2\)</span> value of a <span class="math notranslate nohighlight">\(2 \times 2\)</span> correlation matrix. Unlike the metrics above, which are restricted to values between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>, the MCC can take on values in the range <span class="math notranslate nohighlight">\((-1, 1)\)</span>, where <span class="math notranslate nohighlight">\(-1\)</span> represents an inverse prediction (the model predicts the exact opposite class than its true value), <span class="math notranslate nohighlight">\(0\)</span> represents a random prediction, and <span class="math notranslate nohighlight">\(1\)</span> represents perfect correlation between predictions and true class values.</p>
</section>
</section>
<section id="training-proceedure">
<h3>Training Proceedure<a class="headerlink" href="#training-proceedure" title="Link to this heading">#</a></h3>
<p>Once our model is compiled, we are ready to begin training. Models of <code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> class have a built-in function called <code class="docutils literal notranslate"><span class="pre">model.fit()</span></code> that handles training execution. It has the following positional and optional inputs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> 
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Evidently, this function is very versitile and can handle a wide range of data structures. In our training procedure, we will mainly use the <code class="docutils literal notranslate"><span class="pre">x,</span> <span class="pre">y,</span> <span class="pre">batch_size,</span> <span class="pre">epochs,</span> <span class="pre">verbose,</span> <span class="pre">callbacks,</span> <span class="pre">validation_data,</span> <span class="pre">shuffle,</span> <span class="pre">class_weight</span></code> parameters. Let’s go through each one and its importance towards model training.</p>
<p><code class="docutils literal notranslate"><span class="pre">x</span></code>: This is our training data. This function accomodates several data structures, namely tensorflow <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> and <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> objects, as well as <code class="docutils literal notranslate"><span class="pre">numpy</span></code> arrays. We will be using the numpy arrays generated above for our training.</p>
<p><code class="docutils literal notranslate"><span class="pre">y</span></code>: These are the labels associated with our training data. They must be encoded before being passed into the function. Because our model has two output neurons instead of the typical one for a binary classification scheme, the labels must be encoded as if the model was tasked with a multi-class classification scheme with two classes. As such, our model is not constructed for one hot encoding, so we must use the encoding algorithm outlined above. [REVISE THIS]</p>
<p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: Our batch size – how many images the model will be trained on simultaneously. Accepts <code class="docutils literal notranslate"><span class="pre">int</span></code> objects.</p>
<p><code class="docutils literal notranslate"><span class="pre">epochs</span></code>: The number of iterations through the entire training dataset. Accepts <code class="docutils literal notranslate"><span class="pre">int</span></code> objects.</p>
<p><code class="docutils literal notranslate"><span class="pre">verbose</span></code>: Determines what the function outputs to the system to monitor training progress. A value of <code class="docutils literal notranslate"><span class="pre">0</span></code> means that the function outputs nothing to the console, and the user does not know at what stage of training the model is. <code class="docutils literal notranslate"><span class="pre">1</span></code> outputs all available information about training progress to the user. <code class="docutils literal notranslate"><span class="pre">2</span></code> outputs some useful information, but excludes the progress bar present in <code class="docutils literal notranslate"><span class="pre">1.</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">callbacks</span></code>: This input accepts a list of Tensorflow keras <code class="docutils literal notranslate"><span class="pre">Callback</span></code> objects, which are constructed to monitor certain aspects of the model’s training and make changes to the training procedure while it is in motion. These objects allow us to make these changes, or monitor progress, without restarting the training run. There are dozens of pre-fabricated callbacks available in the Tensorflow API, and its possible to make custom ones. For training <code class="docutils literal notranslate"><span class="pre">DualFinder</span></code> we make use of the <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code>, <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code>, and our custom <code class="docutils literal notranslate"><span class="pre">FeatureMapCallback</span></code>. The <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> callback saves the model and its weights as a <code class="docutils literal notranslate"><span class="pre">.keras</span></code> file after each training epoch so that if training is interrupted, the user can begin training the model from the last checkpoint instead of the restarting. The <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code> checkpoint monitors the progression of an evalution metric over a specified number of epochs (in our case, 5). If the metric is measured to decrease for longer than a specified tolerance level, training is stopped and the model is saved. This technique of “early stopping” is utilized in machine learning to train unstable models that might incur massive fluctuations in their evaluation metrics over the course of their training. Our custom <code class="docutils literal notranslate"><span class="pre">FeatureMapCallback</span></code> takes as input a randomly-selected image from the dataset (either a single or a dual), has the model predict the class of the image throughout training, and plots and saves a heatmap of the features of the image the model used to classify it, and therefore what the model deemed as “important indicators” of the class of the object. These plots allow us to determine what features the model is picking up on across its hidden layers and over all of its training epochs, revealing information about the model’s decision-making that is otherwise hidden in the hidden layers.</p>
<p><code class="docutils literal notranslate"><span class="pre">validation_data</span></code>: Accepts a tuple containing our validation dataset (stored in a numpy array) and our encoded validation labels (also stored in a numpy array). Data is passed into the function in this way because the function allows the user to pass their entire dataset into <code class="docutils literal notranslate"><span class="pre">x</span></code> and let the model automatically separate the training data from the validation data using <code class="docutils literal notranslate"><span class="pre">validation_split</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">class_weight</span></code>: Accepts as input a dictionary of weights (floats) that map to the (integer) classes of the dataset. Many datasets (including our own) are imbalanced, and it is often unfeasible to have equal number of samples per class in real data. As such, we want to train our model such that it can make accurate predictions when faced with an imbalanced dataset. Our <code class="docutils literal notranslate"><span class="pre">class_weights</span></code> dictionary weights under-represented classes such that predicting these classes has more of an impact on the loss function so that these classes do not get ignored during training. As such, using class weights during training is a powerful tool to prevent overfitting. We create our <code class="docutils literal notranslate"><span class="pre">class_weigts</span></code> dictionary using the <code class="docutils literal notranslate"><span class="pre">sklearn.utils.class_weight.compute_class_weight</span></code> function from Scikit-Learn – a python library with many additional machine learning algorithms and tools.</p>
<p>We demonstrate an example training run using our <strong>model A</strong> training scheme. In this program, we train our model on synthetic and real data for 30 training epochs. In our first iteration, we want to illustrate how poorly chosen hyperparameters can negatively impact training success. Since our model is trained on both types of data, we would want to use a smaller learning rate so that the model doesn’t miss important features. We will also want to use a medium to large batch size because we want to include as many different samples from each data type for the model to learn from. As such, we will chose a large learning rate of <code class="docutils literal notranslate"><span class="pre">1e-3</span></code> and a large batch size of <code class="docutils literal notranslate"><span class="pre">128</span></code>. We run the training algorithm and display plots of metrics vs. epoch below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Specify some initial hyperparameters to illustrate their impact on training. </span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">image_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;modelB&quot;</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">model_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_models/&quot;</span>

<span class="n">dual_finder_instance</span> <span class="o">=</span> <span class="n">DualFinder</span><span class="p">(</span><span class="n">train_dataset_modelA</span><span class="p">,</span> <span class="n">val_dataset_modelA</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">train_labels_modelA</span><span class="p">,</span> <span class="n">val_labels_modelA</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)</span>
<span class="n">history_bad_params_modelA</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">dual_finder_instance</span><span class="o">.</span><span class="n">trainCNN</span><span class="p">(</span><span class="n">model_filepath</span> <span class="o">=</span> <span class="n">model_filepath</span><span class="p">,</span> <span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history_bad_params</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models/saved_history.npy&quot;</span><span class="p">)</span>

<span class="n">acc_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">val_acc_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>

<span class="n">recall_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">]</span>
<span class="n">val_f1_score_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">]</span>
<span class="c1">#mcc_bad_paramsA = history_bad_params[&#39;MCC&#39;]</span>
<span class="c1">#val_mcc_bad_paramsA = history_bad_params[&#39;val_MCC&#39;]</span>

<span class="n">save_filepath</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/saved_figures/&quot;</span>
<span class="n">modelA_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_training_progress</span><span class="p">(</span><span class="n">loss_bad_paramsA</span><span class="p">,</span> <span class="n">acc_bad_paramsA</span><span class="p">,</span> <span class="n">modelA_epochs</span><span class="p">,</span> <span class="n">save_filepath</span> <span class="o">=</span> <span class="n">save_filepath</span><span class="p">,</span> <span class="n">training_run</span> <span class="o">=</span> <span class="s2">&quot;Bad Parameters&quot;</span><span class="p">,</span>
                                 <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_bad_paramsA</span><span class="p">,</span> <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_bad_paramsA</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="n">f1_score_bad_paramsA</span><span class="p">,</span>
                                 <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss_bad_paramsA</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_acc_bad_paramsA</span><span class="p">,</span> <span class="n">val_recall</span> <span class="o">=</span> <span class="n">val_recall_bad_paramsA</span><span class="p">,</span> <span class="n">val_precision</span> <span class="o">=</span> <span class="n">val_precision_bad_paramsA</span><span class="p">,</span> 
                                 <span class="n">val_f1_score</span> <span class="o">=</span> <span class="n">val_f1_score_bad_paramsA</span><span class="p">)</span>

                                 
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-run-one-discussion">
<h3>Training Run One Discussion<a class="headerlink" href="#training-run-one-discussion" title="Link to this heading">#</a></h3>
<p>With our choice of hyperparameters above, we see that the model’s training accuracy, precision, recall, and F1 score seems to plateu at a value of <span class="math notranslate nohighlight">\(0.70\)</span>, while the validation values of these metrics fluctuate wildly between values of ~<span class="math notranslate nohighlight">\(0.5\)</span> and ~ <span class="math notranslate nohighlight">\(0.70\)</span> over the training run. This is likely caused by our high learning rate, as the optimizer takes large steps between local maxima and minima in loss function space, corresponding to low and high values for these metrics respectively. As such, our optmizer has not converged on a stable solution, and has likely not learned the features of the dataset well enough to produce consistent results, which is not suitable for a detection prorgam. This demonstrate the essentialness of choosing optimal hyperparameter values when training a model.</p>
</section>
<section id="training-run-two-revised-hyperparameters">
<h3>Training Run Two: Revised Hyperparameters<a class="headerlink" href="#training-run-two-revised-hyperparameters" title="Link to this heading">#</a></h3>
<p>Let’s redo this training procedure with better informed choices for hyperparameters. We see that our learning rate was too high, so lets reduce it to <code class="docutils literal notranslate"><span class="pre">learning_rate</span> <span class="pre">=</span> <span class="pre">5e-7</span></code>. Additionally, lets reduce our batch size to <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">=</span> <span class="pre">32</span></code> to make sure that our model does not miss small but important variations in the features of the dataset. While this will increase our training time, it may provide some stability to the model. Training for the same number of epochs, <code class="docutils literal notranslate"><span class="pre">epochs</span> <span class="pre">=</span> <span class="pre">30</span></code> as above, we train a fresh instance of our model using these hyperparameters and plot the results below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">revised_batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">revised_learning_rate</span> <span class="o">=</span> <span class="mf">5e-7</span>
<span class="n">image_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;modelB&quot;</span>
<span class="n">model_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_models_better_params/&quot;</span>

<span class="n">dual_finder_instance</span> <span class="o">=</span> <span class="n">DualFinder</span><span class="p">(</span><span class="n">train_dataset_modelA</span><span class="p">,</span> <span class="n">val_dataset_modelA</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">train_labels_modelA</span><span class="p">,</span> <span class="n">val_labels_modelA</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">revised_batch_size</span><span class="p">,</span> <span class="n">revised_learning_rate</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)</span>
<span class="n">history_bad_params_modelA</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">dual_finder_instance</span><span class="o">.</span><span class="n">trainCNN</span><span class="p">(</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">model_filepath</span> <span class="o">=</span> <span class="n">model_filepath</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-run-two-results-revised-hyperparameters">
<h3>Training Run Two Results: Revised Hyperparameters<a class="headerlink" href="#training-run-two-results-revised-hyperparameters" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history_better_params</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_better_params/saved_history.npy&quot;</span><span class="p">)</span>

<span class="n">acc_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">val_acc_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>

<span class="n">recall_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">]</span>
<span class="n">val_f1_score_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">]</span>

<span class="n">save_filepath_better_params</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/saved_figures_better_params_modelA/&quot;</span>
<span class="n">modelA_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_training_progress</span><span class="p">(</span><span class="n">loss_better_paramsA</span><span class="p">,</span> <span class="n">acc_better_paramsA</span><span class="p">,</span> <span class="n">modelA_epochs</span><span class="p">,</span> <span class="n">save_filepath</span> <span class="o">=</span> <span class="n">save_filepath_better_params</span><span class="p">,</span> <span class="n">training_run</span> <span class="o">=</span> <span class="s2">&quot;Better Parameters&quot;</span><span class="p">,</span>
                                 <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_better_paramsA</span><span class="p">,</span> <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_better_paramsA</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="n">f1_score_better_paramsA</span><span class="p">,</span>
                                 <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss_better_paramsA</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_acc_better_paramsA</span><span class="p">,</span> <span class="n">val_recall</span> <span class="o">=</span> <span class="n">val_recall_better_paramsA</span><span class="p">,</span> <span class="n">val_precision</span> <span class="o">=</span> <span class="n">val_precision_better_paramsA</span><span class="p">,</span> 
                                 <span class="n">val_f1_score</span> <span class="o">=</span> <span class="n">val_f1_score_better_paramsA</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="transfer-learning">
<h2>Transfer Learning<a class="headerlink" href="#transfer-learning" title="Link to this heading">#</a></h2>
<p>When we revised our hyperparameters to better reflect our model architecture and the structure of our dataset, we were able to train a more stable model that achieved a validation accuracy, recall, precision, and F1 score of approximately <span class="math notranslate nohighlight">\(45\%\)</span>. This is statistically less than if we were randomly deciding whether an image was a single or a dual. Since the training metrics were high, the model is most-likely overfitting to the data. We can help remedy this by including more dropout/regularization layers, fine-tuning hyperparameters, and/or adjusting our training procedure. We can try to achieve this through rigorous hyperparameter optimization. We can test many hyperparameter combinations, revising their values based on training results, until we arrive at a combination that yields an optimally trained model given our architecture and dataset structure. We can systematically test these hyperparameters through the use of an optimization algorithm, such as a Tree-Based Parzen Estimator (TPE) (which we will discuss in detail on the “Optimization” section of this tutorial). However, these methods require several training runs to converge on an optimal solution. While we will eventually utilize them for hyperparameter optimization the nature of our dataset, with its synthetic and real data components, lends itself nicely to a machine-learning training tactic called <em>transfer learning</em>.</p>
<p>Transfer learning refers to the process of retraining a model, that has been pretrained on a certain dataset, with another dataset while preserving the information learned from its original training input. This process allows the model to retain important feature information it learned from the original training dataset while learning new – and most likely specialized – information from the new dataset, thus producing a better informed and hopefully more accurate model. We call our transfer-learning scheme the <strong>model B</strong> training procedure, and we initiate it by training the model freely on our synthetic dataset for 10 training epochs. Once this finishes, we “freeze” several convolutional layers by setting their parameters to “untrainable”, preserving the data learned from the synthetic set, and training the model on our real dataset for 10 training epochs. We then gradually unfreeze the layers by resetting them to “trainable”, allowing the neurons in these layers to adjust their weights and biases based on real data. We unfreeze one layer per training epoch. Once completely unfrozen, we allow the model to train freely on the real dataset for however many epochs remain after the unfreezing stage, as we allow the model to be trained in the transfer-learning stage for 20 total epochs. Theoretically, this method will allow the model to learn the noise and light profiles of real HSC data without overwriting the valuable overall structure it learned from the synthetic datam thus yielding a highly accurate model. For our data, where an ideally-trained model would learn overall structure (such as where two point sources may broadly be located in a given image if they are present) from the synethic images, then learn fine structure and appropiate noise levels from the real images during the transfer learning stage. As such, we expect this method to yield a significantly more accurate model than training the model on all image types simultaneously, as mixing real and synthetic data in the <strong>model A</strong> procedure does not allow the model sufficient time to learn from the structures in one datatype before it must learn from the other, which contributes to instability in the model and lower metrics overall.</p>
<p>We demonstrate this training proceedure below, using hyperparameters that were optimized during the research and development of this algorithm over this past summer. As with <strong>model A</strong>, we plot the results of this training procedure below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">init_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="mf">5.518358e-07</span>
<span class="c1">#learning_rate = 1.72332548599593680e-06</span>
<span class="n">image_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;modelB&quot;</span>
<span class="n">model_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_models_example_modelB/&quot;</span>
<span class="c1">#num_frozen_layers = 22</span>
<span class="n">num_frozen_layers</span> <span class="o">=</span> <span class="mi">17</span>
<span class="n">num_frozen_fc_layers</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">dual_finder_instance</span> <span class="o">=</span> <span class="n">DualFinder</span><span class="p">(</span><span class="n">train_dataset_modelB_sim</span><span class="p">,</span> <span class="n">val_dataset_modelB_sim</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">train_labels_modelB_sim</span><span class="p">,</span> <span class="n">val_labels_modelB_sim</span><span class="p">,</span> <span class="n">init_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)</span>
<span class="c1">#history_synthetic, pretrained_model = dual_finder_instance.trainCNN(model_filepath)</span>
<span class="c1">#0.32523228915885216</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#os.environ[&#39;TF_GPU_ALLOCATOR&#39;] = &#39;cuda_malloc_async&#39;</span>
<span class="n">tl_epochs</span> <span class="o">=</span> <span class="mi">30</span>
<span class="c1">#tl_learning_rate = 2.7607071462012844e-08</span>
<span class="n">tl_learning_rate</span> <span class="o">=</span> <span class="mf">1.72332548599593680e-06</span>
<span class="c1"># num_frozen_layers = 12</span>
<span class="n">tl_batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="c1">#tl_learning_rate = 8.944489782605628e-06</span>
<span class="c1">#tl_learning_rate = 5.518358e-07</span>
<span class="n">dropout_percentage</span> <span class="o">=</span> <span class="mf">0.21253947483790814</span>
<span class="n">history_synth</span><span class="p">,</span> <span class="n">history_frozen</span><span class="p">,</span> <span class="n">history_unfreeze</span><span class="p">,</span> <span class="n">history_unfrozen</span><span class="p">,</span> <span class="n">model_retrained</span> <span class="o">=</span> <span class="n">dual_finder_instance</span><span class="o">.</span><span class="n">transferLearning</span><span class="p">(</span><span class="n">num_frozen_layers</span><span class="p">,</span> <span class="n">model_filepath</span><span class="p">,</span> <span class="n">tl_epochs</span><span class="p">,</span> <span class="n">train_dataset_modelB_real</span><span class="p">,</span> <span class="n">train_labels_modelB_real</span><span class="p">,</span> <span class="n">val_dataset_modelB_real</span><span class="p">,</span> <span class="n">val_labels_modelB_real</span><span class="p">,</span> <span class="n">tl_batch_size</span><span class="p">,</span> <span class="n">tl_learning_rate</span><span class="p">,</span> <span class="n">dropout_percentage</span><span class="p">,</span> <span class="n">save_feature_maps</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="training-results-transfer-learning">
<h3>Training Results: Transfer Learning<a class="headerlink" href="#training-results-transfer-learning" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Alternative plotting version that plots all sections of the training run on the same plot, color coding them by </span>
<span class="c1"># step in the transfer learning process</span>
<span class="k">def</span> <span class="nf">extract_f1</span><span class="p">(</span><span class="n">f1_array</span><span class="p">):</span>
    <span class="n">f1_score</span> <span class="o">=</span> <span class="p">[</span><span class="n">entry</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">f1_array</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">f1_score</span>
<span class="c1">#Synthetic training phase</span>
<span class="n">history_synthetic</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/saved_history.npy&quot;</span><span class="p">)</span>
<span class="n">acc_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_synth</span><span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">val_acc_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>

<span class="n">recall_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_synth</span> <span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">])</span>
<span class="n">val_f1_score_synth</span><span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">])</span>
<span class="n">modelB_synth_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># Frozen training phase</span>
<span class="n">history_frozen</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/saved_history_frozen.npy&quot;</span><span class="p">)</span>
<span class="c1">#print(history_frozen)</span>
<span class="n">acc_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">val_acc_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>

<span class="n">recall_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_frozen</span> <span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">])</span>
<span class="n">val_f1_score_frozen</span><span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">])</span>
<span class="n">modelB_frozen_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="c1">#Unfreeze training phase</span>
<span class="n">histories_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_frozen_layers</span><span class="p">):</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;saved_models_example_modelB/saved_history_unfreeze_</span><span class="si">{</span><span class="n">ii</span><span class="si">}</span><span class="s2">.npy&quot;</span><span class="p">)</span>
    <span class="n">histories_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
    
<span class="n">acc_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">recall_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">precision_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">f1_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>


<span class="n">val_acc_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_loss_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_recall_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_precision_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_f1_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>



<span class="k">for</span> <span class="n">history</span> <span class="ow">in</span> <span class="n">histories_unfreeze</span><span class="p">:</span>
    <span class="n">acc_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">loss_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">recall_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">precision_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">f1_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">extract_f1</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1">#mcc_values_unfreeze.append(history[&#39;static_MCC&#39;])</span>

    <span class="n">val_acc_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_loss_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_recall_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_precision_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_f1_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">extract_f1</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">unfreeze_end</span> <span class="o">=</span> <span class="mi">20</span><span class="o">+</span><span class="p">(</span><span class="n">num_frozen_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># initial frozen training plus however long it takes to unfreeze the layers. </span>
<span class="n">modelB_unfreeze_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">unfreeze_end</span><span class="p">)</span>

<span class="n">history_unfrozen</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/saved_history_unfrozen.npy&quot;</span><span class="p">)</span>
<span class="n">acc_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_unfrozen</span><span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

<span class="n">recall_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_unfrozen</span> <span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">])</span>
<span class="n">val_f1_score_unfrozen</span><span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">])</span>
<span class="n">modelB_unfrozen_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">unfreeze_end</span><span class="p">,</span> <span class="n">unfreeze_end</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc_unfrozen</span><span class="p">))</span>

<span class="n">combined_data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Synthetic&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">acc_synth</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_acc_synth</span><span class="p">},</span>
        <span class="s1">&#39;Loss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">loss_synth</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_loss_synth</span><span class="p">},</span>
        <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">recall_synth</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_recall_synth</span><span class="p">},</span>
        <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">precision_synth</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_precision_synth</span><span class="p">},</span>
        <span class="s1">&#39;F1 Score&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">f1_score_synth</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_f1_score_synth</span><span class="p">},</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Frozen&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">acc_frozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_acc_frozen</span><span class="p">},</span>
        <span class="s1">&#39;Loss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">loss_frozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_loss_frozen</span><span class="p">},</span>
        <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">recall_frozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_recall_frozen</span><span class="p">},</span>
        <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">precision_frozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_precision_frozen</span><span class="p">},</span>
        <span class="s1">&#39;F1 Score&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">f1_score_frozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_f1_score_frozen</span><span class="p">},</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Gradual Unfreezing&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">acc_values_unfreeze</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_acc_values_unfreeze</span><span class="p">},</span>
        <span class="s1">&#39;Loss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">loss_values_unfreeze</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_loss_values_unfreeze</span><span class="p">},</span>
        <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">recall_values_unfreeze</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_recall_values_unfreeze</span><span class="p">},</span>
        <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">precision_values_unfreeze</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_precision_values_unfreeze</span><span class="p">},</span>
        <span class="s1">&#39;F1 Score&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">f1_values_unfreeze</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_f1_values_unfreeze</span><span class="p">},</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Unfrozen&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">acc_unfrozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_acc_unfrozen</span><span class="p">},</span>
        <span class="s1">&#39;Loss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">loss_unfrozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_loss_unfrozen</span><span class="p">},</span>
        <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">recall_unfrozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_recall_unfrozen</span><span class="p">},</span>
        <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">precision_unfrozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_precision_unfrozen</span><span class="p">},</span>
        <span class="s1">&#39;F1 Score&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">f1_score_unfrozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_f1_score_unfrozen</span><span class="p">},</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">total_epochs</span> <span class="o">=</span> <span class="p">[</span><span class="n">modelB_synth_epochs</span><span class="p">,</span> <span class="n">modelB_frozen_epochs</span><span class="p">,</span> <span class="n">modelB_unfreeze_epochs</span><span class="p">,</span> <span class="n">modelB_unfrozen_epochs</span><span class="p">]</span>
<span class="n">save_filepath</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/saved_figs_modelB/&quot;</span>
<span class="n">plot_grouped_training_progress</span><span class="p">(</span><span class="n">combined_data</span><span class="p">,</span> <span class="n">total_epochs</span><span class="p">,</span> <span class="n">save_filepath</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="transfer-learning-discussion">
<h3>Transfer Learning Discussion<a class="headerlink" href="#transfer-learning-discussion" title="Link to this heading">#</a></h3>
<p>Let’s analyze the trends in the training metrics through each step of the transfer-learning process and work to figure out what is contributing to the model’s behavior.</p>
<section id="synthetic-phase">
<h4>Synthetic Phase<a class="headerlink" href="#synthetic-phase" title="Link to this heading">#</a></h4>
<p>When training on synthetic data for <span class="math notranslate nohighlight">\(10\)</span> training epochs, the model behaves similarly to what we observed when training according to the modelA algorithm. We see that both the training and validatiom measurements for each of the metrics begin at ~<span class="math notranslate nohighlight">\(80\%\)</span> and climb sharply in the first few training epochs, before plateauing slightly around 8 training epochs. This is consistently with how we expected the model to behave, as during this phase it is allowed to freely learn from synthetic data it has never seen before; and thus sharply increases its accuracy, recall, precision, and F1 score before slowing down once it has iterated through the data several times. Curiously, the validation metrics are slighly higher than the training metrics throughout the synthetic phase.</p>
</section>
<section id="frozen-phase">
<h4>Frozen Phase<a class="headerlink" href="#frozen-phase" title="Link to this heading">#</a></h4>
<p>Once the specified number of frozen layers are set to “untrainable”, the model’s metrics drop sharply, with training metrics starting at ~70 and validation metrics charting much lower at ~60%. This makes sense, as through layer freezing we have purposefully temporarily reduced the capabilities of the model and are now introducing it to completely new real data – with new light and noise profiles. Interestingly, over the 10 training epochs we allow the model to train over in this phase, the metrics rise even more dramatically than during the start of the synthetic phase. with training metrics reaching above 95% by the end of the era. Unlike the synthetic phase, validation metrics lag significantly behind, reaching a maximum of ~85% in most cases after 10 epochs. This indicates that the real dataset introduced to <em>DualFinder</em> at this stage is quite different in feature sturcture than the synthetic, so initially the model struggles to identify singles and duals in this dataset, but over a very short amount of time the model learns well from the real images. The freezing of several convolutional layers contributes to the overfitting problem seen in this phase by reducing the number of neurons available to drop out and the effect of L2 regularization on the model.</p>
</section>
<section id="gradual-unfreezing-phase">
<h4>Gradual Unfreezing Phase<a class="headerlink" href="#gradual-unfreezing-phase" title="Link to this heading">#</a></h4>
<p>During this stage the behavior of the model deviates the most from what we’ve previously seen. As the layers are reset to trainable, and the model is allowed to train for 1 epoch per unfreezing, each of the metrics gradually <em>decreases</em> in value while the loss function value <em>increases</em>. This is most pronounced in the validation metrics, which seem to decrease at a faster rate, and are more unstable during this phase. When a layer is unfrozen, the information stored within the neurons – which were not adjusted during prior training – are now partially “overwritten” by values from the real datasets. This results in partial loss of information learned from the synthetic dataset, which contributed towards poorer evaluation metrics. Additionally, because the layers can only be unfrozen in a stepwise fashion, the model experiences sudden “burts” of newly trainable neurons, which may contribute towards the instability seen in the validation metrics. While this phase temporarily negatively impacts the success of the model, it is necessary to allow the model to equally learn from features present in the synthetic dataset and the real dataset. Overall, this will yield a more versitile model that can predict the presence of dual AGN candidates in more diverse datasets.</p>
</section>
<section id="fully-unfrozen-phase">
<h4>Fully Unfrozen Phase<a class="headerlink" href="#fully-unfrozen-phase" title="Link to this heading">#</a></h4>
<p>After all layers are reset to their trainable status, the model is allowed to train freely for <span class="math notranslate nohighlight">\(18\)</span> training epochs. With access to all trainable parameters, the model’s metrics once again increase. This time, however, they start off significantly higher than the previous stage; with the training accuracy, recall, precision, and F1 score starting at <span class="math notranslate nohighlight">\(&gt;96\%\)</span> and achieving nearly 99%. While the validation metrics begin with lower values, they steadily climb as well achieving scores of <span class="math notranslate nohighlight">\(&gt;98%\)</span> over the course of the fully unfrozen phase. The model finishes training with its validation metrics scoring at ~<span class="math notranslate nohighlight">\(98\%\)</span>. We do see some instability in the model’s training during this phase, even though all layers are fully unfrozen. This may be due to inherent variations in the dataset, as well as differences between what the model learned from synthetic data and real data. However, these fluctuations warrant further study and refinement.</p>
<p>Overall, we have demonstrated that for deep CNNs, using transfer-learning techniques to train the model on one dataset, and then retrain it on a separate one (with perhaps fundamentally different structure), is an effective and efficient method to create a model with high accuracy, precision, and recall that is highly adaptable to making predictions in different datasets. There are several different methods that have been developed to increase versitility of the model and fight the overfitting problem we say appear in our training – namely <em>cross validation</em> – that are beyond the scope of this tutorial, but we highly recommend the reader to check out <a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html">this tutorial from scikit-learn</a> that demonstrates the fundamentals of its design and the basics of its implementation.</p>
</section>
</section>
</section>
<section id="hyperparameter-optimization">
<h2>Hyperparameter Optimization<a class="headerlink" href="#hyperparameter-optimization" title="Link to this heading">#</a></h2>
<p>Our revised training procedure helped us improve our model substantially. We see that both our model’s training and validation F1 scores and accuracies reach values of over <span class="math notranslate nohighlight">\(98\%\)</span>. This means our model consistently and accurately is able to detect dual AGN from our vast dataset. We were able to achieve these high-valued metrics by “fine-tuning” our hyperparameters to best suit the model architecture and the dataset structure. During the R&amp;D of this model, we utilized an optimization library called <code class="docutils literal notranslate"><span class="pre">Optuna</span></code>. <code class="docutils literal notranslate"><span class="pre">Optuna</span></code> optimizes hyperparameters by creating an <code class="docutils literal notranslate"><span class="pre">objective</span></code>, in which we define the hyperparameters we seek to optimize and the range we want to optimize them over, the model architecture, and the training scheme we hope to opimize over. Once defined, we pass this <code class="docutils literal notranslate"><span class="pre">objective</span></code> into a <code class="docutils literal notranslate"><span class="pre">study</span></code> object, that uses an optimization algorithm to search the hyperparameter parameter space for parameters that maximimze (in the case of accuracy, F1 score, etc.) or minimize (in the case of loss function) the value of these metrics over several training runs.</p>
<p><code class="docutils literal notranslate"><span class="pre">Optuna</span></code> makes several pre-programmed optimization algorithms available, which include Grid Search, Random Search, and the Tree-structured Parzen Estimator (TPE) algorithm. Grid Search conducts an exhaustive search over the hyperparameter space, testing the effect of as many possible parameters within the time limits of the optimization session. While this method has reduced risk of skipping over an optimal parameter combination, it is incredibly time consuming and may be too computationally expensive if many hyperparameters are being optimized simultaneously. Conversely, Random Search takes a random sample of hyperparamter values from the hyperparameter space and samples over a distribution. The TPE algorithm takes inputted parameters and creates grouped combinations using a Gaussian Mixture Model, an unsupervised ML model that assumes the data is generated using a combination of Gaussians with unknown parameters. Parameter combinations are then sampled from the clustered groups, and the model is trained and evaluated to determine the success of these combinations. TPE is the default algorithm for <code class="docutils literal notranslate"><span class="pre">Optuna</span></code>, as it is efficient at finding hyperparameter values and adaptive to the model’s response to these combinations. However, using an unsupervised machine learning model always introduces some amount of uncertainty into hyperparameter combination determination, which may yield inaccurate combinations if the TPE algorithm gets stuck in local minima in its loss function. Nevertheless, we will use TPE for our example optimization below, as it additionally can handle high-dimension hyperparameter spaces, which allows us to optimize several hyperparameters simultaneously. In our example, we optimize 6 hyperparameters simultaneously:</p>
<p>To setup our optimization run, we created the <code class="docutils literal notranslate"><span class="pre">optimize</span></code> module and the <code class="docutils literal notranslate"><span class="pre">OptimzeHyperparameters</span></code>object, which takes as input a model and its dataset(s), as well as the hyperparameters the user wishes to opimize, and performs an example optimization run using <code class="docutils literal notranslate"><span class="pre">10</span></code> trials. We store the evaluation parameters, as well as their associated hyperparameter combinations, in arrays to be plotted in our <code class="docutils literal notranslate"><span class="pre">visualize_optimization</span></code> function. The optimization run and associated plots are displayed below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trial_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_optimization_trials/&quot;</span>
<span class="n">hyperparameter_optimization</span> <span class="o">=</span> <span class="n">OptimizeHyperparameters</span><span class="p">(</span><span class="n">trial_filepath</span><span class="p">,</span>
                                                      <span class="n">synth_train_dataset</span> <span class="o">=</span> <span class="n">train_dataset_modelB_sim</span><span class="p">,</span> 
                                                      <span class="n">synth_train_labels</span> <span class="o">=</span> <span class="n">train_labels_modelB_sim</span><span class="p">,</span> 
                                                      <span class="n">synth_val_dataset</span> <span class="o">=</span> <span class="n">val_dataset_modelB_sim</span><span class="p">,</span> 
                                                      <span class="n">synth_val_labels</span> <span class="o">=</span> <span class="n">val_labels_modelB_sim</span><span class="p">,</span> 
                                                      <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset_modelB_real</span><span class="p">,</span> 
                                                      <span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_labels_modelB_real</span><span class="p">,</span>
                                                      <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">val_dataset_modelB_real</span><span class="p">,</span>
                                                      <span class="n">val_labels</span> <span class="o">=</span> <span class="n">val_labels_modelB_real</span><span class="p">)</span>
<span class="n">num_trials</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="n">hyperparameter_optimization</span><span class="o">.</span><span class="n">test_study</span><span class="p">(</span><span class="n">num_trials</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;transfer learn&quot;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p>Now let’s create a visual representation of the optimization process to see the TPE optimizer in action. The function above saved the metadata from each optimization run into <code class="docutils literal notranslate"><span class="pre">.csv</span></code> files associated with each trial number. Our <code class="docutils literal notranslate"><span class="pre">VisualizeOptimization</span></code> <code class="docutils literal notranslate"><span class="pre">class</span></code> extracts the values of each hyperparameter – <code class="docutils literal notranslate"><span class="pre">init_learning_rate</span></code>, <code class="docutils literal notranslate"><span class="pre">init_batch_size</span></code>, <code class="docutils literal notranslate"><span class="pre">droput_rate</span></code>, <code class="docutils literal notranslate"><span class="pre">num_frozen_layers</span></code>, <code class="docutils literal notranslate"><span class="pre">unfreeze_learning_rate</span></code>, and <code class="docutils literal notranslate"><span class="pre">unfreeze_batch_size</span></code> – and overlays their evolution over trial number with the <code class="docutils literal notranslate"><span class="pre">best_value</span></code> of the optimziation run, which calculated by <code class="docutils literal notranslate"><span class="pre">best_value</span> <span class="pre">=</span> <span class="pre">1-accuracy</span></code>. As such, a smaller <code class="docutils literal notranslate"><span class="pre">best_value</span></code> means a more accurate model. We display the plots below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trial_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_optimization_trials/&quot;</span>
<span class="n">opt_visualizer</span> <span class="o">=</span> <span class="n">VisualizeOptimization</span><span class="p">(</span><span class="n">trial_filepath</span><span class="p">)</span>
<span class="n">opt_visualizer</span><span class="o">.</span><span class="n">plot_best_params</span><span class="p">(</span><span class="n">num_trials</span> <span class="o">=</span> <span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="optimization-discussion">
<h3>Optimization Discussion<a class="headerlink" href="#optimization-discussion" title="Link to this heading">#</a></h3>
<p>Through our brief optimization tutorial, we were able to find a combination of hyperparameters that yields a model with an optimization score of <span class="math notranslate nohighlight">\(&lt; 0.01\)</span>, corresponding to an accuracy estimate of <span class="math notranslate nohighlight">\(&gt;99\%\)</span>. We cannot see much evidence of convergence for the <code class="docutils literal notranslate"><span class="pre">best_value</span></code> score and the other hyperparameters in the plots above, mostly because we sought to optimize our model over relatively few trials (~7). As such, the TPE algorithm does not have much of an opportunity to converge on optimal hyperparameter combinations. Given more time, we may see some convergence in the hyperparameters – particularly the learning rate – and the optimization score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pwd
<span class="kn">from</span> <span class="nn">extract_feature_maps</span> <span class="kn">import</span> <span class="n">create_gif</span>
<span class="n">gif_save_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_models_example_modelB/feature_map_progress/animated_feature_map.gif&quot;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">exists</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/feature_map_progress/&quot;</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/feature_map_progress/&quot;</span><span class="p">)</span>
<span class="n">fm_filepath</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/feature_maps/saved_models_example_modelB/&quot;</span>
<span class="n">create_gif</span><span class="p">(</span><span class="n">fm_filepath</span><span class="p">,</span> <span class="n">gif_save_filepath</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">gif_save_filepath</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h3>
<p>In this notebook, we have described the structure of convolutional neural networks through the example of <em>DualFinder</em> and the role each component plays in allowing the model to “learn” from training data and be able to classify an image based on these learned features. We discussed two possible training algorithms. In <strong>modelA</strong>, all of the training data is used simultaneously, and in <strong>modelB</strong>, the model is first trained on synthetic data, and then is trained on our real dataset using transfer learning techniques. We analyzed how the choice of different hyperparameters affected the performance of the model, as well as the effect of different training procedure on model efficacy and versitility. Finally, we created an <code class="docutils literal notranslate"><span class="pre">Optuna</span></code> hyperparameter optimization algorithm that test the choice of several hyperparameters on the model’s training over several trials, and plotted the value of these hyperparameters – as well as the model’s optimziation score – to demonstrate how <code class="docutils literal notranslate"><span class="pre">Optuna</span></code>’s TPE algorithm works in action.</p>
<p>As machine learning techniques become an increasingly useful tool for us as astrophysicists to use in our data analysis, understanding the science behind why algorithms like CNNs work so well and how they can be applied to astrophysical data is essential to effectively use them in tandem with expert analysis to make remarkable discoveries and learn new information about our universe. Thank you for working though this notebook!</p>
</section>
<section id="works-cited-and-libaries-used">
<h3>Works Cited and Libaries Used.<a class="headerlink" href="#works-cited-and-libaries-used" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Jadon Shruti (2018)., “Introduction to Different Activation Functions for Deep Learning”., Medium., <a class="reference external" href="https://medium.com/shrutijadon/survey-on-activation-functions-for-deep-learning-9689331ba092">https://medium.com/shrutijadon/survey-on-activation-functions-for-deep-learning-9689331ba092</a></p></li>
<li><p>van Dijk, David., “Lecture 2: Supervised Learning”, Lecture, Yale University., New Haven, CT, January 18, 2024.</p></li>
<li><p>Abadi, et al. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from <a class="reference external" href="http://tensorflow.org">tensorflow.org</a>.</p></li>
<li><p>Pedregosa, F., Varoquaux, G., Gramfort, A., et al. 2011,
Journal of Machine Learning Research, 12, 2825</p></li>
<li><p>Astropy: Astropy Collaboration et al. (2013)</p></li>
<li><p>Optuna hyperparameter optimization framework: Akiba
et al. (2019)</p></li>
</ol>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#author-isaac-moskowitz">Author: Isaac Moskowitz</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#professor-earl-p-bellinger">Professor Earl P. Bellinger</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#astr-330-scientific-computing-in-astrophysics">ASTR 330: Scientific Computing in Astrophysics.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-project">Final Project.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing-and-packaging">Data Preprocessing and Packaging</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-structure">Dataset Structure</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#synthetic-images">Synthetic Images</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#real-and-composite-images">Real and “Composite” Images</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-and-design-of-dualfinder">Architecture and Design of <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conv2d-and-maxpooling2d-layers"><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> and <code class="docutils literal notranslate"><span class="pre">MaxPooling2d</span></code> Layers.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-functions">Activation Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dropout-regularization-and-batchnormalization"><code class="docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">Regularization</span></code>, and <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code>.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compiling-dualfinder">Compiling <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-learning-rate">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-batch-size">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">batch_size</span></code></a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-dropout">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">dropout</span></code></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-dualfinder">Training <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-metrics">Model Metrics</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-proceedure">Training Proceedure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-one-discussion">Training Run One Discussion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-two-revised-hyperparameters">Training Run Two: Revised Hyperparameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-two-results-revised-hyperparameters">Training Run Two Results: Revised Hyperparameters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">Transfer Learning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-results-transfer-learning">Training Results: Transfer Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning-discussion">Transfer Learning Discussion</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#synthetic-phase">Synthetic Phase</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#frozen-phase">Frozen Phase</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#gradual-unfreezing-phase">Gradual Unfreezing Phase</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#fully-unfrozen-phase">Fully Unfrozen Phase</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-optimization">Hyperparameter Optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-discussion">Optimization Discussion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#works-cited-and-libaries-used">Works Cited and Libaries Used.</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Isaac Moskowitz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>