
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>How to Train Your Neural Net: A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes. &#8212; How to Train Your Neural Net, A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes.</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'ASTR330_Final_Project_Jupyter';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="How to Train Your Neural Net, A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes. - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="How to Train Your Neural Net, A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes. - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="markdown.html">Markdown Files</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks.html">Content with notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="markdown-notebooks.html">Notebooks with MyST Markdown</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/iam37/DualFinder.git/main?urlpath=tree/dual_finder_book/ASTR330_Final_Project_Jupyter.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/iam37/DualFinder.git" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/iam37/DualFinder.git/issues/new?title=Issue%20on%20page%20%2FASTR330_Final_Project_Jupyter.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/ASTR330_Final_Project_Jupyter.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>How to Train Your Neural Net: A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes.</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">How to Train Your Neural Net: A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes.</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#author-isaac-moskowitz">Author: Isaac Moskowitz</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#professor-earl-p-bellinger">Professor Earl P. Bellinger</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#astr-330-scientific-computing-in-astrophysics">ASTR 330: Scientific Computing in Astrophysics.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-project">Final Project.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing-and-packaging">Data Preprocessing and Packaging</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-structure">Dataset Structure</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#synthetic-images">Synthetic Images</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#real-and-composite-images">Real and “Composite” Images</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-and-design-of-dualfinder">Architecture and Design of <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conv2d-and-maxpooling2d-layers"><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> and <code class="docutils literal notranslate"><span class="pre">MaxPooling2d</span></code> Layers.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-functions">Activation Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dropout-regularization-and-batchnormalization"><code class="docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">Regularization</span></code>, and <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code>.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compiling-dualfinder">Compiling <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-learning-rate">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-batch-size">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-dropout">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">dropout</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-dualfinder">Training <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-metrics">Model Metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-proceedure">Training Proceedure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-one-discussion">Training Run One Discussion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-two-revised-hyperparameters">Training Run Two: Revised Hyperparameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-two-results-revised-hyperparameters">Training Run Two Results: Revised Hyperparameters</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">Transfer Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-results-transfer-learning">Training Results: Transfer Learning</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-optimization">Hyperparameter Optimization</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="how-to-train-your-neural-net-a-comprehensive-guide-to-designing-and-training-convolutional-neural-networks-for-astrophysical-purposes">
<h1>How to Train Your Neural Net: A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes.<a class="headerlink" href="#how-to-train-your-neural-net-a-comprehensive-guide-to-designing-and-training-convolutional-neural-networks-for-astrophysical-purposes" title="Link to this heading">#</a></h1>
<section id="author-isaac-moskowitz">
<h2>Author: Isaac Moskowitz<a class="headerlink" href="#author-isaac-moskowitz" title="Link to this heading">#</a></h2>
</section>
<section id="professor-earl-p-bellinger">
<h2>Professor Earl P. Bellinger<a class="headerlink" href="#professor-earl-p-bellinger" title="Link to this heading">#</a></h2>
<section id="astr-330-scientific-computing-in-astrophysics">
<h3>ASTR 330: Scientific Computing in Astrophysics.<a class="headerlink" href="#astr-330-scientific-computing-in-astrophysics" title="Link to this heading">#</a></h3>
</section>
<section id="final-project">
<h3>Final Project.<a class="headerlink" href="#final-project" title="Link to this heading">#</a></h3>
</section>
</section>
</section>
<section id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h1>
<p>In the past few years, machine learning and artificial intelligence have become incredibly useful and popular tools for scientific analysis, serving as a type of virtual research assistant that can probe and analyze large datasets to assist and help advance human scientific discoveries. Research in astrophysics often involves analyzing huge datasets, with the newly-launched Roman and Euclid satellites expected to output terabytes of data <em>per day</em>, these datasets have grown exponetially. Machine learning frameworks are fantastic tools that astrophysicists can use to study these datasets in a comprehensive way that will lead to new discoveries and new answers to some of the biggest current questions of our field. Nevertheless, desiging and training these models to best perform a given data analysis task is a difficult and confusing endeavour (speaking from personal experience). That is why I have created this Juypter Notebook as a tutorial on how to design, train, test, and optimize a convolutional neural network for an image recognition task in astronomy. We will be using the CNN <em>DualFinder</em>, a network I and my collegues in Professor Meg Urry’s research group at Yale University designed to detect dual AGN candidates in large sky survey fields. The results of using this model on Hyper-Suprime Cam, Hubble Space Telescope, and Euclid data will be publically available through Moskowitz <em>et al.</em> (in preparation). This notebook goes through the steps of creating and loading in the training and testing datasets, desiging the model architecture to fit our image identification task, creating a training schema for our model, the effect of hyperparameters on a model’s training success, the effect of two different training procedures on the model’s ability to detect dual AGN, and the process of optimizing hyperparameters. The training data, data preparation codes, model design codes, model training codes, training visualization codes, and model optimization codes are available under the package <code class="docutils literal notranslate"><span class="pre">dual_finder</span></code> provided on my GitHub page along with this tutorial.</p>
<p><strong>Disclaimer:</strong> This tutorial has cells that train the model, which requires GPU compatibility. We have provided functionallity that displays the results of previously-executed training runs in the cells immediately succeeding training cells. Additionally, because of the size of the training dataset, the <code class="docutils literal notranslate"><span class="pre">dual_finder</span></code> package will require substantial free storage space to download.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">streamlit</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">tqdm</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">listdir</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">isfile</span><span class="p">,</span> <span class="n">join</span>
<span class="kn">from</span> <span class="nn">os.path</span> <span class="kn">import</span> <span class="n">exists</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="c1">#!pwd</span>
<span class="c1">#from spectral_cube import SpectralCube</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="data-preprocessing-and-packaging">
<h1>Data Preprocessing and Packaging<a class="headerlink" href="#data-preprocessing-and-packaging" title="Link to this heading">#</a></h1>
<p>Astrophysical data can come in many different varieties. We often work with <code class="docutils literal notranslate"><span class="pre">FITS</span></code> files for image data, <code class="docutils literal notranslate"><span class="pre">FITS</span></code> tables for numerical data, and data cubes for spectra, among a myriad of other filetypes. Preprocessing your data in a way that you can use effectively to train and test your neural network is essential to tailoring the network to handle your given task as well as yield accurate predictions. In this demonstration, we will be working with image data, as is common with computer vision problems solved with neural networks. More specifically, we will be working with images of quasar (QSO) objects taken by the Hyper-Suprime Cam on the Subaru Telescope at Mauna Kea, HI. This telescope has a resolution of approximately <span class="math notranslate nohighlight">\(0.4\)</span> arcsecond, which makes it well suited for preliminary studies of dual AGN with (semi) large separations on the order of tens of kiloparsecs.</p>
<p>We accessed our data directly from the HSC Public Data Release 3 (PDR3) catalogue to be <span class="math notranslate nohighlight">\(16^&quot; \times 16^&quot;\)</span>, chosen to capture potential dual AGN candidates that may be separated by up to 3.5 arcseconds, but small enough so as to not also collect other point-source objects (such as stars) in that region of the sky. The cutouts returned by HSC’s data retrieval system are not uniform, and so our first preprocessing step is to reshape all objects to be of the same shape.</p>
<section id="dataset-structure">
<h2>Dataset Structure<a class="headerlink" href="#dataset-structure" title="Link to this heading">#</a></h2>
<p>Before we dive into how to process data for <code class="docutils literal notranslate"><span class="pre">DualFinder</span></code>, we must first discuss the structure of our example dataset. We trained <code class="docutils literal notranslate"><span class="pre">DualFinder</span></code> on two datasets of sample single and dual AGN – one made of synthetic images and the other made of real images.</p>
<section id="synthetic-images">
<h3>Synthetic Images<a class="headerlink" href="#synthetic-images" title="Link to this heading">#</a></h3>
<p>We create our synthetic images by first modeling a point-source light profile with a Moffat model [INSERT RERFERENCE] and Gaussian noise, then convolving the image with a real PSF from HSC to best model the noise and light profiles that would be captured in real images from HSC. We created approximately 55,000 of these images</p>
</section>
<section id="real-and-composite-images">
<h3>Real and “Composite” Images<a class="headerlink" href="#real-and-composite-images" title="Link to this heading">#</a></h3>
<p>While we modeled our synthetic images as closely as possible to real HSC images, there is no way to capture exactly all of the image exentricities (such as its noise and light profiles) in a simulated image. As such, in order to create a model that can effectively detect dual AGN candidates in real images, it must be trained on real images. There are many images of single AGN available in HSC PDR3. However, there are very few images of real confirmed dual AGN, which is the motivation behind why this network was developed. As such, we have a bit of a cart-and-horse problem, as we cannot effectively train our model without these real images, but we need this model to find these images in the first place. Our work-around for this problem was to create so-called <em>composite</em> images to model dual AGN. We created composite images by combining two confirmed single poit-source AGN into a single image, capturing inherent variability in orientation and relative brightness by selecting one of the point-sources as the “center” (and placing it at the center of the image) and the other as the “companion” (and rotating it about the center for arbitrary angles) and by reducing the flux of one of the sources by a given percentage value before combining into a single image. This method allowed us to make an arbitrarily large dataset of images that visually represented dual AGN without needing to find a large sample of true dual AGN candidates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># from dual_finder.preprocess_data.process_data import create_dataset</span>
<span class="kn">import</span> <span class="nn">importlib</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="c1">#!pwd</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;dual_finder/dual_finder&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">reload_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
<span class="c1">#sys.path.append(&quot;dual_finder/dual_finder/preprocess_data/&quot;)</span>
<span class="c1">#os.chdir(&quot;dual_finder/dual_finder/preprocess_data/&quot;)</span>
<span class="c1">#sys.path.append(&quot;dual_finder/dual_finder/cnn/&quot;)</span>
<span class="c1">#sys.path.append(&quot;dual_finder/dual_finder/visualize/&quot;)</span>
<span class="c1">#sys.path.append(&quot;dual_finder/dual_finder/optimize/&quot;)</span>
<span class="c1">#os.chdir(&quot;/vast/palmer/scratch/urry/iam37/astr330&quot;)</span>
<span class="c1">#os.chdir(&quot;dual_finder/dual_finder/cnn/&quot;)</span>
<span class="c1">#os.chdir(&quot;dual_finder/dual_finder&quot;)</span>
<span class="o">!</span>pwd
<span class="kn">from</span> <span class="nn">preprocess_data.process_data</span> <span class="kn">import</span> <span class="n">create_dataset</span>

<span class="kn">from</span> <span class="nn">preprocess_data.fits_utils</span> <span class="kn">import</span> <span class="n">modified_plot_image</span> <span class="k">as</span> <span class="n">plot_image</span><span class="p">,</span> <span class="n">plot_dataset_sample</span>

<span class="kn">from</span> <span class="nn">cnn.create_cnn</span> <span class="kn">import</span> <span class="n">ModelCreator</span>

<span class="kn">from</span> <span class="nn">cnn.load_model</span> <span class="kn">import</span> <span class="n">loadModelClass</span>

<span class="kn">from</span> <span class="nn">cnn.train_cnn</span> <span class="kn">import</span> <span class="n">DualFinder</span>

<span class="kn">from</span> <span class="nn">cnn.extract_feature_maps</span> <span class="kn">import</span> <span class="n">FeatureExtractor</span>

<span class="kn">from</span> <span class="nn">optimize.optimize_hyperparameters</span> <span class="kn">import</span> <span class="n">OptimizeHyperparameters</span>
<span class="kn">from</span> <span class="nn">visualize.visualize_performance</span> <span class="kn">import</span> <span class="n">load_training_history</span><span class="p">,</span> <span class="n">plot_training_progress</span><span class="p">,</span> <span class="n">plot_grouped_training_progress</span><span class="p">,</span> <span class="n">VisualizeOptimization</span>

<span class="c1">#os.chdir(&quot;/vast/palmer/scratch/urry/iam37/astr330&quot;)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/moskowitzi/Desktop/Junior_Year_at_Yale/Spring_Semester/ASTR_330/final_project_git_repo/DualFinder/dual_finder_book
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">line</span> <span class="mi">18</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="c1">#sys.path.append(&quot;dual_finder/dual_finder/preprocess_data/&quot;)</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="c1">#os.chdir(&quot;dual_finder/dual_finder/preprocess_data/&quot;)</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span> <span class="c1">#sys.path.append(&quot;dual_finder/dual_finder/cnn/&quot;)</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">15</span> <span class="c1">#os.chdir(&quot;dual_finder/dual_finder/cnn/&quot;)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="c1">#os.chdir(&quot;dual_finder/dual_finder&quot;)</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s1">&#39;pwd&#39;</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">18</span> <span class="kn">from</span> <span class="nn">preprocess_data.process_data</span> <span class="kn">import</span> <span class="n">create_dataset</span>
<span class="g g-Whitespace">     </span><span class="mi">20</span> <span class="kn">from</span> <span class="nn">preprocess_data.fits_utils</span> <span class="kn">import</span> <span class="n">modified_plot_image</span> <span class="k">as</span> <span class="n">plot_image</span><span class="p">,</span> <span class="n">plot_dataset_sample</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span> <span class="kn">from</span> <span class="nn">cnn.create_cnn</span> <span class="kn">import</span> <span class="n">ModelCreator</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;preprocess_data&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The following script loads &quot;model B&quot; data, which is split between synthetic and real datasets</span>
<span class="n">X_train_1</span><span class="p">,</span> <span class="n">X_val_1</span><span class="p">,</span> <span class="n">X_train_2</span><span class="p">,</span> <span class="n">X_val_2</span><span class="p">,</span> <span class="n">train_modelA</span><span class="p">,</span> <span class="n">val_modelA</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="n">train_dataset_modelB_sim</span><span class="p">,</span> <span class="n">train_labels_modelB_sim</span> <span class="o">=</span> <span class="n">X_train_1</span>
<span class="n">val_dataset_modelB_sim</span><span class="p">,</span> <span class="n">val_labels_modelB_sim</span> <span class="o">=</span> <span class="n">X_val_1</span>
<span class="n">train_dataset_modelB_real</span><span class="p">,</span> <span class="n">train_labels_modelB_real</span> <span class="o">=</span> <span class="n">X_train_2</span>
<span class="n">val_dataset_modelB_real</span><span class="p">,</span> <span class="n">val_labels_modelB_real</span> <span class="o">=</span> <span class="n">X_val_2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30000/30000 [00:07&lt;00:00, 4277.17it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24266/24266 [00:05&lt;00:00, 4300.48it/s]
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:05&lt;00:00,  2.39it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Compiling: confirmed_single_AGN_spring
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0it [00:00, ?it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Compiling: confirmed_single_AGN_fall
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 991/991 [00:00&lt;00:00, 1577.47it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of composite images: (25258, 60, 60, 1)
Shape of all single real AGN images: (991, 60, 60, 1)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>991it [00:04, 216.29it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of augmented single images: (15856, 60, 60)
shape of augmented single images:  (15856, 60, 60, 1)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15856/15856 [00:00&lt;00:00, 7780168.95it/s]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>modelB_labels_real: [&#39;single AGN&#39; &#39;single AGN&#39; &#39;single AGN&#39; ... &#39;double AGN&#39; &#39;double AGN&#39;
 &#39;double AGN&#39;]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of real model B training data: (30835, 60, 60, 1)
Shape of real model B training labels: (30835,)
Shape of real model B validation data: (10279, 60, 60, 1)
Shape of real model B validation labels: (10279,)
Shape of simulated model B training data: (40699, 60, 60, 1)
Shape of simulated model B training labels: (40699,)
Shape of simulated model B validation data: (13567, 60, 60, 1)
Shape of simulated model B validation labels: (13567,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This script creates &quot;model A&quot; data, which concatenates synthetic and real datasets for the model to train on simultaneously.</span>
<span class="n">train_dataset_modelA</span><span class="p">,</span> <span class="n">train_labels_modelA</span> <span class="o">=</span> <span class="n">train_modelA</span>
<span class="n">val_dataset_modelA</span><span class="p">,</span> <span class="n">val_labels_modelA</span> <span class="o">=</span> <span class="n">val_modelA</span>
</pre></div>
</div>
</div>
</div>
<p>Lets visually inspect our dataset. We will use the plotting function designed in ASTR 330 Lab 3 to display a randomly selected simulated single and double AGN, a real single AGN, and a composite AGN.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Synthetic images</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">val_dataset_modelB_sim</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">val_labels_modelB_sim</span><span class="p">))</span>
<span class="c1">#print(val_labels_modelB_sim[345])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">val_labels_modelB_sim</span> <span class="o">==</span> <span class="s1">&#39;single AGN&#39;</span><span class="p">))[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">((</span><span class="n">val_labels_modelB_real</span> <span class="o">==</span> <span class="s1">&#39;single AGN&#39;</span><span class="p">))[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_dataset_sample</span><span class="p">(</span><span class="n">val_dataset_modelB_sim</span><span class="p">,</span> <span class="n">val_labels_modelB_sim</span><span class="p">,</span> 
                    <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Randomly Selected Synthetic Single AGN&quot;</span><span class="p">,</span> <span class="n">AGN_type</span> <span class="o">=</span> <span class="s2">&quot;single AGN&quot;</span><span class="p">)</span>
<span class="n">plot_dataset_sample</span><span class="p">(</span><span class="n">val_dataset_modelB_sim</span><span class="p">,</span> <span class="n">val_labels_modelB_sim</span><span class="p">,</span> 
                    <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Randomly Selected Synthetic Double AGN&quot;</span><span class="p">,</span> <span class="n">AGN_type</span> <span class="o">=</span> <span class="s2">&quot;double AGN&quot;</span><span class="p">)</span>

<span class="c1"># Real images</span>
<span class="n">plot_dataset_sample</span><span class="p">(</span><span class="n">val_dataset_modelB_real</span><span class="p">,</span> <span class="n">val_labels_modelB_real</span><span class="p">,</span> 
                    <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Randomly Selected Real Single AGN&quot;</span><span class="p">,</span> <span class="n">AGN_type</span> <span class="o">=</span> <span class="s2">&quot;single AGN&quot;</span><span class="p">)</span>
<span class="n">plot_dataset_sample</span><span class="p">(</span><span class="n">val_dataset_modelB_real</span><span class="p">,</span> <span class="n">val_labels_modelB_real</span><span class="p">,</span> 
                    <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Randomly Selected Composite AGN&quot;</span><span class="p">,</span> <span class="n">AGN_type</span> <span class="o">=</span> <span class="s2">&quot;double AGN&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(13567, 60, 60, 1)
(13567,)
[    0     1     2 ... 13560 13561 13566]
[    0     1     6 ... 10270 10274 10277]
1
</pre></div>
</div>
<img alt="_images/95925979b071a224a7a984e1477294390ada726e1486be9da330796dfa2c7722.png" src="_images/95925979b071a224a7a984e1477294390ada726e1486be9da330796dfa2c7722.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1
</pre></div>
</div>
<img alt="_images/18528d644dc0a100cc60d1821c0ba4a1664ff2abf445e523dfeafedc05bd7f83.png" src="_images/18528d644dc0a100cc60d1821c0ba4a1664ff2abf445e523dfeafedc05bd7f83.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1
</pre></div>
</div>
<img alt="_images/ae6c1e43259f46fde13d3e7a417888a6aef03d62e527496e8457ce8eda1d966a.png" src="_images/ae6c1e43259f46fde13d3e7a417888a6aef03d62e527496e8457ce8eda1d966a.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1
</pre></div>
</div>
<img alt="_images/8fd65fb634a7f5adc81f0cc102aeccaea4989c54a08017b2b4ff338935a68cfe.png" src="_images/8fd65fb634a7f5adc81f0cc102aeccaea4989c54a08017b2b4ff338935a68cfe.png" />
</div>
</div>
</section>
</section>
<section id="architecture-and-design-of-dualfinder">
<h2>Architecture and Design of <em>DualFinder</em><a class="headerlink" href="#architecture-and-design-of-dualfinder" title="Link to this heading">#</a></h2>
<p><em>DualFinder</em> is a deep convolutional neural network with four convolutional layers, three fully connected layers, and an output layers with two neurons representing the two possible classes for our binary classification task: <strong>single AGN</strong> and <strong>dual AGN</strong>.</p>
<section id="conv2d-and-maxpooling2d-layers">
<h3><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> and <code class="docutils literal notranslate"><span class="pre">MaxPooling2d</span></code> Layers.<a class="headerlink" href="#conv2d-and-maxpooling2d-layers" title="Link to this heading">#</a></h3>
<p>Following the structures of the AlexNET (Krizhevsky <em>et al</em> 2012), VGG6 (Simonyan &amp; Zisserman 2014), and GaMorNet (Ghosh <em>et al</em> 2020), we begin our model with an input layer of filter size <span class="math notranslate nohighlight">\(96\)</span>. The filter in a convolutional layer is a matrix of weights that are applied iteratively to elemenents in the inputted image as the network “strides” over the two-dimensional grayscale image. Our CNN multiplies the weights in this filter to the imput values of each element in the image that is contained within our filter, sums up the result, outputs it to a single pixel in the next layer, and repeats this process over the entire image in several steps, or <strong>strides</strong>. The size of the stride indicates how many pixels the filter is moved before it is applied again. Consequently, the stride size informs the amount of downsampling the model performs form layer to layer. A larger stride size will lead to more downsampling. CNNs of similar architectures to <em>DualFinder</em> are designed to reduce the dimensionality of the inputted images to capture the pixels that produce maximum values when multiplied by the weights in our filter, which is often indicates that the model has captured the most important information in the image. In practice, the model accomplishes this downsampling through the use of a <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> layer, which sums up the values in the filter and outputs them to the next layer. We repeat this process for three additional <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> layers past our input, with the filter size increasing in each layer to help the model capture finer details in the image. The larger the filter size, the larger the weight matrix and therefore more pixels “make the cut” from downsampling into the next round, and thus more small-scale structure is preserved. We intenionally set our initial filter size to be relatively small because we want the model to discover large scale repeated structure first before it learns from finer details in each image. This is done to prevent the model from recognizing background noise, contaminant sources, or fluctuations in the seeing of a given image as essential for classification, and to encourage the model to identify patterns – such as the presence of one (or two!) bright circular objects near the centers of each image. Our last convolutional layer has a filter size of <span class="math notranslate nohighlight">\(384\)</span>, which was empirically tested yield high-valued metrics in GaMorNet (Ghosh <em>et al</em>. 2020). We include a <code class="docutils literal notranslate"><span class="pre">for</span></code> loop that adds a given number <code class="docutils literal notranslate"><span class="pre">num_layers</span></code> of layers of this size. We fine-tune <code class="docutils literal notranslate"><span class="pre">num_layers</span></code> as a hyperparameter to measure its effect on the model’s success. Once the data has been downsized through these layers, we flatten the layer and allow all neurons to be fully connected to those in the previous layer through the use of a <code class="docutils literal notranslate"><span class="pre">Dense</span></code> class fully connected layer. This allows the model to retail the <em>most important</em>, or high level, information from the image and pass it to the final output layer, with two output neurons representing the “single AGN” and “double AGN” classes for prediction.</p>
</section>
</section>
<section id="activation-functions">
<h2>Activation Functions<a class="headerlink" href="#activation-functions" title="Link to this heading">#</a></h2>
<p>In a CNN, the value a neuron takes on is multiplied by a matrix of weights <span class="math notranslate nohighlight">\(w_i\)</span>, the result of which is added to a bias term <span class="math notranslate nohighlight">\(b_i\)</span> and passed through a function to give an output to the neuron, which in a fully connected layer is sent to every neuron in the next layer, and in a convolutional layer is summed with other outputs within the filter and subsequently given to the following layer. Mathematically, this process is modeled by $<span class="math notranslate nohighlight">\(y_i(x) = \sum^{N}_{i = 1}f(w_i \cdot x_i + b_i)\)</span><span class="math notranslate nohighlight">\(
where \)</span>N<span class="math notranslate nohighlight">\( is the total number of neurons in each layer. The function \)</span>f<span class="math notranslate nohighlight">\( is our *activation function* and it is essential for regulating neuron outputs to the next layer. Although the equation above is a linear transformation, these functions – along with the weight matricies – introduce non-linearity into the model essential for the model to make novel predictions and learn from the dataset. There are several activation functions available in the `Tensorflow` library which have their benefits and drawbacks for different machine learning tasks and purposes. We use the `leaky_relu` function, an adaptation of the popular ReLU (Rectified Liner Unit) function. In the ReLU function, neurons with negative values are set to zero, and neurons with positive values preserve their outputs and are passed onto the next layer. This model gained popularity over the earlier *sigmoid* function, which maps the output of a neuron to \)</span>0<span class="math notranslate nohighlight">\( for large negative outputs or \)</span>1$ for large positive outputs, because of its simplicity (as it is a piecewise linear function), its computational efficiency, and its ability to preserve useful information from the neuron by outputing its value without correction to the next layer. Nevertheless,  models using ReLU often suffer from the “dying ReLU” problem, wherby setting the output of a neuron with a negative value has rendered it dormant and therefore does not take part in the rest of the training process. This leads to loss of information and instability while training the model. There have been several activation functions developed to combat this problem, including the <code class="docutils literal notranslate"><span class="pre">leaky_relu</span></code> function, which allows for small negative outputs to be passed onto the next layer. Some of the most popular activation functions and there graphs are plotted below. <img alt="Activation Functions" src="markdown_images/activation_functions.png" /> (Image credit: Jadon Shruti (2018)., “Introduction to Different Activation Functions for Deep Learning”., <em>Medium</em>., <a class="reference external" href="https://medium.com/&#64;shrutijadon/survey-on-activation-functions-for-deep-learning-9689331ba092">https://medium.com/&#64;shrutijadon/survey-on-activation-functions-for-deep-learning-9689331ba092</a>)</p>
<p>Our final output layer uses the <code class="docutils literal notranslate"><span class="pre">softmax</span></code> activivation function, which is well-suited for categorical probability predictions because all of the component predictions that are created by the function must sum to 1 (there is a 100% probability that the model will predict <em>something</em>). We are treating our binary classification problem as a multi-class classification scheme with only two classes. We could’ve also represented our task as purely binary – in which case, we would have one output layer where the value of the neuron represents the probability that the image belongs to the positive class (<span class="math notranslate nohighlight">\(0\)</span> represents no chance, and therefore the negative class). Both methods are equally valid ways of desiging the model, however, we intend to adjust our model architecture to account for three or more classes of images in future development, so using a categorical classification scheme allows us to more easily scale up the number of classes predicted by the model.</p>
</section>
<section id="dropout-regularization-and-batchnormalization">
<h2><code class="docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">Regularization</span></code>, and <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code>.<a class="headerlink" href="#dropout-regularization-and-batchnormalization" title="Link to this heading">#</a></h2>
<p><em>DualFinder</em> also contains several non-trainable layers that are dispersed between the <code class="docutils literal notranslate"><span class="pre">Conv2D</span></code>, <code class="docutils literal notranslate"><span class="pre">MaxPooling2D</span></code> and <code class="docutils literal notranslate"><span class="pre">Dense</span></code> layers within the model. Together, the <code class="docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">Regularization</span></code> and <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code> layers are designed to prevent the model from <em>overfitting</em> to the dataset. If a CNN is too deep of a network, it can achieve very high metrics when training on training data, but when tested on validation data, the model demonstrates poor performance. This is the “overfitting” problem, and it arises in very deep models where because of its complexity and learning capacity the model essentially “memorizes” the structure of the training data, down to its finest details, but doesnt learn the overall patterns well. So when presented with new data, it cannot recognize any patterns that are indicative of a class and therefore does not perform well. Because of the size of our model, overfitting remains an important problem with the model to monitor and fight against during training and testing, so lets go over the tools in our arsenal that help us prevent it.</p>
<p><code class="docutils literal notranslate"><span class="pre">Dropout</span></code>: The technique of dropout involves randomly selecting a certain percentage of neurons and setting them to be untrainable (therefore “dropping them out”) during training. This introduces uncertainty in the model and purposeful loss of information, which enables the model to learn the larger-scale patterns of an image more effectively and therefore apply them to new data.</p>
<p><code class="docutils literal notranslate"><span class="pre">Regularization</span></code>: L2 regularization involves applying a “penalty term” to the loss function that is the sum of the squares of the weights of the model. As such, the new loss function, with L2 regularization, is given by,
$<span class="math notranslate nohighlight">\( L = L_0 + \lambda \sum_{j = 1}^{N}(w_j)\)</span><span class="math notranslate nohighlight">\( 
where \)</span>L_0<span class="math notranslate nohighlight">\( is the original loss function (in our case, categorical crossentropy) and \)</span>\lambda<span class="math notranslate nohighlight">\( represents how much importance regularization has in the calculation of the loss function. \)</span>\lambda$ is an adjustable hyperparameter that is fine-tuned with training runs. While the loss function is minimized during training, the introduction of L2 regularization tends to decay the weights to near zero (but crucially non-zero) values. This allows the weights to be dominated by outputs from features of the image, and less affected by background noise, which leads to better applicability of the model to new data and therefore less overfitting.</p>
<p><code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code>: Batch normalization serves many purposes in regulating model training, from stabilizing gradient descent to reducing CNN training times by fascilitating faster loss function convergence, and generally is a method that improves the stability and versatility of the model. It does so by slightly adjusting the activation function of a given layer such that the mean output of the function is <span class="math notranslate nohighlight">\(0\)</span> and its standard deviation is <span class="math notranslate nohighlight">\(1\)</span> over a given image batch. This process introduces a small amount of noise via random variations caused by the normalization to the model outputs, which in turn helps prevent the model from memorizing the noise profiles of the dataset.</p>
<p>Putting it all together, we show a schematic diagram of <em>DualFinder</em> below, which highlights some of the key components (such as the convolutional layers, dropout layers, and fully connected layers) of the model’s architecture. <img alt="DualFinder Diagram" src="markdown_images/structure_of_dual_finder.png" /></p>
<p>All of these components of the model work together, often in ways unknown to us as the user due to the highly non-linear structure of the network, to extract features from the dataset and learn how they correlate to the given labels, so that once fully trained, the model can effectively discover similar images based on the presence (or lack thereof) of these features in new images.</p>
</section>
<section id="compiling-dualfinder">
<h2>Compiling <em>DualFinder</em><a class="headerlink" href="#compiling-dualfinder" title="Link to this heading">#</a></h2>
<p>Once we have preprocessed our data, we are ready to compile and train our model. Our model contained over 9 million trainable parameters, and countless connections between neurons that makes the calculations of weights and biases a highly non-linear problem. As such, we cannot rely on familiar algorithms such as <span class="math notranslate nohighlight">\(\chi^2\)</span> minimization or even Markov Chain Monte Carlo (MCMC) simulations to arrive at optimial weights and biases for our dataset.</p>
<p>Enter <em>Stochastic Gradient Descent</em> (SGD). SGD projects our optimizable parameters into a high-dimensional parameter space according to the outputs of the binary cross-entropy loss function. This space is a complicated surface with many peaks and valleys that is difficult to visualize, as for most machine-learning applications, usually has a higher dimension than the three we can easily visualize. Nevertheless, algorithms employing SGD are specially designed to handle this multidimensionality. It calculates the gradient at a particular point, corresponding to a combination of weight and bias values, and adjusts these weights so as to “travel” along the gradient (which we know from multivariable calculus represents the path of greatest ascent/descent” towards the <strong>global minimum</strong> of the loss function parameter space. For our model, we use a modern version of SGD called <code class="docutils literal notranslate"><span class="pre">Adam</span></code>, which is an adaptive SGD algorithm that continually calculates the <em>momentum</em> of the gradient descent. In this algorithm, the next step in gradient descent is calculated by taking the update to the gradient at each iteration and takes the linear combination of this update, and the previous, to create an update to the gradient descent. This method allows for more efficient convergence towards a local minimum, though there have been studies that cast doubt on the completeness of this conversion for large-parameter models. Nevertheless, it remains popular among modern machine learning models for its efficiency and relative efficacy, and is what we used to optimize our model.</p>
<section id="hyperparameters-learning-rate">
<h3>Hyperparameters: <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code><a class="headerlink" href="#hyperparameters-learning-rate" title="Link to this heading">#</a></h3>
<p>The algorithm does this in sufficiently small incremental steps, often called a “learning rate” in machine learning, so that it is efficiently progressing towards a minimum without overstepping what could be a valley in the parameter surface. This learning rate is often an adjustable <em>hyperparameter</em> of the model – an input to our model that can be adjusted manually to test its effect on the model’s efficacy – that needs to be optimized for the SGD algorithm to converge on a minimum. If the learning rate is too large, then the optimization algorithm can completely skip over minima and fail to converge. If the learning rate is too small, the time to convergence could be enormous, and we may lack the computing resources to fasciliate convergence this way. As such, finding the optimal learning rate is crucial to model success.</p>
</section>
<section id="hyperparameters-batch-size">
<h3>Hyperparameters: <code class="docutils literal notranslate"><span class="pre">batch_size</span></code><a class="headerlink" href="#hyperparameters-batch-size" title="Link to this heading">#</a></h3>
<p>It might initially seem wise to train our model on one image at a time to ensure the model has ample time to learn from its features. However, for large models with large datasets, this approach can be impractical, as the computational resources required for this may not be available. Moreover, this may lead to the optimizer getting stuck in local minima and not learning from overall patterns in the entire dataset. As good as GPUs are at parallelization, training on the entire dataset all at once is also not feasible for most (if not all) GPU resources, and will most-likely cause your program to crash. This is where <em>mini batching</em> will be useful. Mini-batching, or simply batching, creates clusters of images within the training data based on a <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> (how many images are contained within the batch). The model will be trained on the images within a batch simultaneously, allowing the model to capture overall structure present in many (or all)images without sacrificing its ability to detect individual variations. This is also an adjustable hyperparameter. Larger datasets may require a larger batch size to ensure efficient convergence, while smaller datasets most likely use smaller batch sizes to ensure variation in the dataset isn’t missed. Batch sizes are usually given in powers of 2, which empirically is seen to yield better optimizer convergence. It is important to note that adjusting the batch size hyperparameter may also necessitate a corresponding adjustment to the learning rate, as a larger batch size will need a smaller learning rate to make sure that the model does not overshoot minima.</p>
</section>
<section id="hyperparameters-dropout">
<h3>Hyperparameters: <code class="docutils literal notranslate"><span class="pre">dropout</span></code><a class="headerlink" href="#hyperparameters-dropout" title="Link to this heading">#</a></h3>
<p>Neural networks with large numbers of parameters, when trained over many training epochs, can get very good at identifying training data correctly. So much so, that the model essentially memorizes the dataset, but doesnt learn from the features and is thus unable to reproduce its success with brand-new data. This phenomena is called <em>overfitting</em> and it often manifests itself in a model achieving near perfect accuracy on training datasets, but failing to reach benchmarks on validation or testing datasets. We implement several methods to combat this, but one of the most popular and effective is to randomly set the outputs of a certain percentage of neurons to zero. This “deactivates” them, and removes them as trainable parameters during a given training cycle. This ensures that some neurons are learning from features for the first time in any given training iteration, which helps avoid overfitting. The percentage of neurons that are randomly selected for deactivation, <code class="docutils literal notranslate"><span class="pre">dropout</span></code>, is an adjustable hyperparameter that has significant impact on training efficacy. If too little neurons are dropped out, then the model is prone to overfitting. If too many are dropped out, then the model cannot effectively learn from the dataset.</p>
</section>
</section>
<section id="training-dualfinder">
<h2>Training <em>DualFinder</em><a class="headerlink" href="#training-dualfinder" title="Link to this heading">#</a></h2>
<p>Lets illustrate how to construct a training run of <em>DualFinder</em>. We first must create an instance of our <code class="docutils literal notranslate"><span class="pre">DualFinder</span></code> class, which contains several functions that train the model and monitor its progress. As of the creation of this project, our classification problem is binary, so we have two possible classes that a given image can fall under: “single AGN” or “double AGN”.</p>
<p>Our loss function is the <em>categorical crossentropy</em> function, given by, $<span class="math notranslate nohighlight">\( L = -\frac{1}{N}\sum_{i}^{N}y_i\log{p(y_i)}+(1-y_i)\log{(1-p(y_i))} \)</span>$</p>
<p>where <span class="math notranslate nohighlight">\(y_i\)</span> is the true value of the class, <span class="math notranslate nohighlight">\(\log{p(y_i)}\)</span> represents the model’s prediction, and <span class="math notranslate nohighlight">\(N\)</span> is the total number of datapoints. Both the predicted and true labels <span class="math notranslate nohighlight">\(\log{p(y_i)}\)</span> and <span class="math notranslate nohighlight">\(y_i\)</span> respectively must be numerically encoded so that the loss function can be calculated and thus prediction can be made. For binary classification tasks, it is common to define a <em>positive</em> and <em>negative</em> class and represent the output of the model as its prediction of the likelihood that a given image belongs to the positive class. In <em>DualFinder</em>, we define the positive class to be if two point sources are detected in the image. Consequently, the label of “double AGN” is given a value of <code class="docutils literal notranslate"><span class="pre">1.0</span></code> and an image labeled as a “single AGN” is given a value of <code class="docutils literal notranslate"><span class="pre">0.0</span></code> (lack of a double AGN). The final two neurons of the model output these probabilities, the loss function check’s the model’s probability prediction to the true value, and outputs a value, which motivates the continued exploration of parameter space towards the global minimum.</p>
<p>One approach to numerically encode labels is to create a “binary class matrix” from categorical class vectors. In this method, the categorical variable, in our case the label “single AGN” or “double AGN”, is first mapped to a numerical value, in our case “single AGN” to <span class="math notranslate nohighlight">\(0\)</span> and “double AGN” <span class="math notranslate nohighlight">\(1\)</span>. Then, the array (vector) containing the numerical encoding of these labels are passed into a function that creates a matrix of ones and zeros that represent the presence of a particular class in a particular label. To illustrate this, suppose that we encoded a snipet of our training labels such that $<span class="math notranslate nohighlight">\(y_i = [..., 1, 1, 0, 0, 1....]\)</span><span class="math notranslate nohighlight">\(. The binary matrix representation of this would be \)</span><span class="math notranslate nohighlight">\([...,
[0, 1], 
[0, 1], 
[1, 0],
[1, 0], 
[0, 1], ...]\)</span>$.
We create these matricies using Tensorflow’s built-in <code class="docutils literal notranslate"><span class="pre">tensorflow.keras.utils.to_categorical()</span></code> function. Once our labels are encoded, we compile our model with the binary cross-entropy loss function and all useful monitoring metrics – which in our case includes accuracy, false positives, false negatives, true positives, true negatives, recall, precision, F1 score, and the Matthews Correlation Coefficient (MCC).</p>
<section id="model-metrics">
<h3>Model Metrics<a class="headerlink" href="#model-metrics" title="Link to this heading">#</a></h3>
<p><strong>Recall</strong>: Recall measures how often the model correctly predicts the positive class out of the total number of positives in the dataset. A recall value of 1 indicates the model always predicts the positive class correcly, i.e, any time there is an instance of the positive class in the dataset, the model identifies it correctly. Because the goal of our model is to detect as many dual AGN candidates (positive classes) as available in a dataset, achieving a high recall is top priority and as such this metric is arguably the most important for evaluating the success of <em>DualFinder</em>.</p>
<p><strong>Precision</strong>: Precision is a measure of how many positive predictions made by the model were correct. It is defined as the predicted positives divided by the total number of positives <span class="math notranslate nohighlight">\(\frac{TP}{TP+FP}\)</span> where <span class="math notranslate nohighlight">\(TP\)</span> is a true positive and <span class="math notranslate nohighlight">\(FP\)</span> is a false positive.</p>
<p>The distinction between precision and recall is subtle. Essentially, recall measures the percentage of positive class detections that were identified correctly, while precision measures how often the model is correct when it predicts a positive detection. Both are vital to measuring the efficacy of <em>DualFinder</em> though a high value in one or the other individually doesn’t necessarily mean that the model is performing well. For example, suppose during a given training iteration the model achieves a high precion of <span class="math notranslate nohighlight">\(P = 98.7\%\)</span> while the recall lags behind at <span class="math notranslate nohighlight">\(R = 50.7\%\)</span>. This would mean that when the model predicts a positive class, it is highly likely to be correct. However, because the recall is so low, the model rarely predicts a positive class, and so it misses a lot of potential detections (i.e, the model has many false negatives). A <em>DualFinder</em> model with these metrics would be horrible at detecting dual AGN candidates, as it would miss-classify most of them as single AGN. Given the size of the datasets we hope to implement <em>DualFinder</em> on, it is highly unlikely that scientists would review images classified as single AGN, so the model would not be able to perform its duties and actually hampers further investigation of the images that it misses.</p>
<p>On the other hand, if the recall is high but the precision is low, then the model classifies nearly everything as a potential dual AGN candidate, which is not very useful. Consequently, a model is optimally trained when both metrics take on high values.</p>
<p><strong>F1 Score</strong>: F1 score is defined as $<span class="math notranslate nohighlight">\(\frac{precision \cdot recall}{precision + recall}\)</span>$ and is thus a combination of the two metrics above. It is an effective single metric to use to evaluate the success of a model without running into the issues of using solely precision or recall outlined above. As is the case with the metrics above, a high value of the F1 score indicates high values in precision <em>and</em> recall and thus a potentially well-trained model.</p>
<p><strong>MCC</strong>: The Matthews Correlation Coefficient (MCC) measures the difference between the actual and predicted values of the dataset’s labels and outputs a number that is equivalent to the <span class="math notranslate nohighlight">\(\chi^2\)</span> value of a <span class="math notranslate nohighlight">\(2 \times 2\)</span> correlation matrix. Unlike the metrics above, which are restricted to values between <span class="math notranslate nohighlight">\(0\)</span> and <span class="math notranslate nohighlight">\(1\)</span>, the MCC can take on values in the range <span class="math notranslate nohighlight">\((-1, 1)\)</span>, where <span class="math notranslate nohighlight">\(-1\)</span> represents an inverse prediction (the model predicts the exact opposite class than its true value), <span class="math notranslate nohighlight">\(0\)</span> represents a random prediction, and <span class="math notranslate nohighlight">\(1\)</span> represents perfect correlation between predictions and true class values.</p>
</section>
</section>
<section id="training-proceedure">
<h2>Training Proceedure<a class="headerlink" href="#training-proceedure" title="Link to this heading">#</a></h2>
<p>Once our model is compiled, we are ready to begin training. Models of <code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code> class have a built-in function called <code class="docutils literal notranslate"><span class="pre">model.fit()</span></code> that handles training execution. It has the following positional and optional inputs:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> 
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Evidently, this function is very versitile and can handle a wide range of data structures. In our training procedure, we will mainly use the <code class="docutils literal notranslate"><span class="pre">x,</span> <span class="pre">y,</span> <span class="pre">batch_size,</span> <span class="pre">epochs,</span> <span class="pre">verbose,</span> <span class="pre">callbacks,</span> <span class="pre">validation_data,</span> <span class="pre">shuffle,</span> <span class="pre">class_weight</span></code> parameters. Let’s go through each one and its importance towards model training.</p>
<p><code class="docutils literal notranslate"><span class="pre">x</span></code>: This is our training data. This function accomodates several data structures, namely tensorflow <code class="docutils literal notranslate"><span class="pre">Tensor</span></code> and <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> objects, as well as <code class="docutils literal notranslate"><span class="pre">numpy</span></code> arrays. We will be using the numpy arrays generated above for our training.</p>
<p><code class="docutils literal notranslate"><span class="pre">y</span></code>: These are the labels associated with our training data. They must be encoded before being passed into the function. Because our model has two output neurons instead of the typical one for a binary classification scheme, the labels must be encoded as if the model was tasked with a multi-class classification scheme with two classes. As such, our model is not constructed for one hot encoding, so we must use the encoding algorithm outlined above. [REVISE THIS]</p>
<p><code class="docutils literal notranslate"><span class="pre">batch_size</span></code>: Our batch size – how many images the model will be trained on simultaneously. Accepts <code class="docutils literal notranslate"><span class="pre">int</span></code> objects.</p>
<p><code class="docutils literal notranslate"><span class="pre">epochs</span></code>: The number of iterations through the entire training dataset. Accepts <code class="docutils literal notranslate"><span class="pre">int</span></code> objects.</p>
<p><code class="docutils literal notranslate"><span class="pre">verbose</span></code>: Determines what the function outputs to the system to monitor training progress. A value of <code class="docutils literal notranslate"><span class="pre">0</span></code> means that the function outputs nothing to the console, and the user does not know at what stage of training the model is. <code class="docutils literal notranslate"><span class="pre">1</span></code> outputs all available information about training progress to the user. <code class="docutils literal notranslate"><span class="pre">2</span></code> outputs some useful information, but excludes the progress bar present in <code class="docutils literal notranslate"><span class="pre">1.</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">callbacks</span></code>: This input accepts a list of Tensorflow keras <code class="docutils literal notranslate"><span class="pre">Callback</span></code> objects, which are constructed to monitor certain aspects of the model’s training and make changes to the training procedure while it is in motion. These objects allow us to make these changes, or monitor progress, without restarting the training run. There are dozens of pre-fabricated callbacks available in the Tensorflow API, and its possible to make custom ones. For training <code class="docutils literal notranslate"><span class="pre">DualFinder</span></code> we make use of the <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code>, <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code>, and our custom <code class="docutils literal notranslate"><span class="pre">FeatureMapCallback</span></code>. The <code class="docutils literal notranslate"><span class="pre">ModelCheckpoint</span></code> callback saves the model and its weights as a <code class="docutils literal notranslate"><span class="pre">.keras</span></code> file after each training epoch so that if training is interrupted, the user can begin training the model from the last checkpoint instead of the restarting. The <code class="docutils literal notranslate"><span class="pre">EarlyStopping</span></code> checkpoint monitors the progression of an evalution metric over a specified number of epochs (in our case, 5). If the metric is measured to decrease for longer than a specified tolerance level, training is stopped and the model is saved. This technique of “early stopping” is utilized in machine learning to train unstable models that might incur massive fluctuations in their evaluation metrics over the course of their training. Our custom <code class="docutils literal notranslate"><span class="pre">FeatureMapCallback</span></code> takes as input a randomly-selected image from the dataset (either a single or a dual), has the model predict the class of the image throughout training, and plots and saves a heatmap of the features of the image the model used to classify it, and therefore what the model deemed as “important indicators” of the class of the object. These plots allow us to determine what features the model is picking up on across its hidden layers and over all of its training epochs, revealing information about the model’s decision-making that is otherwise hidden in the hidden layers.</p>
<p><code class="docutils literal notranslate"><span class="pre">validation_data</span></code>: Accepts a tuple containing our validation dataset (stored in a numpy array) and our encoded validation labels (also stored in a numpy array). Data is passed into the function in this way because the function allows the user to pass their entire dataset into <code class="docutils literal notranslate"><span class="pre">x</span></code> and let the model automatically separate the training data from the validation data using <code class="docutils literal notranslate"><span class="pre">validation_split</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">class_weight</span></code>: Accepts as input a dictionary of weights (floats) that map to the (integer) classes of the dataset. Many datasets (including our own) are imbalanced, and it is often unfeasible to have equal number of samples per class in real data. As such, we want to train our model such that it can make accurate predictions when faced with an imbalanced dataset. Our <code class="docutils literal notranslate"><span class="pre">class_weights</span></code> dictionary weights under-represented classes such that predicting these classes has more of an impact on the loss function so that these classes do not get ignored during training. As such, using class weights during training is a powerful tool to prevent overfitting. We create our <code class="docutils literal notranslate"><span class="pre">class_weigts</span></code> dictionary using the <code class="docutils literal notranslate"><span class="pre">sklearn.utils.class_weight.compute_class_weight</span></code> function from Scikit-Learn – a python library with many additional machine learning algorithms and tools.</p>
<p>We demonstrate an example training run using our <strong>model A</strong> training scheme. In this program, we train our model on synthetic and real data for 30 training epochs. In our first iteration, we want to illustrate how poorly chosen hyperparameters can negatively impact training success. Since our model is trained on both types of data, we would want to use a smaller learning rate so that the model doesn’t miss important features. We will also want to use a medium to large batch size because we want to include as many different samples from each data type for the model to learn from. As such, we will chose a large learning rate of <code class="docutils literal notranslate"><span class="pre">1e-3</span></code> and a large batch size of <code class="docutils literal notranslate"><span class="pre">128</span></code>. We run the training algorithm and display plots of metrics vs. epoch below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#Specify some initial hyperparameters to illustrate their impact on training. </span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">image_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;modelB&quot;</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">model_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_models/&quot;</span>

<span class="n">dual_finder_instance</span> <span class="o">=</span> <span class="n">DualFinder</span><span class="p">(</span><span class="n">train_dataset_modelA</span><span class="p">,</span> <span class="n">val_dataset_modelA</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">train_labels_modelA</span><span class="p">,</span> <span class="n">val_labels_modelA</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)</span>
<span class="n">history_bad_params_modelA</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">dual_finder_instance</span><span class="o">.</span><span class="n">trainCNN</span><span class="p">(</span><span class="n">model_filepath</span> <span class="o">=</span> <span class="n">model_filepath</span><span class="p">,</span> <span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;double AGN&#39; &#39;single AGN&#39; &#39;single AGN&#39; ... &#39;single AGN&#39; &#39;double AGN&#39;
 &#39;double AGN&#39;]
[&#39;double AGN&#39; &#39;double AGN&#39; &#39;double AGN&#39; ... &#39;double AGN&#39; &#39;single AGN&#39;
 &#39;single AGN&#39;]
Converting to list
Converting to list
</pre></div>
</div>
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential_3"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ rescaling_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Rescaling</span>)         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │        <span style="color: #00af00; text-decoration-color: #00af00">13,920</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_15 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_12          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │           <span style="color: #00af00; text-decoration-color: #00af00">384</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">884,992</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_16 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_13          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">590,080</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_17 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_14          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_6 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_15 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">885,120</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_18 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_7 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13824</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │     <span style="color: #00af00; text-decoration-color: #00af00">7,078,400</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_19 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_15          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │         <span style="color: #00af00; text-decoration-color: #00af00">2,048</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │       <span style="color: #00af00; text-decoration-color: #00af00">262,656</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">2</span>)              │         <span style="color: #00af00; text-decoration-color: #00af00">1,026</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,720,674</span> (37.08 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,718,434</span> (37.07 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">2,240</span> (8.75 KB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential_3"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ rescaling_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Rescaling</span>)         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │        <span style="color: #00af00; text-decoration-color: #00af00">13,920</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_15 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_12          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │           <span style="color: #00af00; text-decoration-color: #00af00">384</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">884,992</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_16 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_13          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">590,080</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_17 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_14          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_6 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_15 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">885,120</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_18 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_7 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten_3 (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13824</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                 │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │     <span style="color: #00af00; text-decoration-color: #00af00">7,078,400</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_19 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_15          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │         <span style="color: #00af00; text-decoration-color: #00af00">2,048</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │       <span style="color: #00af00; text-decoration-color: #00af00">262,656</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">2</span>)              │         <span style="color: #00af00; text-decoration-color: #00af00">1,026</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,720,674</span> (37.08 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,718,434</span> (37.07 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">2,240</span> (8.75 KB)
</pre>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-04-19 00:37:22,454 - INFO - save_feature_maps == True, WILL save feature maps
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature map will feature: [&#39;double AGN&#39;]
Shape of randomly selected image: (1, 60, 60, 1)
Epoch 1/30
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">14</span><span class="p">],</span> <span class="n">line</span> <span class="mi">12</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="n">model_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_models/&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span> <span class="n">dual_finder_instance</span> <span class="o">=</span> <span class="n">DualFinder</span><span class="p">(</span><span class="n">train_dataset_modelA</span><span class="p">,</span> <span class="n">val_dataset_modelA</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">train_labels_modelA</span><span class="p">,</span> <span class="n">val_labels_modelA</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">12</span> <span class="n">history_bad_params_modelA</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">dual_finder_instance</span><span class="o">.</span><span class="n">trainCNN</span><span class="p">(</span><span class="n">model_filepath</span> <span class="o">=</span> <span class="n">model_filepath</span><span class="p">,</span> <span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span><span class="p">)</span>

<span class="nn">File ~/Desktop/Junior_Year_at_Yale/Spring_Semester/ASTR_330/final_project_git_repo/DualFinder/dual_finder/dual_finder/cnn/train_cnn.py:167,</span> in <span class="ni">DualFinder.trainCNN</span><span class="nt">(self, dropout_rate, save_feature_maps, model_filepath)</span>
<span class="g g-Whitespace">    </span><span class="mi">164</span>     <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;save_feature_maps&#39; == </span><span class="si">{</span><span class="n">save_feature_maps</span><span class="si">}</span><span class="s2">, NOT saving feature maps&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">165</span>     <span class="n">callback_array</span> <span class="o">=</span> <span class="p">[</span><span class="n">checkpoint_callback</span><span class="p">]</span>
<span class="ne">--&gt; </span><span class="mi">167</span> <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">train_labels_one_hot</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchSize</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_dataset</span><span class="p">,</span> <span class="n">val_labels_one_hot</span><span class="p">),</span> <span class="n">epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="n">class_weightsDict</span><span class="p">,</span> <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callback_array</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">169</span> <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">170</span> <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117,</span> in <span class="ni">filter_traceback.&lt;locals&gt;.error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span> <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">116</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">117</span>     <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">118</span> <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span>     <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:325,</span> in <span class="ni">TensorFlowTrainer.fit</span><span class="nt">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)</span>
<span class="g g-Whitespace">    </span><span class="mi">323</span> <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">iterator</span> <span class="ow">in</span> <span class="n">epoch_iterator</span><span class="o">.</span><span class="n">enumerate_epoch</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">324</span>     <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">325</span>     <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">326</span>     <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">327</span>         <span class="n">step</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pythonify_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">328</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">329</span>     <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150,</span> in <span class="ni">filter_traceback.&lt;locals&gt;.error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">148</span> <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">149</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">150</span>   <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">151</span> <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">152</span>   <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833,</span> in <span class="ni">Function.__call__</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">830</span> <span class="n">compiler</span> <span class="o">=</span> <span class="s2">&quot;xla&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span> <span class="k">else</span> <span class="s2">&quot;nonXla&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">832</span> <span class="k">with</span> <span class="n">OptionalXlaContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">833</span>   <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">835</span> <span class="n">new_tracing_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experimental_get_tracing_count</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">836</span> <span class="n">without_tracing</span> <span class="o">=</span> <span class="p">(</span><span class="n">tracing_count</span> <span class="o">==</span> <span class="n">new_tracing_count</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878,</span> in <span class="ni">Function._call</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">875</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">876</span> <span class="c1"># In this case we have not created variables on the first call. So we can</span>
<span class="g g-Whitespace">    </span><span class="mi">877</span> <span class="c1"># run the first trace but we should fail if variables are created.</span>
<span class="ne">--&gt; </span><span class="mi">878</span> <span class="n">results</span> <span class="o">=</span> <span class="n">tracing_compilation</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">879</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kwds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variable_creation_config</span>
<span class="g g-Whitespace">    </span><span class="mi">880</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">881</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_created_variables</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">882</span>   <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Creating variables on a non-first call to a function&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">883</span>                    <span class="s2">&quot; decorated with tf.function.&quot;</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139,</span> in <span class="ni">call_function</span><span class="nt">(args, kwargs, tracing_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="n">bound_args</span> <span class="o">=</span> <span class="n">function</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span> <span class="n">flat_inputs</span> <span class="o">=</span> <span class="n">function</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">unpack_inputs</span><span class="p">(</span><span class="n">bound_args</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">139</span> <span class="k">return</span> <span class="n">function</span><span class="o">.</span><span class="n">_call_flat</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>     <span class="n">flat_inputs</span><span class="p">,</span> <span class="n">captured_inputs</span><span class="o">=</span><span class="n">function</span><span class="o">.</span><span class="n">captured_inputs</span>
<span class="g g-Whitespace">    </span><span class="mi">141</span> <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322,</span> in <span class="ni">ConcreteFunction._call_flat</span><span class="nt">(self, tensor_inputs, captured_inputs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1318</span> <span class="n">possible_gradient_type</span> <span class="o">=</span> <span class="n">gradients_util</span><span class="o">.</span><span class="n">PossibleTapeGradientTypes</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1319</span> <span class="k">if</span> <span class="p">(</span><span class="n">possible_gradient_type</span> <span class="o">==</span> <span class="n">gradients_util</span><span class="o">.</span><span class="n">POSSIBLE_GRADIENT_TYPES_NONE</span>
<span class="g g-Whitespace">   </span><span class="mi">1320</span>     <span class="ow">and</span> <span class="n">executing_eagerly</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1321</span>   <span class="c1"># No tape is watching; skip to running the function.</span>
<span class="ne">-&gt; </span><span class="mi">1322</span>   <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference_function</span><span class="o">.</span><span class="n">call_preflattened</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1323</span> <span class="n">forward_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_forward_and_backward_functions</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1324</span>     <span class="n">args</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1325</span>     <span class="n">possible_gradient_type</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1326</span>     <span class="n">executing_eagerly</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1327</span> <span class="n">forward_function</span><span class="p">,</span> <span class="n">args_with_tangents</span> <span class="o">=</span> <span class="n">forward_backward</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216,</span> in <span class="ni">AtomicFunction.call_preflattened</span><span class="nt">(self, args)</span>
<span class="g g-Whitespace">    </span><span class="mi">214</span> <span class="k">def</span> <span class="nf">call_preflattened</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">core</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">215</span><span class="w">   </span><span class="sd">&quot;&quot;&quot;Calls with flattened tensor inputs and returns the structured output.&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">216</span>   <span class="n">flat_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_flat</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span>   <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">pack_output</span><span class="p">(</span><span class="n">flat_outputs</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251,</span> in <span class="ni">AtomicFunction.call_flat</span><span class="nt">(self, *args)</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span> <span class="k">with</span> <span class="n">record</span><span class="o">.</span><span class="n">stop_recording</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">250</span>   <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bound_context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
<span class="ne">--&gt; </span><span class="mi">251</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bound_context</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span>         <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span>         <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">254</span>         <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">flat_outputs</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">255</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span>   <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">257</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="n">make_call_op_in_graph</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">258</span>         <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">259</span>         <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">260</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_bound_context</span><span class="o">.</span><span class="n">function_call_options</span><span class="o">.</span><span class="n">as_attrs</span><span class="p">(),</span>
<span class="g g-Whitespace">    </span><span class="mi">261</span>     <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500,</span> in <span class="ni">Context.call_function</span><span class="nt">(self, name, tensor_inputs, num_outputs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1498</span> <span class="n">cancellation_context</span> <span class="o">=</span> <span class="n">cancellation</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1499</span> <span class="k">if</span> <span class="n">cancellation_context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1500</span>   <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1501</span>       <span class="n">name</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1502</span>       <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1503</span>       <span class="n">inputs</span><span class="o">=</span><span class="n">tensor_inputs</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1504</span>       <span class="n">attrs</span><span class="o">=</span><span class="n">attrs</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1505</span>       <span class="n">ctx</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1506</span>   <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1507</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1508</span>   <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute_with_cancellation</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1509</span>       <span class="n">name</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1510</span>       <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1514</span>       <span class="n">cancellation_manager</span><span class="o">=</span><span class="n">cancellation_context</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1515</span>   <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53,</span> in <span class="ni">quick_execute</span><span class="nt">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">52</span>   <span class="n">ctx</span><span class="o">.</span><span class="n">ensure_initialized</span><span class="p">()</span>
<span class="ne">---&gt; </span><span class="mi">53</span>   <span class="n">tensors</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_Execute</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">_handle</span><span class="p">,</span> <span class="n">device_name</span><span class="p">,</span> <span class="n">op_name</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span>                                       <span class="n">inputs</span><span class="p">,</span> <span class="n">attrs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">55</span> <span class="k">except</span> <span class="n">core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">56</span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history_bad_params</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models/saved_history.npy&quot;</span><span class="p">)</span>

<span class="n">acc_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">val_acc_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>

<span class="n">recall_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">]</span>
<span class="n">val_f1_score_bad_paramsA</span> <span class="o">=</span> <span class="n">history_bad_params</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">]</span>
<span class="c1">#mcc_bad_paramsA = history_bad_params[&#39;MCC&#39;]</span>
<span class="c1">#val_mcc_bad_paramsA = history_bad_params[&#39;val_MCC&#39;]</span>

<span class="n">save_filepath</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/saved_figures/&quot;</span>
<span class="n">modelA_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_training_progress</span><span class="p">(</span><span class="n">loss_bad_paramsA</span><span class="p">,</span> <span class="n">acc_bad_paramsA</span><span class="p">,</span> <span class="n">modelA_epochs</span><span class="p">,</span> <span class="n">save_filepath</span> <span class="o">=</span> <span class="n">save_filepath</span><span class="p">,</span> <span class="n">training_run</span> <span class="o">=</span> <span class="s2">&quot;Bad Parameters&quot;</span><span class="p">,</span>
                                 <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_bad_paramsA</span><span class="p">,</span> <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_bad_paramsA</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="n">f1_score_bad_paramsA</span><span class="p">,</span>
                                 <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss_bad_paramsA</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_acc_bad_paramsA</span><span class="p">,</span> <span class="n">val_recall</span> <span class="o">=</span> <span class="n">val_recall_bad_paramsA</span><span class="p">,</span> <span class="n">val_precision</span> <span class="o">=</span> <span class="n">val_precision_bad_paramsA</span><span class="p">,</span> 
                                 <span class="n">val_f1_score</span> <span class="o">=</span> <span class="n">val_f1_score_bad_paramsA</span><span class="p">)</span>

                                 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/724a1615bc5ace56dbf3bb887d797c84011d8c2c75d6e3087ae5c5ea447f104d.png" src="_images/724a1615bc5ace56dbf3bb887d797c84011d8c2c75d6e3087ae5c5ea447f104d.png" />
</div>
</div>
</section>
<section id="training-run-one-discussion">
<h2>Training Run One Discussion<a class="headerlink" href="#training-run-one-discussion" title="Link to this heading">#</a></h2>
<p>With our choice of hyperparameters above, we see that the model’s training accuracy, precision, recall, and F1 score seems to plateu at a value of <span class="math notranslate nohighlight">\(0.70\)</span>, while the validation values of these metrics fluctuate wildly between values of ~<span class="math notranslate nohighlight">\(0.5\)</span> and ~ <span class="math notranslate nohighlight">\(0.70\)</span> over the training run. This is likely caused by our high learning rate, as the optimizer takes large steps between local maxima and minima in loss function space, corresponding to low and high values for these metrics respectively. As such, our optmizer has not converged on a stable solution, and has likely not learned the features of the dataset well enough to produce consistent results, which is not suitable for a detection prorgam. This demonstrate the essentialness of choosing optimal hyperparameter values when training a model.</p>
</section>
<section id="training-run-two-revised-hyperparameters">
<h2>Training Run Two: Revised Hyperparameters<a class="headerlink" href="#training-run-two-revised-hyperparameters" title="Link to this heading">#</a></h2>
<p>Let’s redo this training procedure with better informed choices for hyperparameters. We see that our learning rate was too high, so lets reduce it to <code class="docutils literal notranslate"><span class="pre">learning_rate</span> <span class="pre">=</span> <span class="pre">5e-7</span></code>. Additionally, lets reduce our batch size to <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">=</span> <span class="pre">32</span></code> to make sure that our model does not miss small but important variations in the features of the dataset. While this will increase our training time, it may provide some stability to the model. Training for the same number of epochs, <code class="docutils literal notranslate"><span class="pre">epochs</span> <span class="pre">=</span> <span class="pre">30</span></code> as above, we train a fresh instance of our model using these hyperparameters and plot the results below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">revised_batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">revised_learning_rate</span> <span class="o">=</span> <span class="mf">5e-7</span>
<span class="n">image_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">dropout_rate</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;modelB&quot;</span>
<span class="n">model_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_models_better_params/&quot;</span>

<span class="n">dual_finder_instance</span> <span class="o">=</span> <span class="n">DualFinder</span><span class="p">(</span><span class="n">train_dataset_modelA</span><span class="p">,</span> <span class="n">val_dataset_modelA</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">train_labels_modelA</span><span class="p">,</span> <span class="n">val_labels_modelA</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">revised_batch_size</span><span class="p">,</span> <span class="n">revised_learning_rate</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)</span>
<span class="n">history_bad_params_modelA</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">dual_finder_instance</span><span class="o">.</span><span class="n">trainCNN</span><span class="p">(</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">model_filepath</span> <span class="o">=</span> <span class="n">model_filepath</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;double AGN&#39; &#39;single AGN&#39; &#39;single AGN&#39; ... &#39;single AGN&#39; &#39;double AGN&#39;
 &#39;double AGN&#39;]
[&#39;double AGN&#39; &#39;double AGN&#39; &#39;double AGN&#39; ... &#39;double AGN&#39; &#39;single AGN&#39;
 &#39;single AGN&#39;]
Converting to list
Converting to list
</pre></div>
</div>
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential_4"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ rescaling_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Rescaling</span>)         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_16 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │        <span style="color: #00af00; text-decoration-color: #00af00">13,920</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_20 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_16          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │           <span style="color: #00af00; text-decoration-color: #00af00">384</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_17 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">884,992</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_21 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_17          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_18 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">590,080</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_22 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_18          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_8 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_19 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">885,120</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_23 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13824</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │     <span style="color: #00af00; text-decoration-color: #00af00">7,078,400</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_24 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_19          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │         <span style="color: #00af00; text-decoration-color: #00af00">2,048</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │       <span style="color: #00af00; text-decoration-color: #00af00">262,656</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">2</span>)              │         <span style="color: #00af00; text-decoration-color: #00af00">1,026</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,720,674</span> (37.08 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,718,434</span> (37.07 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">2,240</span> (8.75 KB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential_4"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ rescaling_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Rescaling</span>)         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_16 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │        <span style="color: #00af00; text-decoration-color: #00af00">13,920</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_20 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_16          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │           <span style="color: #00af00; text-decoration-color: #00af00">384</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_17 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">884,992</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_21 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_17          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_18 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">590,080</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_22 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_18          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_8 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_19 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">885,120</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_23 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_9 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>)  │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten_4 (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13824</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_12 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │     <span style="color: #00af00; text-decoration-color: #00af00">7,078,400</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_24 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_19          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │         <span style="color: #00af00; text-decoration-color: #00af00">2,048</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_13 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │       <span style="color: #00af00; text-decoration-color: #00af00">262,656</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_14 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">2</span>)              │         <span style="color: #00af00; text-decoration-color: #00af00">1,026</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,720,674</span> (37.08 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,718,434</span> (37.07 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">2,240</span> (8.75 KB)
</pre>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-04-19 00:50:29,481 - INFO - save_feature_maps == True, WILL save feature maps
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature map will feature: [&#39;double AGN&#39;]
Shape of randomly selected image: (1, 60, 60, 1)
Epoch 1/30
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">17</span><span class="p">],</span> <span class="n">line</span> <span class="mi">11</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="n">model_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_models_better_params/&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="n">dual_finder_instance</span> <span class="o">=</span> <span class="n">DualFinder</span><span class="p">(</span><span class="n">train_dataset_modelA</span><span class="p">,</span> <span class="n">val_dataset_modelA</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">train_labels_modelA</span><span class="p">,</span> <span class="n">val_labels_modelA</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">revised_batch_size</span><span class="p">,</span> <span class="n">revised_learning_rate</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">11</span> <span class="n">history_bad_params_modelA</span><span class="p">,</span> <span class="n">model</span> <span class="o">=</span> <span class="n">dual_finder_instance</span><span class="o">.</span><span class="n">trainCNN</span><span class="p">(</span><span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span><span class="p">,</span> <span class="n">model_filepath</span> <span class="o">=</span> <span class="n">model_filepath</span><span class="p">)</span>

<span class="nn">File ~/Desktop/Junior_Year_at_Yale/Spring_Semester/ASTR_330/final_project_git_repo/DualFinder/dual_finder/dual_finder/cnn/train_cnn.py:167,</span> in <span class="ni">DualFinder.trainCNN</span><span class="nt">(self, dropout_rate, save_feature_maps, model_filepath)</span>
<span class="g g-Whitespace">    </span><span class="mi">164</span>     <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;save_feature_maps&#39; == </span><span class="si">{</span><span class="n">save_feature_maps</span><span class="si">}</span><span class="s2">, NOT saving feature maps&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">165</span>     <span class="n">callback_array</span> <span class="o">=</span> <span class="p">[</span><span class="n">checkpoint_callback</span><span class="p">]</span>
<span class="ne">--&gt; </span><span class="mi">167</span> <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">train_labels_one_hot</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchSize</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_dataset</span><span class="p">,</span> <span class="n">val_labels_one_hot</span><span class="p">),</span> <span class="n">epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="n">class_weightsDict</span><span class="p">,</span> <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callback_array</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">169</span> <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">170</span> <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117,</span> in <span class="ni">filter_traceback.&lt;locals&gt;.error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span> <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">116</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">117</span>     <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">118</span> <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span>     <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:325,</span> in <span class="ni">TensorFlowTrainer.fit</span><span class="nt">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)</span>
<span class="g g-Whitespace">    </span><span class="mi">323</span> <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">iterator</span> <span class="ow">in</span> <span class="n">epoch_iterator</span><span class="o">.</span><span class="n">enumerate_epoch</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">324</span>     <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">325</span>     <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">326</span>     <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">327</span>         <span class="n">step</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pythonify_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">328</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">329</span>     <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150,</span> in <span class="ni">filter_traceback.&lt;locals&gt;.error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">148</span> <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">149</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">150</span>   <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">151</span> <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">152</span>   <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833,</span> in <span class="ni">Function.__call__</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">830</span> <span class="n">compiler</span> <span class="o">=</span> <span class="s2">&quot;xla&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span> <span class="k">else</span> <span class="s2">&quot;nonXla&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">832</span> <span class="k">with</span> <span class="n">OptionalXlaContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">833</span>   <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">835</span> <span class="n">new_tracing_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experimental_get_tracing_count</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">836</span> <span class="n">without_tracing</span> <span class="o">=</span> <span class="p">(</span><span class="n">tracing_count</span> <span class="o">==</span> <span class="n">new_tracing_count</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878,</span> in <span class="ni">Function._call</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">875</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">876</span> <span class="c1"># In this case we have not created variables on the first call. So we can</span>
<span class="g g-Whitespace">    </span><span class="mi">877</span> <span class="c1"># run the first trace but we should fail if variables are created.</span>
<span class="ne">--&gt; </span><span class="mi">878</span> <span class="n">results</span> <span class="o">=</span> <span class="n">tracing_compilation</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">879</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kwds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variable_creation_config</span>
<span class="g g-Whitespace">    </span><span class="mi">880</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">881</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_created_variables</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">882</span>   <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Creating variables on a non-first call to a function&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">883</span>                    <span class="s2">&quot; decorated with tf.function.&quot;</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139,</span> in <span class="ni">call_function</span><span class="nt">(args, kwargs, tracing_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="n">bound_args</span> <span class="o">=</span> <span class="n">function</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span> <span class="n">flat_inputs</span> <span class="o">=</span> <span class="n">function</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">unpack_inputs</span><span class="p">(</span><span class="n">bound_args</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">139</span> <span class="k">return</span> <span class="n">function</span><span class="o">.</span><span class="n">_call_flat</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>     <span class="n">flat_inputs</span><span class="p">,</span> <span class="n">captured_inputs</span><span class="o">=</span><span class="n">function</span><span class="o">.</span><span class="n">captured_inputs</span>
<span class="g g-Whitespace">    </span><span class="mi">141</span> <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322,</span> in <span class="ni">ConcreteFunction._call_flat</span><span class="nt">(self, tensor_inputs, captured_inputs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1318</span> <span class="n">possible_gradient_type</span> <span class="o">=</span> <span class="n">gradients_util</span><span class="o">.</span><span class="n">PossibleTapeGradientTypes</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1319</span> <span class="k">if</span> <span class="p">(</span><span class="n">possible_gradient_type</span> <span class="o">==</span> <span class="n">gradients_util</span><span class="o">.</span><span class="n">POSSIBLE_GRADIENT_TYPES_NONE</span>
<span class="g g-Whitespace">   </span><span class="mi">1320</span>     <span class="ow">and</span> <span class="n">executing_eagerly</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1321</span>   <span class="c1"># No tape is watching; skip to running the function.</span>
<span class="ne">-&gt; </span><span class="mi">1322</span>   <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference_function</span><span class="o">.</span><span class="n">call_preflattened</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1323</span> <span class="n">forward_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_forward_and_backward_functions</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1324</span>     <span class="n">args</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1325</span>     <span class="n">possible_gradient_type</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1326</span>     <span class="n">executing_eagerly</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1327</span> <span class="n">forward_function</span><span class="p">,</span> <span class="n">args_with_tangents</span> <span class="o">=</span> <span class="n">forward_backward</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216,</span> in <span class="ni">AtomicFunction.call_preflattened</span><span class="nt">(self, args)</span>
<span class="g g-Whitespace">    </span><span class="mi">214</span> <span class="k">def</span> <span class="nf">call_preflattened</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">core</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">215</span><span class="w">   </span><span class="sd">&quot;&quot;&quot;Calls with flattened tensor inputs and returns the structured output.&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">216</span>   <span class="n">flat_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_flat</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span>   <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">pack_output</span><span class="p">(</span><span class="n">flat_outputs</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251,</span> in <span class="ni">AtomicFunction.call_flat</span><span class="nt">(self, *args)</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span> <span class="k">with</span> <span class="n">record</span><span class="o">.</span><span class="n">stop_recording</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">250</span>   <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bound_context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
<span class="ne">--&gt; </span><span class="mi">251</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bound_context</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span>         <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span>         <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">254</span>         <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">flat_outputs</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">255</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span>   <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">257</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="n">make_call_op_in_graph</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">258</span>         <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">259</span>         <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">260</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_bound_context</span><span class="o">.</span><span class="n">function_call_options</span><span class="o">.</span><span class="n">as_attrs</span><span class="p">(),</span>
<span class="g g-Whitespace">    </span><span class="mi">261</span>     <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500,</span> in <span class="ni">Context.call_function</span><span class="nt">(self, name, tensor_inputs, num_outputs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1498</span> <span class="n">cancellation_context</span> <span class="o">=</span> <span class="n">cancellation</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1499</span> <span class="k">if</span> <span class="n">cancellation_context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1500</span>   <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1501</span>       <span class="n">name</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1502</span>       <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1503</span>       <span class="n">inputs</span><span class="o">=</span><span class="n">tensor_inputs</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1504</span>       <span class="n">attrs</span><span class="o">=</span><span class="n">attrs</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1505</span>       <span class="n">ctx</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1506</span>   <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1507</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1508</span>   <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute_with_cancellation</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1509</span>       <span class="n">name</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1510</span>       <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1514</span>       <span class="n">cancellation_manager</span><span class="o">=</span><span class="n">cancellation_context</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1515</span>   <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53,</span> in <span class="ni">quick_execute</span><span class="nt">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">52</span>   <span class="n">ctx</span><span class="o">.</span><span class="n">ensure_initialized</span><span class="p">()</span>
<span class="ne">---&gt; </span><span class="mi">53</span>   <span class="n">tensors</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_Execute</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">_handle</span><span class="p">,</span> <span class="n">device_name</span><span class="p">,</span> <span class="n">op_name</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span>                                       <span class="n">inputs</span><span class="p">,</span> <span class="n">attrs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">55</span> <span class="k">except</span> <span class="n">core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">56</span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-run-two-results-revised-hyperparameters">
<h2>Training Run Two Results: Revised Hyperparameters<a class="headerlink" href="#training-run-two-results-revised-hyperparameters" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history_better_params</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_better_params/saved_history.npy&quot;</span><span class="p">)</span>

<span class="n">acc_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">val_acc_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>

<span class="n">recall_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">]</span>
<span class="n">val_f1_score_better_paramsA</span> <span class="o">=</span> <span class="n">history_better_params</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">]</span>

<span class="n">save_filepath_better_params</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/saved_figures_better_params_modelA/&quot;</span>
<span class="n">modelA_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_training_progress</span><span class="p">(</span><span class="n">loss_better_paramsA</span><span class="p">,</span> <span class="n">acc_better_paramsA</span><span class="p">,</span> <span class="n">modelA_epochs</span><span class="p">,</span> <span class="n">save_filepath</span> <span class="o">=</span> <span class="n">save_filepath_better_params</span><span class="p">,</span> <span class="n">training_run</span> <span class="o">=</span> <span class="s2">&quot;Better Parameters&quot;</span><span class="p">,</span>
                                 <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_better_paramsA</span><span class="p">,</span> <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_better_paramsA</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="n">f1_score_better_paramsA</span><span class="p">,</span>
                                 <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss_better_paramsA</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_acc_better_paramsA</span><span class="p">,</span> <span class="n">val_recall</span> <span class="o">=</span> <span class="n">val_recall_better_paramsA</span><span class="p">,</span> <span class="n">val_precision</span> <span class="o">=</span> <span class="n">val_precision_better_paramsA</span><span class="p">,</span> 
                                 <span class="n">val_f1_score</span> <span class="o">=</span> <span class="n">val_f1_score_better_paramsA</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/dc81def932b98a9d48bbd96008b43fd810cf4b276ab695ae412b9805faa24ec9.png" src="_images/dc81def932b98a9d48bbd96008b43fd810cf4b276ab695ae412b9805faa24ec9.png" />
</div>
</div>
</section>
</section>
<section id="transfer-learning">
<h1>Transfer Learning<a class="headerlink" href="#transfer-learning" title="Link to this heading">#</a></h1>
<p>When we revised our hyperparameters to better reflect our model architecture and the structure of our dataset, we were able to train a more stable model that achieved a validation accuracy, recall, precision, and F1 score of approximately <span class="math notranslate nohighlight">\(45\%\)</span>. This is statistically less than if we were randomly deciding whether an image was a single or a dual. Since the training metrics were high, the model is most-likely overfitting to the data. We can help remedy this by including more dropout/regularization layers, fine-tuning hyperparameters, and/or adjusting our training procedure. We can try to achieve this through rigorous hyperparameter optimization. We can test many hyperparameter combinations, revising their values based on training results, until we arrive at a combination that yields an optimally trained model given our architecture and dataset structure. We can systematically test these hyperparameters through the use of an optimization algorithm, such as a Tree-Based Parzen Estimator (TPE) (which we will discuss in detail on the “Optimization” section of this tutorial). However, these methods require several training runs to converge on an optimal solution. While we will eventually utilize them for hyperparameter optimization the nature of our dataset, with its synthetic and real data components, lends itself nicely to a machine-learning training tactic called <em>transfer learning</em>.</p>
<p>Transfer learning refers to the process of retraining a model, that has been pretrained on a certain dataset, with another dataset while preserving the information learned from its original training input. This process allows the model to retain important feature information it learned from the original training dataset while learning new – and most likely specialized – information from the new dataset, thus producing a better informed and hopefully more accurate model. We call our transfer-learning scheme the <strong>model B</strong> training procedure, and we initiate it by training the model freely on our synthetic dataset for 10 training epochs. Once this finishes, we “freeze” several convolutional layers by setting their parameters to “untrainable”, preserving the data learned from the synthetic set, and training the model on our real dataset for 10 training epochs. We then gradually unfreeze the layers by resetting them to “trainable”, allowing the neurons in these layers to adjust their weights and biases based on real data. We unfreeze one layer per training epoch. Once completely unfrozen, we allow the model to train freely on the real dataset for however many epochs remain after the unfreezing stage, as we allow the model to be trained in the transfer-learning stage for 20 total epochs. Theoretically, this method will allow the model to learn the noise and light profiles of real HSC data without overwriting the valuable overall structure it learned from the synthetic datam thus yielding a highly accurate model. For our data, where an ideally-trained model would learn overall structure (such as where two point sources may broadly be located in a given image if they are present) from the synethic images, then learn fine structure and appropiate noise levels from the real images during the transfer learning stage. As such, we expect this method to yield a significantly more accurate model than training the model on all image types simultaneously, as mixing real and synthetic data in the <strong>model A</strong> procedure does not allow the model sufficient time to learn from the structures in one datatype before it must learn from the other, which contributes to instability in the model and lower metrics overall.</p>
<p>We demonstrate this training proceedure below, using hyperparameters that were optimized during the research and development of this algorithm over this past summer. As with <strong>model A</strong>, we plot the results of this training procedure below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">init_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="mf">5.518358e-07</span>
<span class="c1">#learning_rate = 1.72332548599593680e-06</span>
<span class="n">image_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model_type</span> <span class="o">=</span> <span class="s2">&quot;modelB&quot;</span>
<span class="n">model_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_models_example_modelB/&quot;</span>
<span class="c1">#num_frozen_layers = 22</span>
<span class="n">num_frozen_layers</span> <span class="o">=</span> <span class="mi">17</span>
<span class="n">num_frozen_fc_layers</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">dual_finder_instance</span> <span class="o">=</span> <span class="n">DualFinder</span><span class="p">(</span><span class="n">train_dataset_modelB_sim</span><span class="p">,</span> <span class="n">val_dataset_modelB_sim</span><span class="p">,</span> <span class="n">image_shape</span><span class="p">,</span> <span class="n">train_labels_modelB_sim</span><span class="p">,</span> <span class="n">val_labels_modelB_sim</span><span class="p">,</span> <span class="n">init_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">model_type</span><span class="p">)</span>
<span class="c1">#history_synthetic, pretrained_model = dual_finder_instance.trainCNN(model_filepath)</span>
<span class="c1">#0.32523228915885216</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#os.environ[&#39;TF_GPU_ALLOCATOR&#39;] = &#39;cuda_malloc_async&#39;</span>
<span class="n">tl_epochs</span> <span class="o">=</span> <span class="mi">30</span>
<span class="c1">#tl_learning_rate = 2.7607071462012844e-08</span>
<span class="n">tl_learning_rate</span> <span class="o">=</span> <span class="mf">1.72332548599593680e-06</span>
<span class="c1"># num_frozen_layers = 12</span>
<span class="n">tl_batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="c1">#tl_learning_rate = 8.944489782605628e-06</span>
<span class="c1">#tl_learning_rate = 5.518358e-07</span>
<span class="n">dropout_percentage</span> <span class="o">=</span> <span class="mf">0.21253947483790814</span>
<span class="n">history_synth</span><span class="p">,</span> <span class="n">history_frozen</span><span class="p">,</span> <span class="n">history_unfreeze</span><span class="p">,</span> <span class="n">history_unfrozen</span><span class="p">,</span> <span class="n">model_retrained</span> <span class="o">=</span> <span class="n">dual_finder_instance</span><span class="o">.</span><span class="n">transferLearning</span><span class="p">(</span><span class="n">num_frozen_layers</span><span class="p">,</span> <span class="n">model_filepath</span><span class="p">,</span> <span class="n">tl_epochs</span><span class="p">,</span> <span class="n">train_dataset_modelB_real</span><span class="p">,</span> <span class="n">train_labels_modelB_real</span><span class="p">,</span> <span class="n">val_dataset_modelB_real</span><span class="p">,</span> <span class="n">val_labels_modelB_real</span><span class="p">,</span> <span class="n">tl_batch_size</span><span class="p">,</span> <span class="n">tl_learning_rate</span><span class="p">,</span> <span class="n">dropout_percentage</span><span class="p">,</span> <span class="n">save_feature_maps</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-04-19 00:50:49,376 - INFO - Training on Synthetic Dataset
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>saved_models_example_modelB/
[&#39;double AGN&#39; &#39;double AGN&#39; &#39;single AGN&#39; ... &#39;single AGN&#39; &#39;double AGN&#39;
 &#39;single AGN&#39;]
[&#39;single AGN&#39; &#39;single AGN&#39; &#39;single AGN&#39; ... &#39;double AGN&#39; &#39;double AGN&#39;
 &#39;single AGN&#39;]
Converting to list
Converting to list
</pre></div>
</div>
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential_5"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ rescaling_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Rescaling</span>)         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_20 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │        <span style="color: #00af00; text-decoration-color: #00af00">13,920</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_25 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_20          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │           <span style="color: #00af00; text-decoration-color: #00af00">384</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_21 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">884,992</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_26 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_21          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_22 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">590,080</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_27 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_22          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>) │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_23 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">885,120</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_28 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>) │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13824</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_15 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │     <span style="color: #00af00; text-decoration-color: #00af00">7,078,400</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_29 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_23          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │         <span style="color: #00af00; text-decoration-color: #00af00">2,048</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_16 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │       <span style="color: #00af00; text-decoration-color: #00af00">262,656</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_17 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">2</span>)              │         <span style="color: #00af00; text-decoration-color: #00af00">1,026</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,720,674</span> (37.08 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,718,434</span> (37.07 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">2,240</span> (8.75 KB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">Model: "sequential_5"</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃<span style="font-weight: bold"> Layer (type)                    </span>┃<span style="font-weight: bold"> Output Shape           </span>┃<span style="font-weight: bold">       Param # </span>┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ rescaling_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Rescaling</span>)         │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">60</span>, <span style="color: #00af00; text-decoration-color: #00af00">1</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_20 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │        <span style="color: #00af00; text-decoration-color: #00af00">13,920</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_25 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_20          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">96</span>)     │           <span style="color: #00af00; text-decoration-color: #00af00">384</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_21 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">884,992</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_26 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_21          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_22 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">590,080</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_27 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_22          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">30</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │         <span style="color: #00af00; text-decoration-color: #00af00">1,024</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_10 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>) │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">15</span>, <span style="color: #00af00; text-decoration-color: #00af00">256</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ conv2d_23 (<span style="color: #0087ff; text-decoration-color: #0087ff">Conv2D</span>)              │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │       <span style="color: #00af00; text-decoration-color: #00af00">885,120</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_28 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">13</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)    │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ max_pooling2d_11 (<span style="color: #0087ff; text-decoration-color: #0087ff">MaxPooling2D</span>) │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">6</span>, <span style="color: #00af00; text-decoration-color: #00af00">384</span>)      │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ flatten_5 (<span style="color: #0087ff; text-decoration-color: #0087ff">Flatten</span>)             │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">13824</span>)          │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_15 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │     <span style="color: #00af00; text-decoration-color: #00af00">7,078,400</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dropout_29 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dropout</span>)            │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │             <span style="color: #00af00; text-decoration-color: #00af00">0</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ batch_normalization_23          │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │         <span style="color: #00af00; text-decoration-color: #00af00">2,048</span> │
│ (<span style="color: #0087ff; text-decoration-color: #0087ff">BatchNormalization</span>)            │                        │               │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_16 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">512</span>)            │       <span style="color: #00af00; text-decoration-color: #00af00">262,656</span> │
├─────────────────────────────────┼────────────────────────┼───────────────┤
│ dense_17 (<span style="color: #0087ff; text-decoration-color: #0087ff">Dense</span>)                │ (<span style="color: #00d7ff; text-decoration-color: #00d7ff">None</span>, <span style="color: #00af00; text-decoration-color: #00af00">2</span>)              │         <span style="color: #00af00; text-decoration-color: #00af00">1,026</span> │
└─────────────────────────────────┴────────────────────────┴───────────────┘
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Total params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,720,674</span> (37.08 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">9,718,434</span> (37.07 MB)
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold"> Non-trainable params: </span><span style="color: #00af00; text-decoration-color: #00af00">2,240</span> (8.75 KB)
</pre>
</div><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-04-19 00:50:49,492 - INFO - save_feature_maps == True, WILL save feature maps
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature map will feature: [&#39;single AGN&#39;]
Shape of randomly selected image: (1, 60, 60, 1)
Epoch 1/10
WARNING:tensorflow:5 out of the last 5 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x2d5f63280&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-04-19 00:53:48,820 - WARNING - 5 out of the last 5 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x2d5f63280&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:tensorflow:6 out of the last 6 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x2ebec0940&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-04-19 00:54:24,184 - WARNING - 6 out of the last 6 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x2ebec0940&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">20</span><span class="p">],</span> <span class="n">line</span> <span class="mi">10</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="c1">#tl_learning_rate = 8.944489782605628e-06</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="c1">#tl_learning_rate = 5.518358e-07</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="n">dropout_percentage</span> <span class="o">=</span> <span class="mf">0.21253947483790814</span>
<span class="ne">---&gt; </span><span class="mi">10</span> <span class="n">history_synth</span><span class="p">,</span> <span class="n">history_frozen</span><span class="p">,</span> <span class="n">history_unfreeze</span><span class="p">,</span> <span class="n">history_unfrozen</span><span class="p">,</span> <span class="n">model_retrained</span> <span class="o">=</span> <span class="n">dual_finder_instance</span><span class="o">.</span><span class="n">transferLearning</span><span class="p">(</span><span class="n">num_frozen_layers</span><span class="p">,</span> <span class="n">model_filepath</span><span class="p">,</span> <span class="n">tl_epochs</span><span class="p">,</span> <span class="n">train_dataset_modelB_real</span><span class="p">,</span> <span class="n">train_labels_modelB_real</span><span class="p">,</span> <span class="n">val_dataset_modelB_real</span><span class="p">,</span> <span class="n">val_labels_modelB_real</span><span class="p">,</span> <span class="n">tl_batch_size</span><span class="p">,</span> <span class="n">tl_learning_rate</span><span class="p">,</span> <span class="n">dropout_percentage</span><span class="p">,</span> <span class="n">save_feature_maps</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="nn">File ~/Desktop/Junior_Year_at_Yale/Spring_Semester/ASTR_330/final_project_git_repo/DualFinder/dual_finder/dual_finder/cnn/train_cnn.py:185,</span> in <span class="ni">DualFinder.transferLearning</span><span class="nt">(self, num_layers_to_freeze, model_filepath, newEpochs, new_train_data, new_train_labels, new_val_data, new_val_labels, newBatch, newLearningRate, dropout_rate, train_synth, model, save_feature_maps, newClassWeightsDict)</span>
<span class="g g-Whitespace">    </span><span class="mi">183</span> <span class="k">if</span> <span class="n">train_synth</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">184</span>     <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training on Synthetic Dataset&quot;</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">185</span>     <span class="n">history_synthetic</span><span class="p">,</span> <span class="n">pretrained_model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainCNN</span><span class="p">(</span><span class="n">model_filepath</span> <span class="o">=</span> <span class="n">model_filepath</span><span class="p">,</span> <span class="n">save_feature_maps</span> <span class="o">=</span> <span class="n">save_feature_maps</span><span class="p">,</span> <span class="n">dropout_rate</span> <span class="o">=</span> <span class="n">dropout_rate</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">186</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">187</span>     <span class="n">pretrained_model</span> <span class="o">=</span> <span class="n">model</span>

<span class="nn">File ~/Desktop/Junior_Year_at_Yale/Spring_Semester/ASTR_330/final_project_git_repo/DualFinder/dual_finder/dual_finder/cnn/train_cnn.py:167,</span> in <span class="ni">DualFinder.trainCNN</span><span class="nt">(self, dropout_rate, save_feature_maps, model_filepath)</span>
<span class="g g-Whitespace">    </span><span class="mi">164</span>     <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;save_feature_maps&#39; == </span><span class="si">{</span><span class="n">save_feature_maps</span><span class="si">}</span><span class="s2">, NOT saving feature maps&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">165</span>     <span class="n">callback_array</span> <span class="o">=</span> <span class="p">[</span><span class="n">checkpoint_callback</span><span class="p">]</span>
<span class="ne">--&gt; </span><span class="mi">167</span> <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">train_labels_one_hot</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchSize</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">validation_dataset</span><span class="p">,</span> <span class="n">val_labels_one_hot</span><span class="p">),</span> <span class="n">epochs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="n">class_weightsDict</span><span class="p">,</span> <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callback_array</span><span class="p">,</span> <span class="n">shuffle</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">169</span> <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">170</span> <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;default&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117,</span> in <span class="ni">filter_traceback.&lt;locals&gt;.error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span> <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">116</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">117</span>     <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">118</span> <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">119</span>     <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:325,</span> in <span class="ni">TensorFlowTrainer.fit</span><span class="nt">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)</span>
<span class="g g-Whitespace">    </span><span class="mi">323</span> <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">iterator</span> <span class="ow">in</span> <span class="n">epoch_iterator</span><span class="o">.</span><span class="n">enumerate_epoch</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">324</span>     <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">325</span>     <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">326</span>     <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">327</span>         <span class="n">step</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pythonify_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">328</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">329</span>     <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150,</span> in <span class="ni">filter_traceback.&lt;locals&gt;.error_handler</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">148</span> <span class="n">filtered_tb</span> <span class="o">=</span> <span class="kc">None</span>
<span class="g g-Whitespace">    </span><span class="mi">149</span> <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">150</span>   <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">151</span> <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">152</span>   <span class="n">filtered_tb</span> <span class="o">=</span> <span class="n">_process_traceback_frames</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">__traceback__</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833,</span> in <span class="ni">Function.__call__</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">830</span> <span class="n">compiler</span> <span class="o">=</span> <span class="s2">&quot;xla&quot;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span> <span class="k">else</span> <span class="s2">&quot;nonXla&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">832</span> <span class="k">with</span> <span class="n">OptionalXlaContext</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jit_compile</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">833</span>   <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">835</span> <span class="n">new_tracing_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experimental_get_tracing_count</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">836</span> <span class="n">without_tracing</span> <span class="o">=</span> <span class="p">(</span><span class="n">tracing_count</span> <span class="o">==</span> <span class="n">new_tracing_count</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878,</span> in <span class="ni">Function._call</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">875</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">876</span> <span class="c1"># In this case we have not created variables on the first call. So we can</span>
<span class="g g-Whitespace">    </span><span class="mi">877</span> <span class="c1"># run the first trace but we should fail if variables are created.</span>
<span class="ne">--&gt; </span><span class="mi">878</span> <span class="n">results</span> <span class="o">=</span> <span class="n">tracing_compilation</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">879</span>     <span class="n">args</span><span class="p">,</span> <span class="n">kwds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_variable_creation_config</span>
<span class="g g-Whitespace">    </span><span class="mi">880</span> <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">881</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_created_variables</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">882</span>   <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Creating variables on a non-first call to a function&quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">883</span>                    <span class="s2">&quot; decorated with tf.function.&quot;</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139,</span> in <span class="ni">call_function</span><span class="nt">(args, kwargs, tracing_options)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="n">bound_args</span> <span class="o">=</span> <span class="n">function</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span> <span class="n">flat_inputs</span> <span class="o">=</span> <span class="n">function</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">unpack_inputs</span><span class="p">(</span><span class="n">bound_args</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">139</span> <span class="k">return</span> <span class="n">function</span><span class="o">.</span><span class="n">_call_flat</span><span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>     <span class="n">flat_inputs</span><span class="p">,</span> <span class="n">captured_inputs</span><span class="o">=</span><span class="n">function</span><span class="o">.</span><span class="n">captured_inputs</span>
<span class="g g-Whitespace">    </span><span class="mi">141</span> <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322,</span> in <span class="ni">ConcreteFunction._call_flat</span><span class="nt">(self, tensor_inputs, captured_inputs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1318</span> <span class="n">possible_gradient_type</span> <span class="o">=</span> <span class="n">gradients_util</span><span class="o">.</span><span class="n">PossibleTapeGradientTypes</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1319</span> <span class="k">if</span> <span class="p">(</span><span class="n">possible_gradient_type</span> <span class="o">==</span> <span class="n">gradients_util</span><span class="o">.</span><span class="n">POSSIBLE_GRADIENT_TYPES_NONE</span>
<span class="g g-Whitespace">   </span><span class="mi">1320</span>     <span class="ow">and</span> <span class="n">executing_eagerly</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1321</span>   <span class="c1"># No tape is watching; skip to running the function.</span>
<span class="ne">-&gt; </span><span class="mi">1322</span>   <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inference_function</span><span class="o">.</span><span class="n">call_preflattened</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1323</span> <span class="n">forward_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_select_forward_and_backward_functions</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1324</span>     <span class="n">args</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1325</span>     <span class="n">possible_gradient_type</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1326</span>     <span class="n">executing_eagerly</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1327</span> <span class="n">forward_function</span><span class="p">,</span> <span class="n">args_with_tangents</span> <span class="o">=</span> <span class="n">forward_backward</span><span class="o">.</span><span class="n">forward</span><span class="p">()</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216,</span> in <span class="ni">AtomicFunction.call_preflattened</span><span class="nt">(self, args)</span>
<span class="g g-Whitespace">    </span><span class="mi">214</span> <span class="k">def</span> <span class="nf">call_preflattened</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">args</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">core</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">215</span><span class="w">   </span><span class="sd">&quot;&quot;&quot;Calls with flattened tensor inputs and returns the structured output.&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">216</span>   <span class="n">flat_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">call_flat</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span>   <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">pack_output</span><span class="p">(</span><span class="n">flat_outputs</span><span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251,</span> in <span class="ni">AtomicFunction.call_flat</span><span class="nt">(self, *args)</span>
<span class="g g-Whitespace">    </span><span class="mi">249</span> <span class="k">with</span> <span class="n">record</span><span class="o">.</span><span class="n">stop_recording</span><span class="p">():</span>
<span class="g g-Whitespace">    </span><span class="mi">250</span>   <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bound_context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
<span class="ne">--&gt; </span><span class="mi">251</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_bound_context</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">252</span>         <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span>         <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">254</span>         <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">function_type</span><span class="o">.</span><span class="n">flat_outputs</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">255</span>     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span>   <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">257</span>     <span class="n">outputs</span> <span class="o">=</span> <span class="n">make_call_op_in_graph</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">258</span>         <span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">259</span>         <span class="nb">list</span><span class="p">(</span><span class="n">args</span><span class="p">),</span>
<span class="g g-Whitespace">    </span><span class="mi">260</span>         <span class="bp">self</span><span class="o">.</span><span class="n">_bound_context</span><span class="o">.</span><span class="n">function_call_options</span><span class="o">.</span><span class="n">as_attrs</span><span class="p">(),</span>
<span class="g g-Whitespace">    </span><span class="mi">261</span>     <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500,</span> in <span class="ni">Context.call_function</span><span class="nt">(self, name, tensor_inputs, num_outputs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1498</span> <span class="n">cancellation_context</span> <span class="o">=</span> <span class="n">cancellation</span><span class="o">.</span><span class="n">context</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1499</span> <span class="k">if</span> <span class="n">cancellation_context</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1500</span>   <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1501</span>       <span class="n">name</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1502</span>       <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1503</span>       <span class="n">inputs</span><span class="o">=</span><span class="n">tensor_inputs</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1504</span>       <span class="n">attrs</span><span class="o">=</span><span class="n">attrs</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1505</span>       <span class="n">ctx</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1506</span>   <span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1507</span> <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1508</span>   <span class="n">outputs</span> <span class="o">=</span> <span class="n">execute</span><span class="o">.</span><span class="n">execute_with_cancellation</span><span class="p">(</span>
<span class="g g-Whitespace">   </span><span class="mi">1509</span>       <span class="n">name</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">),</span>
<span class="g g-Whitespace">   </span><span class="mi">1510</span>       <span class="n">num_outputs</span><span class="o">=</span><span class="n">num_outputs</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1514</span>       <span class="n">cancellation_manager</span><span class="o">=</span><span class="n">cancellation_context</span><span class="p">,</span>
<span class="g g-Whitespace">   </span><span class="mi">1515</span>   <span class="p">)</span>

<span class="nn">File ~/anaconda3/envs/astr330/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53,</span> in <span class="ni">quick_execute</span><span class="nt">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="g g-Whitespace">     </span><span class="mi">51</span> <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">52</span>   <span class="n">ctx</span><span class="o">.</span><span class="n">ensure_initialized</span><span class="p">()</span>
<span class="ne">---&gt; </span><span class="mi">53</span>   <span class="n">tensors</span> <span class="o">=</span> <span class="n">pywrap_tfe</span><span class="o">.</span><span class="n">TFE_Py_Execute</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">_handle</span><span class="p">,</span> <span class="n">device_name</span><span class="p">,</span> <span class="n">op_name</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span>                                       <span class="n">inputs</span><span class="p">,</span> <span class="n">attrs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">55</span> <span class="k">except</span> <span class="n">core</span><span class="o">.</span><span class="n">_NotOkStatusException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">56</span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<section id="training-results-transfer-learning">
<h2>Training Results: Transfer Learning<a class="headerlink" href="#training-results-transfer-learning" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history_synthetic</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/saved_history.npy&quot;</span><span class="p">)</span>
<span class="n">acc_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_synth</span><span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">val_acc_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>

<span class="n">recall_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">]</span>
<span class="n">val_f1_score_synth</span><span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">]</span>
<span class="c1">#mcc_better_synth= history_synthetic[&#39;MCC&#39;]</span>
<span class="c1">#val_mcc_synth = history_synthetic[&#39;val_MCC&#39;]</span>


<span class="n">save_filepath_synth</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/saved_figs_modelB/saved_figures_synth_modelB/&quot;</span>
<span class="n">modelB_synth_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_training_progress</span><span class="p">(</span><span class="n">loss_synth</span><span class="p">,</span> <span class="n">acc_synth</span><span class="p">,</span> <span class="n">modelB_synth_epochs</span><span class="p">,</span> <span class="n">save_filepath</span> <span class="o">=</span> <span class="n">save_filepath_synth</span><span class="p">,</span> <span class="n">training_run</span> <span class="o">=</span> <span class="s2">&quot;Train on Synthetic Dataset&quot;</span><span class="p">,</span>
                                 <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_synth</span><span class="p">,</span> <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_synth</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="n">f1_score_synth</span><span class="p">,</span>
                                 <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss_synth</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_acc_synth</span><span class="p">,</span> <span class="n">val_recall</span> <span class="o">=</span> <span class="n">val_recall_synth</span><span class="p">,</span> <span class="n">val_precision</span> <span class="o">=</span> <span class="n">val_precision_synth</span><span class="p">,</span> 
                                 <span class="n">val_f1_score</span> <span class="o">=</span> <span class="n">val_f1_score_synth</span><span class="p">)</span>

<span class="n">history_frozen</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/saved_history_frozen.npy&quot;</span><span class="p">)</span>
<span class="c1">#print(history_frozen)</span>
<span class="n">acc_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">val_acc_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>

<span class="n">recall_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">]</span>
<span class="n">val_f1_score_frozen</span><span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">]</span>

<span class="n">save_filepath_frozen</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/saved_figs_modelB/saved_figures_frozen_modelB/&quot;</span>
<span class="n">modelB_frozen_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_training_progress</span><span class="p">(</span><span class="n">loss_frozen</span><span class="p">,</span> <span class="n">acc_frozen</span><span class="p">,</span> <span class="n">modelB_frozen_epochs</span><span class="p">,</span> <span class="n">save_filepath</span> <span class="o">=</span> <span class="n">save_filepath_frozen</span><span class="p">,</span> <span class="n">training_run</span> <span class="o">=</span> <span class="s2">&quot;Layers Frozen&quot;</span><span class="p">,</span>
                                 <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_frozen</span><span class="p">,</span> <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_frozen</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="n">f1_score_frozen</span><span class="p">,</span>
                                 <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss_frozen</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_acc_frozen</span><span class="p">,</span> <span class="n">val_recall</span> <span class="o">=</span> <span class="n">val_recall_frozen</span><span class="p">,</span> <span class="n">val_precision</span> <span class="o">=</span> <span class="n">val_precision_frozen</span><span class="p">,</span> 
                                 <span class="n">val_f1_score</span> <span class="o">=</span> <span class="n">val_f1_score_frozen</span><span class="p">)</span>

<span class="c1"># During the unfreezing stage, we train the model for one training epoch per newly-unfrozen layer, so the training history object is only recorded</span>
<span class="c1"># for one epoch. As such we load all of the training epochs for the unfreeze portion of the training procedure into an array to be plotted using</span>
<span class="c1"># our plotting functionality.</span>

<span class="n">histories_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_frozen_layers</span><span class="p">):</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;saved_models_example_modelB/saved_history_unfreeze_</span><span class="si">{</span><span class="n">ii</span><span class="si">}</span><span class="s2">.npy&quot;</span><span class="p">)</span>
    <span class="n">histories_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
    
<span class="n">acc_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">recall_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">precision_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">f1_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">mcc_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">val_acc_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_loss_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_recall_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_precision_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_f1_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_mcc_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>


<span class="k">for</span> <span class="n">history</span> <span class="ow">in</span> <span class="n">histories_unfreeze</span><span class="p">:</span>
    <span class="n">acc_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">loss_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">recall_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">precision_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">f1_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1">#mcc_values_unfreeze.append(history[&#39;static_MCC&#39;])</span>

    <span class="n">val_acc_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_loss_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_recall_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_precision_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_f1_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1">#val_mcc_values_unfreeze.append(history[&#39;val_static_MCC&#39;])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">loss_values_unfreeze</span><span class="p">))</span>
<span class="n">save_filepath_unfreeze</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/saved_figs_modelB/saved_figures_unfreeze_modelB/&quot;</span>
<span class="n">unfreeze_end</span> <span class="o">=</span> <span class="mi">11</span><span class="o">+</span><span class="p">(</span><span class="n">num_frozen_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># initial frozen training plus however long it takes to unfreeze the layers. </span>
<span class="n">modelB_unfreeze_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">11</span><span class="o">+</span><span class="p">(</span><span class="n">num_frozen_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_training_progress</span><span class="p">(</span><span class="n">loss_values_unfreeze</span><span class="p">,</span> <span class="n">acc_values_unfreeze</span><span class="p">,</span> <span class="n">modelB_unfreeze_epochs</span><span class="p">,</span> <span class="n">save_filepath</span> <span class="o">=</span> <span class="n">save_filepath_unfreeze</span><span class="p">,</span> <span class="n">training_run</span> <span class="o">=</span> <span class="s2">&quot;Gradual Unfreezing&quot;</span><span class="p">,</span>
                                 <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_values_unfreeze</span><span class="p">,</span> <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_values_unfreeze</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="n">f1_values_unfreeze</span><span class="p">,</span>
                                 <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss_values_unfreeze</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_acc_values_unfreeze</span><span class="p">,</span> <span class="n">val_recall</span> <span class="o">=</span> <span class="n">val_recall_values_unfreeze</span><span class="p">,</span> <span class="n">val_precision</span> <span class="o">=</span> <span class="n">val_precision_values_unfreeze</span><span class="p">,</span> 
                                 <span class="n">val_f1_score</span> <span class="o">=</span> <span class="n">val_f1_values_unfreeze</span><span class="p">)</span>



<span class="n">history_unfrozen</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/saved_history_unfrozen.npy&quot;</span><span class="p">)</span>
<span class="n">acc_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_unfrozen</span><span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="c1">#val_acc_synth = history_synthetic[&#39;val_binary_accuracy&#39;]</span>

<span class="n">recall_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">]</span>
<span class="n">val_f1_score_unfrozen</span><span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">]</span>
<span class="n">modelB_unfrozen_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">unfreeze_end</span><span class="p">,</span> <span class="n">unfreeze_end</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc_unfrozen</span><span class="p">))</span>
<span class="n">save_filepath_unfrozen</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/saved_figs_modelB/save_figures_unfrozen_modelB/&quot;</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_training_progress</span><span class="p">(</span><span class="n">loss_unfrozen</span><span class="p">,</span> <span class="n">acc_unfrozen</span><span class="p">,</span> <span class="n">modelB_unfrozen_epochs</span><span class="p">,</span> <span class="n">save_filepath</span> <span class="o">=</span> <span class="n">save_filepath_unfrozen</span><span class="p">,</span> <span class="n">training_run</span> <span class="o">=</span> <span class="s2">&quot;Fully Unfrozen&quot;</span><span class="p">,</span>
                                 <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_unfrozen</span><span class="p">,</span> <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_unfrozen</span><span class="p">,</span> <span class="n">f1_score</span> <span class="o">=</span> <span class="n">f1_score_unfrozen</span><span class="p">,</span>
                                 <span class="n">val_loss</span> <span class="o">=</span> <span class="n">val_loss_unfrozen</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">val_acc_unfrozen</span><span class="p">,</span> <span class="n">val_recall</span> <span class="o">=</span> <span class="n">val_recall_unfrozen</span><span class="p">,</span> <span class="n">val_precision</span> <span class="o">=</span> <span class="n">val_precision_unfrozen</span><span class="p">,</span> 
                                 <span class="n">val_f1_score</span> <span class="o">=</span> <span class="n">val_f1_score_unfrozen</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0547e3ee84c49e856db10f9c88ece26a914eb20b88480f57c612db6e7442c747.png" src="_images/0547e3ee84c49e856db10f9c88ece26a914eb20b88480f57c612db6e7442c747.png" />
<img alt="_images/bd1509319fa4706237e5bd35862e619035df74036943e751870e74c130885543.png" src="_images/bd1509319fa4706237e5bd35862e619035df74036943e751870e74c130885543.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(16,)
</pre></div>
</div>
<img alt="_images/ccb11a7597265f9649035266ae41e9cde9406fa2bf3313dea83735f9a91b2e89.png" src="_images/ccb11a7597265f9649035266ae41e9cde9406fa2bf3313dea83735f9a91b2e89.png" />
<img alt="_images/354de4043af6a59990f6cd3604fc8f66d6b8eb08643a8c1e08af405fa8c70a24.png" src="_images/354de4043af6a59990f6cd3604fc8f66d6b8eb08643a8c1e08af405fa8c70a24.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Alternative plotting version that plots all sections of the training run on the same plot, color coding them by </span>
<span class="c1"># step in the transfer learning process</span>
<span class="k">def</span> <span class="nf">extract_f1</span><span class="p">(</span><span class="n">f1_array</span><span class="p">):</span>
    <span class="n">f1_score</span> <span class="o">=</span> <span class="p">[</span><span class="n">entry</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">f1_array</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">f1_score</span>
<span class="c1">#Synthetic training phase</span>
<span class="n">history_synthetic</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/saved_history.npy&quot;</span><span class="p">)</span>
<span class="n">acc_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_synth</span><span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">val_acc_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>

<span class="n">recall_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_synth</span> <span class="o">=</span> <span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_synth</span> <span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">])</span>
<span class="n">val_f1_score_synth</span><span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_synthetic</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">])</span>
<span class="n">modelB_synth_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># Frozen training phase</span>
<span class="n">history_frozen</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/saved_history_frozen.npy&quot;</span><span class="p">)</span>
<span class="c1">#print(history_frozen)</span>
<span class="n">acc_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>
<span class="n">val_acc_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>

<span class="n">recall_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_frozen</span> <span class="o">=</span> <span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_frozen</span> <span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">])</span>
<span class="n">val_f1_score_frozen</span><span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_frozen</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">])</span>
<span class="n">modelB_frozen_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="c1">#Unfreeze training phase</span>
<span class="n">histories_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_frozen_layers</span><span class="p">):</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;saved_models_example_modelB/saved_history_unfreeze_</span><span class="si">{</span><span class="n">ii</span><span class="si">}</span><span class="s2">.npy&quot;</span><span class="p">)</span>
    <span class="n">histories_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
    
<span class="n">acc_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">loss_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">recall_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">precision_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">f1_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>


<span class="n">val_acc_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_loss_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_recall_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_precision_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">val_f1_values_unfreeze</span> <span class="o">=</span> <span class="p">[]</span>



<span class="k">for</span> <span class="n">history</span> <span class="ow">in</span> <span class="n">histories_unfreeze</span><span class="p">:</span>
    <span class="n">acc_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">loss_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">recall_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">precision_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">f1_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">extract_f1</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>
    <span class="c1">#mcc_values_unfreeze.append(history[&#39;static_MCC&#39;])</span>

    <span class="n">val_acc_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_loss_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_recall_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_precision_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">val_f1_values_unfreeze</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">extract_f1</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">unfreeze_end</span> <span class="o">=</span> <span class="mi">20</span><span class="o">+</span><span class="p">(</span><span class="n">num_frozen_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># initial frozen training plus however long it takes to unfreeze the layers. </span>
<span class="n">modelB_unfreeze_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">unfreeze_end</span><span class="p">)</span>

<span class="n">history_unfrozen</span> <span class="o">=</span> <span class="n">load_training_history</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/saved_history_unfrozen.npy&quot;</span><span class="p">)</span>
<span class="n">acc_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_binary_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss_unfrozen</span><span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

<span class="n">recall_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="n">val_recall_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_recall&#39;</span><span class="p">]</span>
<span class="n">precision_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span>
<span class="n">val_precision_unfrozen</span> <span class="o">=</span> <span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_precision&#39;</span><span class="p">]</span>

<span class="n">f1_score_unfrozen</span> <span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;f1_score&#39;</span><span class="p">])</span>
<span class="n">val_f1_score_unfrozen</span><span class="o">=</span> <span class="n">extract_f1</span><span class="p">(</span><span class="n">history_unfrozen</span><span class="p">[</span><span class="s1">&#39;val_f1_score&#39;</span><span class="p">])</span>
<span class="n">modelB_unfrozen_epochs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">unfreeze_end</span><span class="p">,</span> <span class="n">unfreeze_end</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc_unfrozen</span><span class="p">))</span>

<span class="n">combined_data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
        <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Synthetic&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">acc_synth</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_acc_synth</span><span class="p">},</span>
        <span class="s1">&#39;Loss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">loss_synth</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_loss_synth</span><span class="p">},</span>
        <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">recall_synth</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_recall_synth</span><span class="p">},</span>
        <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">precision_synth</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_precision_synth</span><span class="p">},</span>
        <span class="s1">&#39;F1 Score&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">f1_score_synth</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_f1_score_synth</span><span class="p">},</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Frozen&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">acc_frozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_acc_frozen</span><span class="p">},</span>
        <span class="s1">&#39;Loss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">loss_frozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_loss_frozen</span><span class="p">},</span>
        <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">recall_frozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_recall_frozen</span><span class="p">},</span>
        <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">precision_frozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_precision_frozen</span><span class="p">},</span>
        <span class="s1">&#39;F1 Score&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">f1_score_frozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_f1_score_frozen</span><span class="p">},</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Gradual Unfreezing&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">acc_values_unfreeze</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_acc_values_unfreeze</span><span class="p">},</span>
        <span class="s1">&#39;Loss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">loss_values_unfreeze</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_loss_values_unfreeze</span><span class="p">},</span>
        <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">recall_values_unfreeze</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_recall_values_unfreeze</span><span class="p">},</span>
        <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">precision_values_unfreeze</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_precision_values_unfreeze</span><span class="p">},</span>
        <span class="s1">&#39;F1 Score&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">f1_values_unfreeze</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_f1_values_unfreeze</span><span class="p">},</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Unfrozen&#39;</span><span class="p">,</span>
        <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">acc_unfrozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_acc_unfrozen</span><span class="p">},</span>
        <span class="s1">&#39;Loss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">loss_unfrozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_loss_unfrozen</span><span class="p">},</span>
        <span class="s1">&#39;Recall&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">recall_unfrozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_recall_unfrozen</span><span class="p">},</span>
        <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">precision_unfrozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_precision_unfrozen</span><span class="p">},</span>
        <span class="s1">&#39;F1 Score&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Training&#39;</span><span class="p">:</span> <span class="n">f1_score_unfrozen</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">:</span> <span class="n">val_f1_score_unfrozen</span><span class="p">},</span>
    <span class="p">}</span>
<span class="p">]</span>
<span class="n">total_epochs</span> <span class="o">=</span> <span class="p">[</span><span class="n">modelB_synth_epochs</span><span class="p">,</span> <span class="n">modelB_frozen_epochs</span><span class="p">,</span> <span class="n">modelB_unfreeze_epochs</span><span class="p">,</span> <span class="n">modelB_unfrozen_epochs</span><span class="p">]</span>
<span class="n">save_filepath</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/saved_figs_modelB/&quot;</span>
<span class="n">plot_grouped_training_progress</span><span class="p">(</span><span class="n">combined_data</span><span class="p">,</span> <span class="n">total_epochs</span><span class="p">,</span> <span class="n">save_filepath</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/122cd1319fa3613e964609b5ba538275a8b241d26ea8c9bcb870396ab2e262a8.png" src="_images/122cd1319fa3613e964609b5ba538275a8b241d26ea8c9bcb870396ab2e262a8.png" />
</div>
</div>
</section>
</section>
<section id="hyperparameter-optimization">
<h1>Hyperparameter Optimization<a class="headerlink" href="#hyperparameter-optimization" title="Link to this heading">#</a></h1>
<p>Our revised training procedure helped us improve our model substantially. We see that both our model’s training and validation F1 scores and accuracies reach values of over <span class="math notranslate nohighlight">\(95\%\)</span>. This means our model consistently and accurately is able to detect dual AGN from our vast dataset. We were able to achieve these high-valued metrics by “fine-tuning” our hyperparameters to best suit the model architecture and the dataset structure. During the R&amp;D of this model, we utilized an optimization library called <code class="docutils literal notranslate"><span class="pre">Optuna</span></code>. <code class="docutils literal notranslate"><span class="pre">Optuna</span></code> optimizes hyperparameters by creating an <code class="docutils literal notranslate"><span class="pre">objective</span></code>, in which we define the hyperparameters we seek to optimize and the range we want to optimize them over, the model architecture, and the training scheme we hope to opimize over. Once defined, we pass this <code class="docutils literal notranslate"><span class="pre">objective</span></code> into a <code class="docutils literal notranslate"><span class="pre">study</span></code> object, that uses an optimization algorithm to search the hyperparameter parameter space for parameters that maximimze (in the case of accuracy, F1 score, etc.) or minimize (in the case of loss function) the value of these metrics over several training runs.</p>
<p><code class="docutils literal notranslate"><span class="pre">Optuna</span></code> makes several pre-programmed optimization algorithms available, which include Grid Search, Random Search, and the Tree-structured Parzen Estimator (TPE) algorithm. Grid Search conducts an exhaustive search over the hyperparameter space, testing the effect of as many possible parameters within the time limits of the optimization session. While this method has reduced risk of skipping over an optimal parameter combination, it is incredibly time consuming and may be too computationally expensive if many hyperparameters are being optimized simultaneously. Conversely, Random Search takes a random sample of hyperparamter values from the hyperparameter space and samples over a distribution. The TPE algorithm takes inputted parameters and creates grouped combinations using a Gaussian Mixture Model, an unsupervised ML model that assumes the data is generated using a combination of Gaussians with unknown parameters. Parameter combinations are then sampled from the clustered groups, and the model is trained and evaluated to determine the success of these combinations. TPE is the default algorithm for <code class="docutils literal notranslate"><span class="pre">Optuna</span></code>, as it is efficient at finding hyperparameter values and adaptive to the model’s response to these combinations. However, using an unsupervised machine learning model always introduces some amount of uncertainty into hyperparameter combination determination, which may yield inaccurate combinations if the TPE algorithm gets stuck in local minima in its loss function. Nevertheless, we will use TPE for our example optimization below, as it additionally can handle high-dimension hyperparameter spaces, which allows us to optimize several hyperparameters simultaneously. In our example, we optimize 6 hyperparameters simultaneously:</p>
<p>To setup our optimization run, we created the <code class="docutils literal notranslate"><span class="pre">optimize</span></code> module and the <code class="docutils literal notranslate"><span class="pre">OptimzeHyperparameters</span></code>object, which takes as input a model and its dataset(s), as well as the hyperparameters the user wishes to opimize, and performs an example optimization run using <code class="docutils literal notranslate"><span class="pre">10</span></code> trials. We store the evaluation parameters, as well as their associated hyperparameter combinations, in arrays to be plotted in our <code class="docutils literal notranslate"><span class="pre">visualize_optimization</span></code> function. The optimization run and associated plots are displayed below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trial_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_optimization_trials/&quot;</span>
<span class="n">hyperparameter_optimization</span> <span class="o">=</span> <span class="n">OptimizeHyperparameters</span><span class="p">(</span><span class="n">trial_filepath</span><span class="p">,</span>
                                                      <span class="n">synth_train_dataset</span> <span class="o">=</span> <span class="n">train_dataset_modelB_sim</span><span class="p">,</span> 
                                                      <span class="n">synth_train_labels</span> <span class="o">=</span> <span class="n">train_labels_modelB_sim</span><span class="p">,</span> 
                                                      <span class="n">synth_val_dataset</span> <span class="o">=</span> <span class="n">val_dataset_modelB_sim</span><span class="p">,</span> 
                                                      <span class="n">synth_val_labels</span> <span class="o">=</span> <span class="n">val_labels_modelB_sim</span><span class="p">,</span> 
                                                      <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset_modelB_real</span><span class="p">,</span> 
                                                      <span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_labels_modelB_real</span><span class="p">,</span>
                                                      <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">val_dataset_modelB_real</span><span class="p">,</span>
                                                      <span class="n">val_labels</span> <span class="o">=</span> <span class="n">val_labels_modelB_real</span><span class="p">)</span>
<span class="n">num_trials</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="n">hyperparameter_optimization</span><span class="o">.</span><span class="n">test_study</span><span class="p">(</span><span class="n">num_trials</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;transfer learn&quot;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<p>Now let’s create a visual representation of the optimization process to see the TPE optimizer in action. The function above saved the metadata from each optimization run into <code class="docutils literal notranslate"><span class="pre">.csv</span></code> files associated with each trial number. Our <code class="docutils literal notranslate"><span class="pre">VisualizeOptimization</span></code> <code class="docutils literal notranslate"><span class="pre">class</span></code> extracts the values of each hyperparameter – <code class="docutils literal notranslate"><span class="pre">init_learning_rate</span></code>, <code class="docutils literal notranslate"><span class="pre">init_batch_size</span></code>, <code class="docutils literal notranslate"><span class="pre">droput_rate</span></code>, <code class="docutils literal notranslate"><span class="pre">num_frozen_layers</span></code>, <code class="docutils literal notranslate"><span class="pre">unfreeze_learning_rate</span></code>, and <code class="docutils literal notranslate"><span class="pre">unfreeze_batch_size</span></code> – and overlays their evolution over trial number with the <code class="docutils literal notranslate"><span class="pre">best_value</span></code> of the optimziation run, which calculated by <code class="docutils literal notranslate"><span class="pre">best_value</span> <span class="pre">=</span> <span class="pre">1-accuracy</span></code>. As such, a smaller <code class="docutils literal notranslate"><span class="pre">best_value</span></code> means a more accurate model. We display the plots below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">trial_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_optimization_trials/&quot;</span>
<span class="n">opt_visualizer</span> <span class="o">=</span> <span class="n">VisualizeOptimization</span><span class="p">(</span><span class="n">trial_filepath</span><span class="p">)</span>
<span class="n">opt_visualizer</span><span class="o">.</span><span class="n">plot_best_params</span><span class="p">(</span><span class="n">num_trials</span> <span class="o">=</span> <span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d1889e3ca3213104dceba206f30254bc124c6d64943598c32df7665b8ff54810.png" src="_images/d1889e3ca3213104dceba206f30254bc124c6d64943598c32df7665b8ff54810.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pwd
<span class="kn">from</span> <span class="nn">extract_feature_maps</span> <span class="kn">import</span> <span class="n">create_gif</span>
<span class="n">gif_save_filepath</span> <span class="o">=</span> <span class="s2">&quot;saved_models_example_modelB/feature_map_progress/animated_feature_map.gif&quot;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">exists</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/feature_map_progress/&quot;</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;saved_models_example_modelB/feature_map_progress/&quot;</span><span class="p">)</span>
<span class="n">fm_filepath</span> <span class="o">=</span> <span class="s2">&quot;dual_finder/dual_finder/cnn/feature_maps/saved_models_example_modelB/&quot;</span>
<span class="n">create_gif</span><span class="p">(</span><span class="n">fm_filepath</span><span class="p">,</span> <span class="n">gif_save_filepath</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/moskowitzi/Desktop/Junior_Year_at_Yale/Spring_Semester/ASTR_330/final_project_git_repo/DualFinder
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024-04-19 01:04:48,033 - INFO - Animating 106 images
2024-04-19 01:04:48,092 - INFO - Animation.save using &lt;class &#39;matplotlib.animation.PillowWriter&#39;&gt;
2024-04-19 01:04:57,335 - INFO - GIF saved successfully at saved_models_example_modelB/feature_map_progress/animated_feature_map.gif
</pre></div>
</div>
<img alt="_images/c527fafd3ad1ec3f7416bd1590bb5a418c7a3cb7404a7d45ec75634a0a2682fc.png" src="_images/c527fafd3ad1ec3f7416bd1590bb5a418c7a3cb7404a7d45ec75634a0a2682fc.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">gif_save_filepath</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4a9a92a310ea7237700d5e45ccfae264f09f4fe36ef7d6dcb8e2620db8d3d5c3.gif" src="_images/4a9a92a310ea7237700d5e45ccfae264f09f4fe36ef7d6dcb8e2620db8d3d5c3.gif" />
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">How to Train Your Neural Net: A Comprehensive Guide to Designing and Training Convolutional Neural Networks for Astrophysical Purposes.</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#author-isaac-moskowitz">Author: Isaac Moskowitz</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#professor-earl-p-bellinger">Professor Earl P. Bellinger</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#astr-330-scientific-computing-in-astrophysics">ASTR 330: Scientific Computing in Astrophysics.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#final-project">Final Project.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing-and-packaging">Data Preprocessing and Packaging</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-structure">Dataset Structure</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#synthetic-images">Synthetic Images</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#real-and-composite-images">Real and “Composite” Images</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#architecture-and-design-of-dualfinder">Architecture and Design of <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conv2d-and-maxpooling2d-layers"><code class="docutils literal notranslate"><span class="pre">Conv2D</span></code> and <code class="docutils literal notranslate"><span class="pre">MaxPooling2d</span></code> Layers.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-functions">Activation Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dropout-regularization-and-batchnormalization"><code class="docutils literal notranslate"><span class="pre">Dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">Regularization</span></code>, and <code class="docutils literal notranslate"><span class="pre">BatchNormalization</span></code>.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compiling-dualfinder">Compiling <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-learning-rate">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-batch-size">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">batch_size</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters-dropout">Hyperparameters: <code class="docutils literal notranslate"><span class="pre">dropout</span></code></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-dualfinder">Training <em>DualFinder</em></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-metrics">Model Metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-proceedure">Training Proceedure</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-one-discussion">Training Run One Discussion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-two-revised-hyperparameters">Training Run Two: Revised Hyperparameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-run-two-results-revised-hyperparameters">Training Run Two Results: Revised Hyperparameters</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-learning">Transfer Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-results-transfer-learning">Training Results: Transfer Learning</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-optimization">Hyperparameter Optimization</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Isaac Moskowitz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>